## 查询

###  数据表的常见约束 

　　当我们创建数据表的时候，还会对字段进行约束，约束的目的在于保证 RDBMS 里面数据的准确性和一致性。

1. 主键约束

   主键起的作用是唯一标识一条记录，不能重复，不能为空， 即 `UNIQUE`+`NOT NULL`。一个数据表的主键只能有一个。 主键可以是一个字段，也可以由多个字段复合组成。

2. 外键约束

   外键确保了表与表之间引用的完整性。一个表中的外键对应 另一张表的主键。外键可以是重复的，也可以为空。比如 `player_id` 在 `player` 表中是主键，如果想设置一个球员比分表即 `player_score`，就可以在 `player_score` 中设置 `player_id` 为外键，关联到 `player` 表中。 除了对键进行约束外，还有字段约束。 

3. 唯一性约束

   唯一性约束表明了字段在表中的数值是唯一的，即使我们已经有了主键，还可以对其他字段进行唯一性约束。比如我们在 `player` 表中给 `player_name` 设置唯一性约束，就表明任何两个球员的姓名不能相同。

4. NOT NULL 约束

   对字段定义了NOT NULL，即表明该字段不应为空，必须有取值。 

5. DEFAULT 约束

   表明了字段的默认值。如果在插入数据的时候，这个字段没有取值，就设置为默认值。比如我们将身高 height 字段的取值默认设置为 0.00，即`DEFAULT 0.00`。 

6. CHECK 约束

   用来检查特定字段取值范围的有效性， CHECK 约束的结果不能为 `FALSE`，比如我们可以对身高 height 的数值进行 CHECK 约束，必须≥0，且＜3，即 `CHECK(height>=0 AND height<3)`。 

### 查询时使用的连接

1. 笛卡尔积。笛卡尔乘积是一个数学运算。假设我有两个集合 X 和 Y，那 么 X 和 Y 的笛卡尔积就是 X 和 Y 的所有可能组合，也就是<u>第一个对象来自于 X，第二个对象来自于 Y 的所有可能</u>。
2. 等值连接。两张表的等值连接就是用两张表中都存在的列进行连接` WHERE a.team_id = b.team_id`。
3. 非等值连接。当我们进行多表查询的时候，如果连接多个表的条件是等号时，就是等值连接，其他的运算符连接就是非等值查询`a.height BETWEEN b.height_lowest and b.height_highest`。
4. 外连接。左外连接，就是指左边的表是主表，需要显示左边表的全部行，而右侧的表是从表；右外连接，指的就是右边的表是主表，需要显示右边表的全部行，而左侧的表是从表。 
5. 自连接。

**使用通配符进行过滤** `%`代表一个或多个字符，而`_`只代表一个字符

**共享锁会发生死锁**  客户端 1 先开启事务，然后采用读锁的方式对`user_id=912178`的数据行进行查询，这时事务没有提交的时候，这几行数据行上了读锁。 然后我们用客户端 2 开启事务，同样对`user_id=912178`获取读锁，理论上获取读锁后还可以对数据进行修改，比如执行下面这条语句： 

``` sql
UPDATE product_comment SET product_i = 10002 WHERE user_id = 912178;
```

当我们执行的时候客户端 2 会一直等待。

### MVCC

**MVCC的作用**

1. Innodb的MVCC能防止幻读的发生。(不是每个MVCC都可以，看MVCC怎么实现)
2. 实现了多个事务并发下，读操作的非阻塞。

**MVCC的实现原理**

MVCC 是通过 Undo Log + Read View 进行数据读取，<u>**Undo Log 保存了历史快照，而 Read View 规则帮我们判断当前版本的数据是否可见。**</u>

1. 首先获取事务自己的版本号，也就是事务ID
2. 获取Read View，<u>Read View 保存了当前事务开启时所有活跃（还没有提交）的事务列表，换个角度可以理解为 Read View 保存了不应该让这个事务看到的其他的事务 ID 列表。</u>
3. 查询得到的数据，然后与 Read View 中的事务版本号进行比较
4. 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照
5. 返回符合规则的数据

**什么是ReadView**

所谓consistent read view就是在某一时刻给事务系统trx_sys打snapshot（快照），把当时trx_sys状态（包括活跃读写事务数组）记下来，之后的所有读操作根据其事务ID（即trx_id）与snapshot中的trx_sys的状态作比较，以此判断read view对于事务的可见性。

**ReadView 规则**

* 如果查询行记录的事务 ID < 活跃的最小事务 ID，也就是说这个行记录在这些活跃的事务创建之前就已经提交了，那么这个行记录对该事务是可见的。
* 如果查询行记录的事务 ID > 活跃的最大事务 ID，这说明该行记录在这些活跃的事务创建之后才创建，那么这个行记录对当前事务不可见。 
* 如果是在最小事务和最大事务之间（看看是不是活跃的事务），说明该行记录所在的事务在当前查询的事务创建的时候，可能还处于活跃的状态，因此我们需要在 trx_ids 集合中进行遍历，如果查询行记录ID存在于当前活跃事务集合中，证明这个事务还处于活跃状态，不可见。否则，证明事务已经提交了， 该行记录可见。

**通过 MVCC 可以解决的问题** 

1. 读写之间阻塞的问题，通过 MVCC 可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力。
2. 降低了死锁的概率。这是因为 MVCC 采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
3. **解决一致性读的问题。一致性读也被称为快照读**，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。 

**快照读和当前读**

　　快照读读取的是快照数据。<u>不加锁的简单的 SELECT 都属于快照读</u>；当前读就是读取最新数据，而不是历史版本的数据。加锁的 SELECT，或者对数据进行增删改都会进行当前读

**InnoDB 是如何解决幻读的**

　　在可重复读的情况下，InnoDB 可以<u>通过 Next-Key 锁 +MVCC 来解决幻读问题</u>。 在读已提交的情况下，即使采用了 MVCC 方式也会出现幻读。 出现幻读的原因是在读已提交的情况下，InnoDB 只采用记录锁。

在默认的可重复读级别下，使用这三个锁

1. 记录锁：针对单个行记录添加锁。
2. 间隙锁（Gap Locking）：可以帮我们锁住一个范围（索引之间的空隙），但不包括记录本身。<u>采用间隙锁的方式可以防止幻读情况的产生</u>。
3. Next-Key 锁：帮我们锁住一个范围，同时锁定记录本身，相当于间隙锁 + 记录锁，可以解决幻读的问题。 在隔离级别为可重复读时，InnoDB 会采用 Next-Key 锁的机制，帮我们解决幻读问题。 还是这个例子，我们能看到当我们想要插入球员艾利克斯·伦（身高 2.16 米）的时候，事务 B 会超时，无法插入该数据。这是因为采用了 Next-Key 锁，会将 height>2.08 的范围都进行锁定，就无法插入符合这个范围的数据了。然后事务 A 重新进行条件范围的查询，就不会出现幻读的情况。 

### 范式

1. 1NF 指的是数据库表中的任何属性都是原子性的，不可再分
2. 2NF 指的数据表里的非主属性都要和这个数据表的候选键有完全依赖关系
3. 3NF 在满足 2NF 的同时，对任何非主属性都不传递依赖于候选键

# 索引

## innoDB跟myisam的区别

1. <u>InnoDB 支持事务，MyISAM 不支持事务。</u>这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一

2. <u>InnoDB 支持外键，而 MyISAM 不支持。</u>对一个包含外键的 InnoDB 表转为 MYISAM 会失败

3. <u>InnoDB 主键索引采用聚集索引（索引的数据域存储数据文件本身），辅助索引的数据域存储主键的值；MyISAM 是非聚集索引，索引文件的数据域存储指向数据文件的指针。辅助索引与主键索引基本一致，但是辅助索引不用保证唯一性。</u>

   聚集索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，<u>**索引保存的是数据文件的指针**</u>。主键索引和辅助索引是独立的。 

4. <u>InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快</u>

5. <u>InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。</u>一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一

## 索引的目的是什么？

1. 快速访问数据表中的数据，提高检索速度。
2. 创建唯一性索引，保证数据库表中每一行数据的唯一性。
3. 加速表和表之间的连接
4. 使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间

## 什么时候需要索引，以及如何选择索引(举例)

1. 字段的数值有唯一性的限制，比如用户名
2. 频繁作为 WHERE 查询条件的字段，尤其在数据表大的情况下 
3. 需要经常 GROUP BY 和 ORDER BY 的列
4. UPDATE、DELETE 的 WHERE 条件列，一般也需要创建索引 
5. DISTINCT 字段需要创建索引

## 什么时候不用索引？

1. **WHERE 条件（包括 GROUP BY、ORDER BY）里用不到的字段**不需要创建索引，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的。举个例子： 因为我们是按照 user_id 来进行检索的，所以不需要对其他字段创建索引，即使这些字段出现在 SELECT 字段中。

2. 如果**表记录太少**，比如少于 1000 个，那么是不需要创建索引的。我之前讲 过一个 SQL 查询的例子（第 23 篇中的 heros 数据表查询的例子，一共 69 个英雄不用索引也很快），表记录太少，是否创建索引对查询效率的影响并不大。

3. 字段中如果**有大量重复数据**，也不用创建索引，比如性别字段。不过我们也 需要根据实际情况来做判断。

   为什么性别不适合建索引呢？因为你访问索引需要付出额外的IO开销，你从索引中拿到的只是地址，要想真正访问到数据还是要对表进行一次IO。假如你要从表的100万行数据中取几个数据，那么利用索引迅速定位，访问索引的这IO开销就非常值了。但如果你是从100万行数据中取50万行数据，就比如性别字段，那你相对需要访问50万次索引，再访问50万次表，加起来的开销并不会比直接对表进行一次完整扫描小。

4. **频繁更新的字段**不一定要创建索引。因为更新数据的时候，也需要更新索引，如果索引太多，在更新索引的时候也会造成负担，从而影响效率。 

## B树和B+树的特点或区别

一个 M 阶的 B 树（M>2）有以下的特性：

1. <u>根节点的儿子数的范围是 [2，M]</u>。
2. <u>每个中间节点包含 k-1 个关键字和 k 个孩子</u>。孩子的数量 = 关键字的数量 +1，k 的取值范围为 [ceil(M/2)， M]。
3. <u>叶子节点包括 k-1 个关键字</u>（叶子节点没有孩子）。k 的取值范围为 [ceil(M/2)， M]。
4. 假设中间节点节点的关键字为：Key[1]， Key[2]， …， Key[k-1]，且<u>关键字按照升序排序</u>，即 Key[i] < Key[i+1]。此时 k-1 个关键字相当于划分了 k 个范围，也就是对应着 k个指针，即为：P[1]， P[2]， …， P[k]，其中 P[1] 指向关键字小于 Key[1] 的子树，P[i] 指向关键字属于 (Key[i-1]， Key[i]) 的子树，P[k] 指向关键字大于 Key[k-1] 的子树。所有叶子节点位于同一层。

B+树和 B 树的差异在于以下几点：

1. <u>有 k 个孩子的节点就有 k 个关键字</u>。也就是孩子数量 = 关键字数，而 B 树中，孩子数量 = 关键字数 +1。
2. <u>非叶子节点的关键字也会同时在子节点中存在，并且是在子节点中所有关键字的最大或最小</u>。
3. <u>非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中</u>。而 B 树中，非叶子节点既保存索引，也保存数据记录。
4. <u>所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且**叶子节点本身按照关键字的大小从小到大顺序链接。**</u>

> 因为叶子节点本身是按照关键子的大小从小到大排列的，并且是一个双向链表，所以在进行范围查找的时候，找到关键字然后按照大小前后遍历就好了

## 聚集索引和非聚集索引的区别

　　InnoDB的主键索引是聚集索引，聚集索引是将主键组织到一棵B+树中，而行数据就储存在叶子节点上，通过主键就能直接获取到行数据。若对辅助索引进行条件搜索，则需要两个步骤：第一步在辅助索引B+树中检索，到达叶子节点找到对应的主键。第二步使用主键在主索引B+树中再进行检索操作，最终到达叶子节点即可获取整行数据。（重点在于通过其他键需要建立辅助索引）

　　MyISM使用的是非聚集索引，非聚集索引的主键索引和辅助索引的B+树节点的结构完全一致只是存储的内容不同而已，主键索引B+树的节点存储了主键，辅助键索引B+树存储了辅助键。**这两种B+树的叶子节点存储的都是指向表数据的地址，表数据存储在独立的地方。先要找到指针，才能找到数据。**

## 非聚集索引一定会回表查询吗?

　　不一定，这涉及到查询语句所要求的字段是否全部命中了索引，如果全部命中了索引，那么就不必再进行回表查询.

　　举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行`select age from employee where age < 20`的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询.

### 什么是回表（讲覆盖索引的时候提到不用回表）

　　所谓的**回表查询**，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。就是聚集索引查询的过程。

## 覆盖索引、联合索引、唯一索引、前缀索引？

**覆盖索引** 

​		在一棵索引树上就能获取SQL所需的所有数据，不需要回表，速度更快。比如说有组合索引(name，age)。`select age from t where name = 'XX';`

**联合索引**

　　联合索引又叫复合索引。对于复合索引：Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index (a，b，c). 可以支持 a | a，b | a，b，c 3种组合进行查找，但不支持 b，c进行查找 .当最左侧字段是常量引用时，索引就十分有效。

**唯一索引**

​		<u>唯一索引就是在普通索引上增加了约束性，也就是关键字唯一，找到了关键字就停止检索。</u> 而普通索引，可能会存在用户记录中的关键字相同的情况，根据页结构的原理，当我们读取一条记录的时候，不是单独将这条记录从磁盘中读出去，而是将这个记录所在的页加载到内存中进行读取。

**前缀索引**

　　当要索引的列字符很多时索引则会很大且变慢，可以只索引列开始的部分字符串 节约索引空间 从而提高索引效率。

**索引下推**

```sql
select * from tuser where name like '张%' and age=10;
```

　　组合索引满足最左匹配原则，但是遇到非等值判断时匹配停止。假设有索引（name，age），name like '陈%'不是等值判断，后面的age=20就用不上组合索引了。如果没有索引下推，组合索引只能拿到name回表判断条件。用了索引下推，就算遇到非等值判断，也能继续判断条件。而MySQL 5.6 以后， 存储引擎根据联合索引，找到`name like '张%'`，由于联合索引中包含`age`列，所以存储引擎直接再联合索引里按照`age=10`过滤。按照过滤后的数据再一一进行回表扫描。　　

## mysql 索引在什么情况下会失效

对表score添加了联合索引(studentid, courseid)：

1. 如果索引进行了**表达式计算**，则会失效。

2. 如果对索引**使用函数**，也会造成失效。

3. 在 WHERE 子句中，如果在 **OR 前的条件列进行了索引，而在 OR 后的条件列没有进行索引**，那么索引会失效。 

   ``` mysql
   # 虽然有联合索引，但是courseid没有索引，此时type为ALL
   explain select fraction from score where studentid = 1 or courseid = 1;
   ```

4. 当我们使用 **LIKE 进行模糊查询**的时候，%在第一位

5. 在 WHERE 子句中，索引列与 **NULL 或者 NOT NULL 进行判断**的时候也会失效。这是因为索引并不存储空值，所以最好在设计数据表的时候就将字段设置为 NOT NULL 约 束，比如你可以将 INT 类型的字段，默认值设置为 0。将字符类型的默认值设置为空字符串`' '`。 

6. 我们在使用联合索引的时候要注意**最左原则**。比如说如果创建了(a, b)联合索引，实际上是创建了a索引，(a,b)索引。b并不能用索引。

   实际上，这两个结果一样，都使用了联合索引

   ``` mysql
   explain select fraction from score where studentid = 1 and courseid = 1;
   explain select fraction from score where courseid = 1 and studentid = 1;
   ```

   就像(studentid, courseid)两个索引，这是用不到索引的，但是就像(studentid, fraction, courseid)三个的联合索引，是可以用到了：

   ``` mysql
   explain select fraction from score where courseid = 1;
   ```

## 为什么使用聚集索引？聚集索引的优势？

看上去聚集索引的效率明显要低于非聚集索引，因为每次使用辅助索引检索都要经过两次B+树查找，这不是多此一举吗？聚集索引的优势在哪？

1. **聚集索引将索引和数据保存在同一个B+Tree中，找到叶子节点就可以立刻将行数据返回了，因此从聚集索引中获取数据通常比在非聚集索引中查找要快。**

   由于行数据和叶子节点存储在一起，同一页中会有多条行数据，访问同一数据页不同行记录时，已经把页加载到了Buffer中，再次访问的时候，会在内存中完成访问，不必访问磁盘。这样主键和行数据是一起被载入内存的，找到叶子节点就可以立刻将行数据返回了，如果按照主键Id来组织数据，获得数据更快。

2. **辅助索引使用主键作为指针，InnoDB在移动行时无须更新辅助索引中的这个"指针"。使用聚集索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。**

   辅助索引使用主键作为"指针"而不是使用地址值作为指针的好处是，减少了当出现行移动或者数据页分裂时辅助索引的维护工作**，**使用主键值当作指针会让辅助索引占用更多的空间，换来的好处是InnoDB在移动行时无须更新辅助索引中的这个"指针"**。**也就是说**行的位置（实现中通过16K的Page来定位）会随着数据库里数据的修改而发生变化（前面的B+树节点分裂以及Page的分裂），使用聚集索引就可以保证不管这个主键B+树的节点如何变化，辅助索引树都不受影响。**

3. **聚集索引适合用在排序的场合，非聚集索引不适合，所以，取出一定范围数据的时候，使用用聚集索引更快**

   因为聚集索引叶节点本身就是索引和数据按相同顺序放置在一起，索引序即是数据序，数据序即是索引序，所以很快。非聚集索引叶节点是保留了一个指向数据的指针，索引本身当然是排序的，但是数据并未排序，数据查询的时候需要消耗额外更多的I/O，所以较慢。

5. 可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚集索引，则每封邮件都可能导致一次磁盘 I/O。

## 聚集索引的劣势

1. **维护索引很昂贵，特别是插入新行或者主键被更新导至要分页(page split)的时候**。建议在大量插入新行后，选在负载较低的时间段，通过OPTIMIZE TABLE优化表，因为必须被移动的行数据可能造成碎片。使用独享表空间可以弱化碎片

2. 表因为使用UUId（随机ID）作为主键，使数据存储稀疏，这就会出现聚集索引有可能有比全表扫面更慢，

   <img src="D:/%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9C%E4%BA%91/pictures/image-20210513150552332.png" alt="image-20210513150552332" style="zoom: 80%;" />

　　所以建议使用int的auto_increment作为主键

<img src="D:/%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9C%E4%BA%91/pictures/image-20210513150623275.png" alt="image-20210513150623275" style="zoom:80%;" />

　　主键的值是顺序的，所以 InnoDB 把每一条记录都存储在上一条记录的后面。当达到页的最大填充因子时（InnoDB 默认的最大填充因子是页大小的 15/16，留出部分空间用于以后修改），下一条记录就会写入新的页中。一旦数据按照这种顺序的方式加载，主键页就会近似于被顺序的记录填满（二级索引页可能是不一样的）

　　如果主键比较大的话，那辅助索引将会变的更大，因为**辅助索引的叶子存储的是主键值；过长的主键值，会导致非叶子节点占用占用更多的物理空间**

## 为什么主键通常建议使用自增id

​		mysql 在底层是以数据页为单位来存储数据的，一个数据页大小默认为 16k，当然你也可以自定义大小，也就是说如果一个数据页存满了，mysql 就会去申请一个新的数据页来存储数据。

- 如果主键为自增 id 的话，mysql 在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。
- 如果主键是非自增 id，为了确保索引有序，mysql 就需要将每次插入的数据都放到合适的位置上。那这样需要不断地调整数据的物理地址、分页，效率会很低。比如说当往一个快满或已满的数据页中插入数据时，新插入的数据会将数据页写满，mysql 就需要申请新的数据页，并且把上个数据页中的部分数据挪到新的数据页上。这就造成了页分裂，这个大量移动数据的过程是会严重影响插入效率的。

　　**聚集索引的数据的物理存放顺序与索引顺序是一致的**，即：**只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的**。如果主键不是自增id，那么可以想象，它会干些什么，不断地调整数据的物理地址、分页，当然也有其他一些措施来减少这些操作，但却无法彻底避免。但如果是自增的，那就简单了，它只需要一页一页地写，索引结构相对紧凑，磁盘碎片少，效率也高。

　　因为**MyISAM的主索引并非聚集索引，那么他的数据的物理地址必然是凌乱的，拿到这些物理地址，按照合适的算法进行I/O读取，于是开始不停的寻道不停的旋转**。**聚集索引则只需一次I/O**。（强烈的对比）

　　不过，如果**涉及到大数据量的排序、全表扫描、count之类的操作的话，还是MyISAM占优势些，因为索引所占空间小，这些操作是需要在内存中完成的**。

## mysql中聚集索引的设定

　　**聚集索引默认是主键**，如果表中没有定义主键，InnoDB 会选择一个**唯一的非空索引**代替。如果没有这样的索引，InnoDB 会**隐式定义一个主键**来作为聚集索引。InnoDB 只聚集在同一个页面中的记录。包含相邻键值的页面可能相距甚远。**如果你已经设置了主键为聚集索引，必须先删除主键，然后添加我们想要的聚集索引，最后恢复设置主键即可**。

　　此时其他索引只能被定义为非聚集索引。这个是最大的误区。有的主键还是无意义的自动增量字段，那样的话Clustered index对效率的帮助，完全被浪费了。

　　刚才说到了，聚集索引性能最好而且具有唯一性，所以非常珍贵，必须慎重设置。**一般要根据这个表最常用的SQL查询方式来进行选择，某个字段作为聚集索引，或组合聚集索引**，这个要看实际情况。

　　记住我们的**最终目的**就是**在相同结果集情况下，尽可能减少逻辑IO**。

## b+树为什么能三层能存2000多万个，计算过程

　　这里我们先假设 B+ 树高为 2，即存在一个根节点和若干个叶子节点，那么这棵 B+ 树的存放总记录数为：根节点指针数 * 单个叶子节点记录行数。

　　我们假设主键 ID 为 **bigint 类型，长度为 8 字节**，而**指针大小在 InnoDB 源码中设置为 6 字节**，这样一共 14 字节，我们一个页中能存放多少这样的单元，其实就代表有多少指针，即 16384/14=1170。

　　在 MySQL中 InnoDB 页的大小默认是 16k。假设一行数据的大小是 1k，那么**一个页可以存放 16 行**这样的数据，也就是单个叶子节点记录行数为16。

　　对于联合索引来说只不过比单值索引多了几列，而这些索引列全都出现在索引树上。对于联合索引，存储引擎会首先根据第一个索引列排序；如果第一列相等则再根据第二列排序，依次类推就构成了索引树。

## 为什么 MySQL 的索引要使用 B+ 树而不是其它树形结构？比如 B 树？

　　**因为 B 树不管叶子节点还是非叶子节点，都会保存数据**，这样导致在在一个内存页中非叶子节点中能保存的指针数量变少（有些资料也称为扇出），指针少的情况下要保存大量数据，只能增加树的高度，导致 IO 操作变多，查询性能变低。

　　在 InnoDB 的表空间文件中，约定 page number 为 3 的代表主键索引的根页，而在根页偏移量为 64 的地方存放了该 B+ 树的 page level。如果 page level 为 1，树高为 2，page level 为 2，则树高为 3。即 B+ 树的高度 =page level+1；

## B+树的叶子节点之间是单链还是双链，页与页之间，页内部呢

　　B+ 树中叶子节点中的数据是通过双向链表连接的。各个页之间也是通过双向链表连接的。叶子节点为，存储了关键字和行记录，在节点内部（也就是页结构的内部）记录之间是一个单向的链表

## 索引还有啥结构（哈希）为什么不用？

1. 哈希索引不是按照索引值顺序存储的，**无法用于排序**
2. 所以哈希索引**不支持部分索引**匹配查找，因为哈希索引是使用索引列中全部内容来计算哈希值的

3. 哈希索引只支持等值比较查询，**不支持范围查询**
4. 出现很多哈希冲突时要遍历所有行指针了，并且**维护操作的代价也会很高**，因为要遍历对应哈希值的链表中的每一行

　　Innodb引擎有一个特殊的功能——自适应哈希索引。就是有些索引值使用非常频繁的话，那么会在B+树索引之上在创建一个哈希索引。

## 为什么不用红黑树

　　B树是多路树，红黑树是二叉树！红黑树一个节点只能存出一个值，B树一个节点可以存储多个值，红黑树的深度会更大,定位时 红黑树的查找次数会大一些。

## 联合索引的结构 

![img](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img6f1e7b3fa559bc84a37327dfd179701f.png)

　　对于联合索引来说只不过比单值索引多了几列，而这些索引列全都出现在索引树上。对于联合索引，存储引擎会首先根据第一个索引列排序；如果第一列相等则再根据第二列排序，依次类推就构成了索引树。

## B+ 树是什么结构，B+ 树的插入过程？

下面以一棵 5 阶 B+ 树的插入过程，5 阶 B+ 树的节点最少 2 个 key，最多 4 个 key。

1. 当树为空树，插入 5。只有一个关键字，叫根节点或叶子节点都是一样的。

   ![](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232856515-1989097703.png)

2. 再次插入 3 个索引关键字，8，10，15。当前节点 key 存满了，如果再插入当前节点就要进行分裂。

   ![clip_image043](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232901391-1401289774.png)

3. 再插入关键字 16。可以看到，这个 B+ 树，现在满足分裂条件了。所以要进行节点分裂。

   ![clip_image045](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232905559-1698012761.png)

   插入 16 后超过了关键字的个数限制，所以要进行分裂。在叶子结点分裂时，假设分裂出来的左结点有 2 个记录，右节点有 3 个记录，中间 key 成为索引结点中的 key，会成为一个父节点，分裂后的两个节点都指向了父结点（根结点）。

   ![clip_image047](https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimg834468-20180406232909712-1807724284.png)

4. 假设我们再插入 17 这个关键字。注意，节点都是有序的。

   ![clip_image049](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232913379-576202883.png)

5. 然后，我们再插入一个 18。

   ![clip_image051](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232917817-1240573630.png)

   此时，我们发现右边的节点，满足了分裂条件，所有我们要进行分裂。当前结点的关键字个数大于5，进行分裂。分裂成两个结点，左结点2个记录，右结点3个记录，关键字16进位到父结点（索引类型）中，将当前结点的指针指向父结点。

   ![clip_image053](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232921679-618565224.png)

6. 插入若干数据后

   ![clip_image055](https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimg834468-20180406232926305-812650003.png)

   

   接着在上图中插入7，结果如下图所示

   ![clip_image057](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img834468-20180406232935105-1001982143.png)

   当前结点的关键字个数超过4，需要分裂。左结点2个记录，右结点3个记录。分裂后关键字7进入到父结点中，将当前结点的指针指向父结点，结果如下图所示。

   ![clip_image059](https://images2018.cnblogs.com/blog/834468/201804/834468-20180406232940557-1204742223.png)

   当前结点的关键字个数超过4，需要继续分裂。左结点2个关键字，右结点2个关键字，关键字16进入到父结点中，将当前结点指向父结点，结果如下图所示。

   ![clip_image061](https://images2018.cnblogs.com/blog/834468/201804/834468-20180406232945267-543224744.png)

   当前结点的关键字个数满足条件，插入结束。

　　以此类推，当插入的数据满足节点分裂时就会进行分裂。但是分裂后，关键字都是有序的。

　　根据这个插入过程，一个 B+ 树的高度，是有一个节点能存储多少关键字，也就是索引决定的。通常，一棵 [MySQL](https://cloud.tencent.com/product/cdb?from=10680) 的 B+ 树，树高为 3 的话，大约能存上亿条。树的高度太高的话，查询效率会大打折扣！

　　假如查询A in (), MySQL是针对N个值分别查一次索引,还是有更好的操作？ MySQL IN的原理，如何优化

# 事务

## MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？

SQL 标准定义的四个隔离级别为：

1. read uncommited ：读到未提交数据。
2. read committed：脏读，不可重复读。
3. repeatable read：可重读。
4. serializable ：串行化。

# 锁

## MVCC的原理、回滚段

回滚段用于存储undoLog，undoLog中记录的就是多版本数据，用于快照读和事务失败后的数据回滚,MySQL在合适的时机会清理undoLog。

## 自增锁、共享锁、排他锁、意向锁、插入意向锁、记录锁、间隙锁是什么

### 间隙锁

间隙锁基于非唯一索引，它锁定一段范围内的索引记录。

```mysql
SELECT * FROM table WHERE id BETWEN 1 AND 10 FOR UPDATE;
```

即所有在`（1，10）`区间内的记录行都会被锁住，所有id 为 2、3、4、5、6、7、8、9 的数据行的插入会被阻塞，但是 1 和 10 两条记录行并不会被锁住。

### 临建锁

临键锁存在于非唯一索引中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的间隙锁，锁定一段左开右闭的索引区间。<u>通过临建锁可以解决幻读的问题</u>。

> 需要强调的一点是，InnoDB 中行级锁是基于索引实现的，临键锁只与非唯一索引列有关，在唯一索引列（包括主键列）上不存在临键锁。

假设有如下表：
**MySql**，**InnoDB**，**Repeatable-Read**：table(id PK, age KEY, name)

| id   | age  | name   |
| ---- | ---- | ------ |
| 1    | 10   | Lee    |
| 3    | 24   | Soraka |
| 5    | 32   | Zed    |
| 7    | 45   | Talon  |

以24为例，当在一个事务对age=24进行操作时，会自动获取（10，32]这一段临键锁。

### 插入意向锁

插入意向锁是一种特殊的间隙锁。插入意向锁在锁定区间相同但记录行本身不冲突的情况下互不排斥。

**MySql**，**InnoDB**，**Repeatable-Read**：users(id PK, name, age KEY)

| id   | name | age  |
| ---- | ---- | ---- |
| 1    | Mike | 10   |
| 2    | Jone | 20   |
| 3    | Tony | 30   |

首先`事务 A` 插入了一行数据，并且没有 `commit`：

```mysql
INSERT INTO users SELECT 4, 'Bill', 15;
```

随后`事务 B` 试图插入一行数据：

```mysql
INSERT INTO users SELECT 5, 'Louis', 16;
```

1. 使用插入意向锁与记录锁。
2. 事务A不会阻塞事务B。

### 意向锁

　　需要强调一下，意向锁是一种`不与行级锁冲突表级锁`，这一点非常重要。意向锁分为两种：

- 意向共享锁

  （intention shared lock, IS）：事务有意向对表中的某些行加共享锁（S锁）

  ```mysql
  -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
  SELECT column FROM table ... LOCK IN SHARE MODE;
  ```

- 意向排他锁

  （intention exclusive lock, IX）：事务有意向对表中的某些行加排他锁（X锁）

  ```mysql
  -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
  SELECT column FROM table ... FOR UPDATE;
  ```

　　另外，意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享/排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。

**意向锁的兼容互斥性**

意向锁是怎么解决这个问题的呢？首先，我们需要知道意向锁之间的兼容互斥性：

|                      | 意向共享锁（IS） | 意向排他锁（IX） |
| -------------------- | ---------------- | ---------------- |
| **意向共享锁（IS）** | 兼容             | 兼容             |
| **意向排他锁（IX）** | 兼容             | 兼容             |

即**意向锁之间是互相兼容的**，emmm......那你存在的意义是啥？

虽然意向锁和自家兄弟互相兼容，但是它会与普通的**排他 / 共享锁**互斥：

|                 | 意向共享锁（IS） | 意向排他锁（IX） |
| --------------- | ---------------- | ---------------- |
| **共享锁（S）** | 兼容             | 互斥             |
| **排他锁（X）** | 互斥             | 互斥             |

**注意：这里的排他 / 共享锁指的都是表锁！！！意向锁不会与行级的共享 / 排他锁互斥！！！**

　　设想这样一张 `users` 表： **MySql**，**InnoDB**，**Repeatable-Read**：users（id PK，name）

| id   | name      |
| ---- | --------- |
| 1    | ROADHOG   |
| 2    | Reinhardt |
| 3    | Tracer    |
| 4    | Genji     |
| 5    | Hanzo     |
| 6    | Mccree    |

　　事务A先获取了某一行的排他锁，并未提交：

```mysql
SELECT * FROM users WHERE id = 6 FOR UPDATE;
```

1. 事务A获取了users表上的意向排他锁。
2. 事务A获取了id为6的数据行上的排他锁。

　　之后事务B想要获取users表的共享锁：

```mysql
LOCK TABLES users READ;
```

1. 事务B检测到事务A持有users表的**意向排他锁**。
2. 事务B对users表的加锁请求被阻塞（排斥）。

　　最后事务C也想获取users表中某一行的**排他锁**：

```mysql
SELECT * FROM users WHERE id = 5 FOR UPDATE;
```

1. 事务C申请`users`表的**意向排他锁**。
2. 事务C检测到事务Ａ持有`users`表的**意向排他锁**。
3. 因为意向锁之间并不互斥，所以事务C获取到了users表的**意向排他锁**。
4. 因为id为5的数据行上不存在任何**排他锁**，最终事务C成功获取到了该数据行上的**排他锁**。

### 自增锁

自增锁是一种比较特殊的**表级锁**。并且在事务向包含了 `AUTO_INCREMENT` 列的表中新增数据时就会去持有自增锁，假设事务 A 正在做这个操作，如果另一个事务 B 尝试执行 `INSERT`语句，事务 B 会被阻塞住，直到事务 A 释放自增锁。

其实在 InnoDB 中，把锁的行为叫做**锁模式**可能更加准确，那具体有哪些锁模式呢，如下：

- 传统模式（Traditional）
- 连续模式（Consecutive）
- 交叉模式（Interleaved）

分别对应配置项 `innodb_autoinc_lock_mode`  的值0、1、2。

mysql8.0之前默认是连续模式。在锁模式处于连续模式下时，如果 `INSERT` 语句能够提前确定插入的数据量，则可以不用获取自增锁，举个例子，像 `INSERT INTO` 这种简单的、能提前确认数量的新增语句，就不会使用自增锁，这个很好理解，在自增值上，我可以直接把这个 `INSERT` 语句所需要的空间流出来，就可以继续执行下一个语句了。

> 当然，这里其实并非什么锁也不用。在实际分配 ID 的过程中，InnoDB 会使用较为轻量级的 mutex 锁，来防止 ID 重复分配，ID 一旦分配好了，mutex 锁就会被释放。

**交叉模式缺陷**

要了解缺陷是什么，还得先了解一下 MySQL 的 Binlog。Binlog 一般用于 MySQL 的**数据复制**，通俗一点就是用于主从同步。在 MySQL 中 Binlog 的格式有 3 种，分别是：

- **Statement** 基于语句，只记录对数据做了修改的SQL语句，能够有效的减少binlog的数据量，提高读取、基于binlog重放的性能
- **Row** 只记录被修改的行，所以Row记录的binlog日志量一般来说会比Statement格式要多。基于Row的binlog日志非常完整、清晰，记录了所有数据的变动，但是缺点是可能会非常多，例如一条`update`语句，有可能是所有的数据都有修改；再例如`alter table`之类的，修改了某个字段，同样的每条记录都有改动。
- **Mixed** Statement和Row的结合，怎么个结合法呢。例如像`alter table`之类的对表结构的修改，采用Statement格式。其余的对数据的修改例如`update`和`delete`采用Row格式进行记录。

如果 MySQL 采用的格式为 `Statement` ，那么 MySQL 的主从同步实际上同步的就是一条一条的 SQL 语句。如果此时我们采用了交叉模式，那么并发情况下 `INSERT` 语句的执行顺序就无法得到保障。

可能你还没看出问题在哪儿，`INSERT` 同时交叉执行，并且 `AUTO_INCREMENT` 交叉分配将会直接导致主从之间同行的数据**主键 ID 不同**。而这对主从同步来说是灾难性的。

在业务中你有一个需要执行 几十秒 的脚本，脚本中不停的调用多次 `INSERT`，这时就问你这个问题，在这几十秒里，会阻塞其他的用户使用对应的功能吗？

### 共享锁

在查询语句后面增加`LOCK IN SHARE MODE`，Mysql会对**查询结果中的每行**都加共享锁。

```sql
SELECT ... LOCK IN SHARE MODE;
```

当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。

### 排他锁

在查询语句后面增加`FOR UPDATE`，Mysql会对查询结果中的每行都加排他锁

```sql
SELECT ... FOR UPDATE;
```

当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请排他锁，否则会被阻塞。

MySql的InnoDB引擎来说，对于`insert`、`update`、`delete`等操作。会自动给涉及的数据加排他锁；

对于一般的`select`语句，InnoDB不会加任何锁，事务可以通过以下语句给显示加共享锁或排他锁。

共享锁：`SELECT ... LOCK IN SHARE MODE;`

排他锁：`SELECT ... FOR UPDATE;`

### 记录锁

对表中的行记录加锁，叫做记录锁，简称行锁。可以使用`sql`语句`select ... for update`来开启锁，`select`语句必须为精准匹配（=），不能为范围匹配，且匹配列字段必须为唯一索引或者主键列。也可以通过对查询条件为主键索引或唯一索引的数据行进行`UPDATE`操作来添加记录锁。

> 记录锁存在于包括主键索引在内的唯一索引中，锁定单条索引记录。

## 事务在提交之前数据存在哪里？或者可以这么问MySQL如何保证redo log和binlog的数据是一致的？

　　MySQL/InnoDB为例，提交（commit）前当然是在内存中。在事务执行过程中，修改数据时会不断产生redo日志（write ahead log），这些日志会写入redo日志文件。

　　在MySQL内部，在事务提交时利用两阶段提交(内部XA的两阶段提交)保证binlog和redo log的一致性问题：

　　首先如果此时SQL已经成功执行(不用undo了)。此阶段InnoDB会写事务的redo log，将Redo Log写入文件，并刷入磁盘，记录上内部XA事务的ID，同时将Redo Log状态设置为Prepare。Redo Log写入成功后，再将Binlog同样刷入磁盘，记录XA事务ID。

　　接着commit，这个阶段分成两个步骤。第一步写binlog（先调用`write()`将binlog内存日志数据写入文件系统缓存，再调用`fsync()`将binlog文件系统缓存日志数据永久写入磁盘）；第二步完成事务的提交（commit），此时在redo log中记录此事务的提交日志，也就是增加commit 标签(并且当事务提交时会调用fsync对redo log进行刷盘；这是默认情况下的策略)。

> 需要注意的是，<u>在这个过程中是以第二阶段中**binlog的写入与否**作为事务是否成功提交的标志。</u>

　　通过上述MySQL内部XA的两阶段提交就可以解决binlog和redo log的一致性问题。数据库在上述任何阶段crash，主从库都不会产生不一致的错误。

此时的崩溃恢复过程如下：

　　如果数据库在记录此事务的binlog之前和过程中发生crash。数据库在恢复后认为此事务并没有成功提交，则会回滚此事务的操作(没有commit标签)。与此同时，因为在binlog中也没有此事务的记录，所以从库也不会有此事务的数据修改。

　　如果数据库在记录此事务的binlog之后发生crash。此时，即使是redo log中还没有记录此事务的commit 标签，数据库在恢复后也会认为此事务提交成功。也就是说，<u>binlog中记录的事务，在恢复时都会被认为是已提交事务，会在redo log中重新写入commit标志，并完成此事务的重做</u>（主库中有此事务的数据修改）。与此同时，因为在binlog中已3经有了此事务的记录，所有从库也会有此事务的数据修改。

> **undolog保存了事务发生之前的数据的一个版本。**

## 说一下binlog，undolog， redolog

* undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC；
* redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；
* binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制；

1. **在MySQL中，binlog记录了数据库系统所有的更新操作，主要是用来实现数据恢复和主从复制的。一方面，主从配置的MySQL集群可以利用binlog将主库中的更新操作传递到从库中，以此来实现主从数据的一致性；另一方面，数据库还可以利用binlog来进行数据的恢复。**

   比如"把id='B' 修改为id = ‘B2’。binlog会写入指定大小的物理文件中，是追加写入的，当前文件写满则会创建新的文件写入。 产生:事务提交的时候，一次性将事务中的sql语句，按照一定的格式记录到binlog中。

2. **redo log是用来实现事务的持久性，即当事务在提交时，需要先将该事务的所有操作日志写到磁盘上的 redo log file进行持久化，这也就是我们常说的 Write Ahead Log 策略。有了redo log，在数据库发生宕机时，即使内存中的数据还没来得及持久化到磁盘上，我们也可以通过redo log完成数据的恢复，这样就避免了数据的丢失。**

   redoLog 是重做日志文件是记录数据修改之后的值，用于持久化到磁盘中。redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。由引擎层的InnoDB引擎实现，是物理日志，记录的是物理数据页修改的信息，比如“某个数据页上内容发生了哪些改动”。当一条数据需要更新时，InnoDB会先将数据更新，然后记录redoLog 在内存中，然后找个时间将redoLog的操作执行到磁盘上的文件上。不管是否提交成功我都记录，你要是回滚了，那我连回滚的修改也记录。它确保了事务的持久性。 

3. **undo log属于逻辑日志，undo log回滚日志保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也就是非锁定读。**

   undolog 也就是我们常说的回滚日志文件，主要用于事务中执行失败，进行回滚，以及MVCC中对于数据历史版本的查看。由引擎层的InnoDB引擎实现，是逻辑日志，记录数据修改被修改前的值，比如"把id='B' 修改为id = 'B2' ，那么undo日志就会用来存放id ='B'的记录”。当一条数据需要更新前，会先把修改前的记录存储在undolog中，如果这个修改出现异常，则会使用undo日志来实现回滚操作，保证事务的一致性。当事务提交之后，undo log并不能立马被删除，而是会被放到待清理链表中，待判断没有事物用到该版本的信息时才可以清理相应undolog。它保存了事务发生之前的数据的一个版本，用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读。 

## MySQL如何保证redo log和binlog的数据是一致的？

![image](D:/%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9C%E4%BA%91/pictures/a66c154c1bc51e071dd2cc8c1d6ca6a3.png)

　　在MySQL内部，在事务提交时利用两阶段提交(内部XA的两阶段提交)保证binlog和redo log的一致性问题：

**第一阶段：**<u>Prepare阶段。此时SQL已经成功执行，并生成事务ID(xid)信息及redo和undo的内存日志。此阶段InnoDB会写事务的redo log，但要注意的是，此时redo log只是记录了事务的所有操作日志，并没有记录提交（commit）日志，因此事务此时的状态为Prepare。此阶段对binlog不会有任何操作。</u>

**第二阶段：**<u>commit 阶段，这个阶段分成两个步骤。第一步写binlog</u>（先调用write()将binlog内存日志数据写入文件系统缓存，再调用fsync()将binlog文件系统缓存日志数据永久写入磁盘）；<u>第二步完成事务的提交（commit），此时在redo log中记录此事务的提交日志</u>（增加commit 标签）。

　　可以看出，此过程中是先写redo log再写binlog的。但需要注意的是，在第一阶段并没有记录完整的redo log（不包含事务的commit标签），而是在第二阶段记录完binlog后再写入redo log的commit 标签。还要注意的是，<u>在这个过程中是以第二阶段中binlog的写入与否作为事务是否成功提交的标志。</u>

　　通过上述MySQL内部XA的两阶段提交就可以解决binlog和redo log的一致性问题。数据库在上述任何阶段crash，主从库都不会产生不一致的错误。

此时的崩溃恢复过程如下：

　　如果数据库在记录此事务的binlog之前和过程中发生crash。数据库在恢复后认为此事务并没有成功提交，则会回滚此事务的操作(没有commit标签)。与此同时，因为在binlog中也没有此事务的记录，所以从库也不会有此事务的数据修改。

　　如果数据库在记录此事务的binlog之后发生crash。此时，即使是redo log中还没有记录此事务的commit 标签，数据库在恢复后也会认为此事务提交成功（因为在上述两阶段过程中，binlog写入成功就认为事务成功提交了）。它会扫描最后一个binlog文件，并提取其中的事务ID（xid），InnoDB会将那些状态为Prepare的事务（redo log没有记录commit 标签）的xid和Binlog中提取的xid做比较，如果在Binlog中存在，则提交该事务，否则回滚该事务。这也就是说，<u>binlog中记录的事务，在恢复时都会被认为是已提交事务，会在redo log中重新写入commit标志，并完成此事务的重做</u>（主库中有此事务的数据修改）。与此同时，因为在binlog中已3经有了此事务的记录，所有从库也会有此事务的数据修改。

## 如果一个sql执行很慢，你能分析一下原因吗？ 

1. 大多数情况下很正常，偶尔很慢，则有如下原因
   1. 数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。
   2. 执行的时候，遇到锁，如表锁、行锁。

2. 这条 SQL 语句一直执行的很慢，则有如下原因。
   1. 没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。
   2. 数据库选错了索引。

#### 为什么数据库会选错了索引

在进行慢SQL分析的时候，有时候我们会发现explain的扫描行数和慢日志中的行数相差很大，那explain中的rows这个扫描行数是怎么判断的？

其实MySQL在真正开始执行语句之前，并不能精确的满足这个条件的记录有多少行，而只能根据统计信息来估算记录数。

这个统计信息就是索引的“区分度”，显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality)。也就是说，这个基数越高，索引的区分度越好。

基数估计错了

## MVCC是什么，起什么作用？ 

MVCC，多版本并发控制，是MySQL中基于乐观锁理论实现隔离级别的方式，用于可重复读取隔离级别的实现。在MySQL中，会在表中每一条数据后面添加两个字段：最近修改该行数据的事务ID，指向该行（undolog表中）回滚段的指针。当前事务只会读取当前版本号之前的数据。

Read View判断行的可见性，创建一个新事务时，copy一份当前系统中的活跃事务列表。意思是，当前不应该被本事务看到的其他事务id列表。


binlog 日志和 redolog 日志清楚吗？ 

说了两个日志的作用以及两阶段提交 mysql 有那些存储引擎，有哪些区别 

## MySQL的行锁的实现原理

　　<u>InnoDB行锁是通过给索引上的索引项加锁来实现的</u>，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。**InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！**在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。

## 锁升级

　　锁升级（Lock Escalation）是指将当前锁的粒度加大，锁粒度：行锁 < 页锁 < 表锁。

　　在以下情况可能发生锁升级：

- 由一句单独的SQL语句在一个对象上持有的锁的数量超过了阈值，默认这个阈值为**5000**。如果是不同对象，则不会发生锁升级；
- 锁资源占用的内存超过了激活内存的40%时就会发生锁升级。

InnoDB根据每个事务访问的每个页对锁进行管理，采用位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

### Mysql的一条语句执行过程

先是连接器，连接成功，如果使用了缓存就还要查询缓存，缓存内能查询到结果后面就不执行了，直接返回。没有命中缓存就依次执行分析器、优化器、执行器。执行器的步骤是这样的，从磁盘文件中找到对应查询条件的整页数据加载到buffer pool中，写入更新数据的旧值到undo日志文件中，更新buffer pool内加载的数据，写redo日志，准备提交事务binlog日志到磁盘中，写入commit标记到redo日志文件里，提交事务完成，buffer pool随机写入磁盘

如果有一台新机器要加到从机里，怎么个过程。 

乐观锁与悲观锁的区别？ 

binlog 日志是 master 推的还是 salve 来拉的？

 （2）当使用or关键字时，or语句前后没有同时使用索引或当or关键字左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效。 （4）数据类型出现隐式转化。如某个索引字段的数据类型为varchar，查询内容为123，如不加引号的话可能会自动转换为int型，使索引无效，产生全表扫描。  5、MySQL 主从同步怎么搞的？分哪几个过程？如果有一台新机器要加到从机里，怎么个过程。 7、binlog 日志是 master 推的还是 salve 来拉的？

mysql innodb下，能不能不设置主键？主键可以为空吗？可以允许几个？主键跟非主键的区别？索引存储形式？ 联合索引失效问题？ mysql mvcc 双写机制？当前读和快照读？事务隔离级别？线上sql优化经验？  跨库聚合怎么实现？分页？第几页？下一页？ 分库分表 聚合查询 limit怎么实现 top的实现 不停机扩容？分表避免冷热？不停机扩库？不停机扩表？跨库事务？ 分库分表为什么这么设计？数据增长怎么做？怎么扩容？数据不均匀怎么办？冷热数据怎么分离？聚合怎么做？跨库聚合怎么做，查询怎么做？跨库分页怎么做？ mysql 线上的组群模式？一主多从？为什么这样？强一致性如何保证？为了解决读写分离吗？是为了一主多备吗？主库crash掉怎么办？从库呢？出现过事务不一致性吗？为什么？怎么解决的？ 访问请求暴增怎么做？怎么缓解压力？MySQL做过哪些优化？覆盖索引？limit两个参数区别？MySQL分页优化的其他方法  SQL调优你会怎么做？索引的数据结构？MYSQL的事务有哪些？比较常用的是哪些？ 关键SQL优化怎么优化的？为什么性能不好？主键必须有吗？ MVCC？版本号怎么变化的？更新的数据的时候怎么确定版本的？幻读怎么解决的？ 一个SQL怎么走的索引？MYSQL会怎么选的？MySQL有哪几种日志？为什么MySQL要写到redo log buff内存？

mysql 自动提交事物：autocommit=20，binlog记录 5、mysql几种锁，区别？ 3种，行(单行)，表(单表)，页(一组数据)。 6、100万页数据，分页查询：从100万跳转到100万01页最快，还是直接输入100万最快，为什么？ 7、如何使用避免最小粒度的行锁：参数？

订阅分库分表的 Binlog 怎么订阅？ 6、分库分表的数据源中假如存在主键冲突要怎么解决？ 7、怎么保证下游对 Binlog 的消费顺序？

数据库，MVCC的实现讲一下？

多版本体现在哪里实现上是怎样的？

怎么解决不可重复读的问题？ 

MySQL 的主从同步机制？

幻读是什么？ 

加 limit， 执行计划，是否有排序，是否可以使用覆盖索引解决排序，不要将自增主键给外部

## 数据库中是否会出现死锁？数据库中的死锁避免是否可用刚才说的方法来避免？

**死锁的四个必要条件？如何避免死锁？如何检测死锁？**

　　<u>如何避免死锁：</u>

1. 预防死锁发生：通过对死锁产生的**四个必要条件**进行限制
2. **检测与拆除死锁**：这种方式使允许死锁发生，检测死锁产生，然后解除死锁
3. 动态避免：<u>在资源分配过程中，确保资源请求批准后系统不会进入死锁或潜在的死锁状态</u>。如**银行家算法**。银行家算法就是设法保证系统动态分配资源后不进入不安全状态，以避免可能产生的死锁。即没当进程提出资源请求且系统的资源能够满足该请求时，系统将判断满足此次资源请求后系统状态是否安全，如果判断结果为安全，则给该进程分配资源，否则不分配资源，申请资源的进程将阻塞

　　<u>如何检测死锁：</u>

1. 有四个参数：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

　　具体是这么做的

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

<u>数据库死锁的避免</u>

1. **保持事务简短**并在一个批处理中
   在同一数据库中并发执行多个需要长时间运行的事务时通常发生死锁。事务运行时间越长，其持有排它锁或更新锁的时间也就越长，从而堵塞了其它活动并可能导致死锁。<u>保持事务在一个批处理中</u>，可以最小化事务的网络通信往返量，减少完成事务可能的延迟并释放锁
2. **使用低隔离级别**
   确定事务是否能在更低的隔离级别上运行。执行提交读允许事务读取另一个事务已读取（未修改）的数据，而不必等待第一个事务完成。使用较低的隔离级别（例如提交读）而不使用较高的隔离级别（例如可串行读）可以缩短持有共享锁的时间，从而降低了锁定争夺（比如这次的S NK和X IK 是InnoDB引擎Repeatable Read级别才有的）

　　<u>数据库死锁的出现</u>

1. 事务之间对资源访问顺序的交替

   一个用户A 访问表A（锁住了表A），然后又访问表B；另一个用户B 访问表B（锁住了表B），然后企图访问表A；这时用户A由于用户B已经锁住表B，它必须等待用户B释放表B才能继续，同样用户B要等用户A释放表A才能继续，这就死锁就产生了。

   <u>降低锁的粒度，不要使用表锁。避免大事务，可以拆分成多个小事务，因为大事务耗时长，与其他事务发生的概率就大。调整程序，对数据库进行多表操作时，尽量按照相同的顺序进行处理并同时锁定连个资源。</u>

2. 并发修改同一记录 

   用户A查询一条纪录，然后修改该条纪录；这时用户B修改该条纪录，这时用户A的事务里锁的性质由查询的共享锁企图上升到独占锁，而<u>用户B里的独占锁由于A有共享锁存在所以必须等A释放掉共享锁，而A由于B的独占锁而无法上升的独占锁也就不可能释放共享锁</u>，于是出现了死锁。 

   <u>使用乐观锁MVCC。</u>为数据增加一个版本标识。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。乐观锁机制避免了长事务中的数据库加锁开销，大大提升了大并发量下的系统整体性能表现。
   <u>使用悲观锁进行控制。从操作员读出数据、开始修改直至提交修改结果的全过程，数据库记录始终处于加锁状态</u>



1. > 通过命令 `show engine Innodb status` 查看事务日志

2. 如果在事务中执行了一条没有命中索引的update语句，则执行全表扫描，把行级锁上升为表级锁，多个这样的事务执行后，就很容易产生死锁和阻塞。类似的情况还有当表中的数据量非常庞大而索引建的过少或不合适的时候，使得经常发生全表扫描，最终应用系统会越来越慢，最终发生阻塞或死锁。

   <u>使用"explain"对SQL语句进行分析，对于有全表扫描的SQL语句，建立相应的索引进行优化。</u>

## 如果进程一次锁住数据库中的多条记录来避免死锁，会带来什么问题？你觉得应该怎样解 决这个问题？

在这我回答了乐观锁，然后回答了乐观锁的实现原理。 

## 如果数据库中的确发生了死锁，应该怎么解决？

- 资源剥夺法。剥夺陷于死锁的进程所占用的资源，但并不撤销此进程，直至死锁解除。

- 进程回退法。**根据数据库的检查点让所有的进程回退到足以解除死锁**。`rollback`

- 进程撤销法。**kill陷入死锁的进程，回收其资源并重新分配，直至死锁解除**

  1：查看当前的事务

  ``` mysql 
  SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;
  ```

  2：查看当前锁定的事务

  ``` mysql 
  SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 
  ```

  3：查看当前等锁的事务

  ``` mysql 
  SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;
  ```

  ```mysql
  kill [ trx_mysql_thread_id ]
  ```

- 系统重启法。结束所有进程的执行并重新启动操作系统。这种方法很简单，但先前的工作全部作废，损失很大。**重启mysql服务器**

## 添加索引会锁表

　　但是MySQL 在 5.6 版本已经优化了这个问题。实现不锁表增加字段和索引非常简单：

``` mysql
ALTER TABLE member ADD user_from smallint(1) NOT NULL, ALGORITHM=INPLACE, LOCK=NONE
```

> ALGORITHM表示算法：default默认（根据具体操作类型自动选择），inplace（不影响DML），copy创建临时表（锁表。禁止读写，进行rename），INSTANT只修改元数据（8.0新增，在修改名字等极少数情况可用）
>
> LOCK表示是否锁表：default默认，none，shared共享锁，exclusive

　　<u>只要不改主键，就不会锁表。</u>

　　然后**在慢查询过程中，如果修改了索引，那么会进入死锁的状态**。

　　总之，alter table的语句是很危险的(其实他的危险其实是未提交事物或者长事务导致的)，在操作之前最好确认对要操作的表没有任何进行中的操作、没有未提交事务、也没有显式事务中的报错语句。如果有alter table的维护任务，在无人监管的时候运行，最好通过lock_wait_timeout设置好超时时间，避免长时间的metedata锁等待。

# 使用

### heap表

　　HEAP表是访问数据速度最快的MySQL表，他使用保存在内存中的散列索引。但如果MySQL或者服务器重新启动，表中数据将会丢失，但是结构不会丢失。创建内存表非常的简单，只需注明 ENGINE= MEMORY 即可:`CREATE TABLE `tablename` ( `columnName` varchar(256) NOT NUL) ENGINE=MEMORY DEFAULT CHARSET=latin1 MAX_ROWS=100000000;`注意： 当内存表中的数据大于max_heap_table_size设定的容量大小时，mysql会转换超出的数据存储到磁盘上，因此这是性能就大打折扣了，所 以我们还需要根据我们的实际情况调整max_heap_table_size，另外在建表语句中还可以通过MAX_ROWS来控制表的记录数

### int 存到数据库里面一般你都用什么类型

* **bigint** 从 -2^63 (-9223372036854775808) 到 2^63-1 (9223372036854775807) 的整型数字
* **int** 从 -2^31 (-2,147,483,648) 到 2^31 – 1 (2,147,483,647) 的整型数字

　　其实当我们在选择使用int的类型的时候，不论是int(3)还是int(11)，它在数据库里面存储的都是4个字节的长度，在使用int(3)的时候如果你输入的是10，会默认给你存储位010,也就是说这个3代表的是默认的一个长度，当你不足3位时，会帮你不全，当你超过3位时，就没有任何的影响。

### varchar（35）的含义；中文在varchar中占几个字符；编码有哪些

  * **4.0版本以下**，varchar(35)，指的是**35字节**，如果存放UTF8汉字时，只能存12个（每个汉字3字节）
  * **5.0版本以上**，varchar(35)，指的是**35字符**，无论存放的是数字、字母还是UTF8汉字（每个汉字3字节），都可以存放35个。

> UTF8编码中一个汉字（包括数字）占用3个字节=一个字符
>
> GBK编码中一个汉字（包括数字）占用2个字节

　　假设VARCHAR(100)与VARCHAR(200)类型，实际存90个字符，它不会对存储端产生影响（就是实际占用硬盘是一样的）。但是，它确实<u>会对查询产生影响，因为当MySql创建临时表（SORT，ORDER等）时，VARCHAR会转换为CHAR，转换后的CHAR的长度就是varchar的长度</u>，在内存中的空间就变大了，在排序、统计时候需要扫描的就越多，时间就越久。

**nvarchar和varchar**

　　从存储方式上，nvarchar是按【字符】存储的，而 varchar是按【字节】存储的；

　　从存储量上考虑， varchar 比较节省空间，因为存储大小为字节的实际长度，而 nvarchar是双字节存储；

　　在使用上，如果存储内容都是英文字符而没有汉字等其他语言符号，建议使用varchar；含有汉字的使用nvarchar，因为nvarchar是使用Unicode编码，即统一的字符编码标准，会减少乱码的出现几率；

　　如果你做的项目可能涉及不同语言之间的转换，建议用nvarchar。

* **超键**(super key):在关系中能唯一标识元组的属性集称为关系模式的超键。比如身份证是超键、姓名是超键、(姓名，性别)是超键、(姓名，性别，年龄)是超键
* **候选键**(candidate key):不含有多余属性的超键称为候选键。超键里面的身份证、姓名是候选键
* **主键**(primary key):用户选作元组标识的一个候选键程序主键。

### 范式

1. 1NF 指的是数据库表中的任何属性都是原子性的，不可再分

2. 2NF 指的数据表里的非主属性都要和这个数据表的候选键有完全依赖关系

   对于**（学号，课名） → 姓名，有 学号 → 姓名，存在非主属性 姓名 对码（学号，课名）的部分函数依赖**

3. 3NF 在满足 2NF 的同时，对任何非主属性都不传递依赖于候选键

   **学号 → 系名，同时 系名 → 系主任**，所以存在非主属性系主任对于学号的传递函数依赖

　　Mysql的驱动程序主要帮助编程语言与 MySQL 服务端进行通信，如果连接、关闭、传输指令与数据等

### 现在使用了PostgreSQL， PostgreSQL与MySQL相比的优点，

1. 首先是强类型的，
2. PostgreSQL 的稳定性更强
3. <u>在高并发读写，负载逼近极限下，PG的性能指标仍可以维持双曲线甚至对数曲线，到顶峰之后不再下降，而 MySQL 明显出现一个波峰后下滑</u>
4. PG有大量字典、数组、bitmap 等数据类型，相比之下mysql就差很多
5. 对于WEB应用来说，复制的特性很重要，mysql到现在也是异步复制，pgsql可以做到同步，异步，半同步复制。还有mysql的同步是基于binlog复制，类似oracle golden gate,是基于stream的复制，做到同步很困难，这种方式更加适合异地复制，pgsql的复制基于wal，可以做到同步复制。同时，pgsql还提供stream复制。　

### explain 执行计划看过没有？其中 type 字段都有哪些值？分别代表什么？

　　type显示查询使用了何种类型。从最好到最差的连接类型依次为：

　　system，const，eq_ref，ref，fulltext，ref_or_null，index_merge，unique_subquery，index_subquery，range，index，ALL

除了all之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引。

- **system**。表中只有一行数据或者是空表，这是const类型的一个特例。且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者index。

- **const。**当主键索引或唯一索引的所有字段跟常量值比较时。

- eq_ref。多表join时，对于来自前面表的每一行，在当前表中只能找到一行。这可能是除了system和const之外最好的类型。当主键或唯一非NULL索引的所有字段都被用作join联接时会使用此类型。eq_ref可用于使用'='操作符作比较的索引列。比较的值可以是常量，也可以是使用在此表之前读取的表的列的表达式。

- **ref**。如果每次只匹配少数行，那就是比较好的一种，使用=或<=>，可以是左覆盖索引或非主键或非唯一键。

- **fulltext**。使用全文索引的时候是这个类型。要注意，**全文索引的优先级很高**，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引

- **ref_or_null**。跟ref类型类似，只是增加了null值的比较。

  `SELECT * FROM ref_table WHERE key_column=expr OR key_column IS NULL;`

- unique_subquery。用于where中的in形式子查询，子查询返回不重复值唯一值，可以完全替换子查询，效率更高。该类型替换了下面形式的IN子查询的ref： `value IN (SELECT primary_key FROM single_table WHERE some_expr)`

- index_subquery。该联接类型类似于unique_subquery。适用于非唯一索引，可以返回重复值。

- range。索引范围查询，常见于使用 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN()或者like等运算符的查询中。

- **index**。索引全表扫描，把索引从头到尾扫一遍。这里包含两种情况：
  一种是查询使用了覆盖索引，那么它只需要扫描索引就可以获得数据，这个效率要比全表扫描要快，因为索引通常比数据表小，而且还能避免二次查询**。在extra中显示Using index，反之，如果在索引上进行全表扫描，没有Using index的提示。**

- **all** 全表扫描，性能最差。

  1. 就算有主键索引什么的，select * from table 仍然是 all。
  2. 联合索引，and可以(调换顺序也是可以的)，or会失效。如果是两个独立的索引没问题

### explain执行计划有哪些字段? 除了type比较重要外还有哪些?  

　　table、type、possible_keys(可能使用到的索引)、key_len(使用到的索引长度)、Extra(额外的信息说明)

### 如何分析一条sql的执行，explain有哪些东西

　　type 表示 mysql 访问数据的方式，常见的有全表扫描（all）、遍历索引（index）、区间查询（range）、常量或等值查询（ref、eq_ref）、主键等值查询（const）、当表中只有一条记录时（system）。下面是效率从最好到最差的一个排序。

```javascript
system > const > eq_ref > ref > range > index > all
```

* key 表示查询过程实际会用到的索引名称。
* rows 表示查询过程中可能需要扫描的行数，这个数据不一定准确，是mysql 抽样统计的一个数据。
* Extra 表示一些额外的信息，通常会显示是否使用了索引，是否需要排序，是否会用到临时表等。

### mysql的主从复制详细过程。（大意了，学的时候，只整了原理和配置过程）

　　当有数据来写入到master主机时，数据发生改变，master会将修改写入到bin_log日志中，同时主服务器与从服务器之间会生成一个IO，从服务器会读到bin_log中的数据，会将其中的修改sql语句在执行一次，从而达到主服务器数据发生改变时，同步到从服务器完成主从复制。

### 数据库中左连接是怎么做的？

　　Oracle 和 MySQL 都使用了**嵌套循环**（Nested-Loop Join）的实现方式。嵌套循环算法，需要区分驱动表和被驱动表，先访问驱动表，筛选出结果集，然后将这个结果集作为循环的基础，访问被驱动表过滤出需要的数据。

* <u>索引嵌套循环INLJ</u>。A 的行数为 N，所以内循环个数没变也是 N，因为还是要对 N 行 A 数据进行比较。但是内循环次数被优化了。之前的 SNLJ 算法，因为没有索引，每个内循环要扫码一次 B 表。有了索引后，<u>不需要再全表扫描 B 表，而是进行 B 表的索引查询。最终查询和比较的次数大大降低。</u>
* <u>块嵌套循环BNLJ</u>。假设这里 A 为驱动表，B 为被驱动表。在外层循环扫描 A 中的所有记录。扫描的时候，会把需要进行 join 用到的列都缓存到 buffer 中。buffer 中的数据有一个特点，里面的记录不需要一条一条地取出来和 B 表进行比较，而是整个 buffer 和 B 表进行批量比较。如果我们把 buffer 的空间开得很大，可以容纳下 A 表的所有记录，那么 **B 表也只需要访问访问一次**。

### 说说如何优化连接操作？

- 用来进行 join 的字段要加**索引**，会触发 INLJ 算法，如果是主键的聚集索引，性能最优。
- 如果无法使用索引，那么注意调整 **join buffer 大小**，适当调大些。
- 小结果集驱动大结果集。**用数据量小的表去驱动数据量大的表，这样可以减少内循环个数**，也就是被驱动表的扫描次数。

### UUID作为主键对于索引写的影响/主键用uuid会有什么问题

**innodb 中的主键是聚集索引，会把相邻主键的数据安放在相邻的物理存储上。如果主键不是自增，而是随机的，那么频繁的插入会使 innodb 频繁地移动磁盘块，而影响写入性能。**

* 不容易被人看出规律（隐藏用户数量）, 散列好，做缓存字段更好处理，不用自增降低数据库消耗，也更适合做分布式系统主键，长度比 int 好，字符串做主键也不会出现 long 型导致前端 js 麻烦问题
* 缺点也就性能差点

### 为什么要用数据库连接池，几个参数介绍

DBCP，c3p0，druid

**因为建立一个数据库连接是一个非常耗时耗力的事，如果使用连接池，当我们需要连接数据库服务器的时候，只需去连接池中取出一条空闲的连接，而不是新建一条连接。这样我们就可以大大减少连接数据库的开销，从而提高了应用程序的性能。**

1. **maxActive** 连接池支持的最大连接数，这里取值为20，表示同时最多有20个数据库连接。一般把maxActive设置成可能的并发量就行了设 0 为没有限制。

2. **maxIdle** 连接池中最多可空闲maxIdle个连接 ，这里取值为20，表示即使没有数据库连接时依然可以保持20空闲的连接，而不被清除，随时处于待命状态。设 0 为没有限制。

3. **minIdle** 连接池中最小空闲连接数，当连接数少于此值时，连接池会创建连接来补充到该值的数量

4. **initialSize** 初始化连接数目 

5. **maxWait** 连接池中连接用完时,新的请求等待时间,毫秒，这里取值-1，表示无限等待，直到超时为止，也可取值9000，表示9秒后超时。超过时间会出错误信息

6. **removeAbandoned** 是否清除已经超过“removeAbandonedTimout”设置的无效连接。如果值为“true”则超过“removeAbandonedTimout”设置的无效连接将会被清除。设置此属性可以从那些没有合适关闭连接的程序中恢复数据库的连接。

7. **removeAbandonedTimeout** 活动连接的最大空闲时间,单位为秒 超过此时间的连接会被释放到连接池中,*针对未被close的活动连接*

8. **minEvictableIdleTimeMillis** 连接池中连接可空闲的时间,单位为毫秒 *针对连接池中的连接对象*

9. **timeBetweenEvictionRunsMillis** / **minEvictableIdleTimeMillis** 每timeBetweenEvictionRunsMillis毫秒秒检查一次连接池中空闲的连接,把空闲时间超过minEvictableIdleTimeMillis毫秒的连接断开,直到连接池中的连接数到minIdle为止.

### 数据库的 having 使用在哪个场景？

　　having语句是分组后过滤的条件，在group by之后使用，也就是如果要用having语句，必须要先有group by语句。　

　　group by的功能是分组聚合，将多条记录变成比较少的记录，而having的功能是由多变少之后，再变少的过程。**另外having后面可以跟多种运算形式，但是运算的结果只能是一个逻辑值（0或者非0的数值）。**

### 假如数据库某个字段是String类型，读的时候用int类型去接收会有什么问题？反过来呢？

　　把参数改成?partyid=565613848aaaa能正常查到565613848的数据，改成?partyid=aaaaa565613848就只能查到partyid=0的数据。mysql会从左到右开始读取 一旦遇到非数字则视作后面的所有字符值为0 无论后面是否有数字。

### 为什么数据量大的时候会出现慢sql？慢查询排查

　　分页查询方式会从数据库第一条记录开始扫描，所以越往后，查询速度越慢，而且查询的数据越多，也会拖慢总查询速度。使用子查询优化:这种方式先定位偏移位置的 id，然后往后查询，这种方式适用于 id 递增的情况。

``` mysql
-- 1327ms
select * from orders_history where type=8 andid >= (select id from orders_history where type=8 limit 100000,1) limit 100;
-- 3710ms
select * from orders_history where type=8 limit 100000,100;
```

### 分布式ID的特点

* 全局唯一性。不能出现有重复的ID标识，这是基本要求
* 递增性。确保生成ID对于用户或业务是递增的
* 高可用性。确保任何时候都能生成正确的ID
* 高性能。在高并发的环境下依然表现良好

### 分布式数据库id生成中间件

　　苍穹数据库ID是使用Twitter的雪花算法生成的。核心是long类型占用64个bit，通过移位计算出一个long类型的ID。在苍穹系统中，第1位作为正数标志，第2~41位作为时间戳数量单位毫秒，第42~54位作为机器ID数量，第55~64位作为每毫秒产生的序列号。

![图片](D:/%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9C%E4%BA%91/pictures/640)



### mysql为什么要有最左前缀原理 

### limit优化 

　　offset 偏大之后 limit 查找会变慢：**就算有主键索引，这样也是没有用到索引的！！！！！！**

``` mysql
select * from t limit 10000,10;
```

　　这句 SQL 的执行逻辑是

1. 从数据表中读取第N条数据添加到数据集中
2. 重复第一步直到 N = 10000 + 10
3. 根据 offset 抛弃前面 10000 条数
4. 返回剩余的 10 条数据

**子查询——将查询落到索引上**（**先找到主键，然后再根据主键索引找到相应的id**）

```sql
Select * From table_name Where id in (Select id From table_name where ( user = xxx )) limit 10000, 10;

select * from table_name where( user = xxx ) limit 10000,10
```

　　相比较结果是（500w条数据）：第一条花费平均耗时约为第二条的 1/3 左右。同样是较大的 offset，第一条的查询更为复杂，为什么性能反而得到了提升？基本原理就是：

- 子查询只用到了索引列(user设置为索引列)，**没有取实际的数据，所以不涉及到磁盘IO**，所以即使是比较大的 offset 查询速度也不会太差。
- 利用子查询的方式，**把原来的基于 user 的搜索转化为基于主键（id）的搜索**，主查询因为已经获得了准确的索引值，所以查询过程也相对较快。

```mysql
select * from table_name inner join (select id from table_name where (user = xxx) limit 10000,10) b on table_name.id = b.id;
```

### sql很慢的解决方案

1. 首先通过jprofile看耗时时间长的操作，具体是不是sql引起的，具体找到哪一行代码耗时最长，是什么sql引起的，是不是因为<u>索引设置出错、是不是有大量相同的SQL，where是否相同，也就是程序中**有大量循环操作导致**</u>。

2. 在这个操作的时候，是不是因为事务处理不当出现了锁的等待堵塞甚至死锁。通过sql语句可以查询被阻塞线程、被阻塞的sql、阻塞线程、阻塞sql通过`performance_schema.data_lock_waits`这个表查。

   ``` mysql
   select t1.REQUESTING_THREAD_ID as '被阻塞线程'
   ,t2.trx_query as '被阻塞SQL'
   ,t1.BLOCKING_THREAD_ID as '阻塞线程'
   ,t3.trx_query as '阻塞SQL'
   ,(UNIX_TIMESTAMP() - UNIX_TIMESTAMP(t3.trx_started)) as '阻塞时间'
   from
   (
      SELECT REQUESTING_THREAD_ID,REQUESTING_ENGINE_TRANSACTION_ID,BLOCKING_THREAD_ID,BLOCKING_ENGINE_TRANSACTION_ID
      FROM performance_schema.data_lock_waits
   ) t1
   left join information_schema.innodb_trx t2 on t1.REQUESTING_ENGINE_TRANSACTION_ID=t2.trx_id
   left join information_schema.innodb_trx t3 on t1.BLOCKING_ENGINE_TRANSACTION_ID=t3.trx_id
   ```

3. 还可以通过`SHOW ENGINE INNODB STATUS;`查询最近依次死锁的日志。在status里面是死锁日志。LATEST DETECTED DEADLOCK后面是两个事务的信息。

4. 然后优化一下sql。分页、过滤掉不需要的数据、如果是join的话优化一下让小表驱动大表。

### mybatis\<foreach>的作用或者说批处理的作用

　　批量写入mysql可以大量减少与数据库的交互，减轻数据库的压力。比之前逐个单独写入，批量写入时日志量（MySQL的binlog和innodb的事务让日志）减少，**降低了日志刷盘的数据量和频率，从而提高效率**。同时**也能减少SQL语句解析的次数，减少网络传输的IO，性能上有一定提升**。

mysql设计表时怎么去提高性能 

数据库范式 ？BCNF？第四第五范式？ 

联合索引最多多少个字段 ? MySQL 单张表索引的硬性限制（不能超过 64 个）

## SQL

sql查询一个月内数据的前5的id  **desc+limit**

查找员工表第N高的工资

如何写SQL求出中位数、平均数、众数 

将daming的成绩设置成80 **where**

今天看不同视频数量超过100个的用户id的前三名/每一科成绩的前三名

找出所有语文考及格但是数学没有考及格的学生 先找语文的，在这里面再找数学的。注意in的使用

输出每个course的第一名，包括id,name,score,course **现根据分数找到对应的stu，然后join其他表，最后group by**

一个表一千个列值为true和false，写sql 查询查有300个列值为true的行。

``` mysql
select *  from t where LENGTH(REPLACE(CONCAT(v2,v3,v4,v5,v6,v7,v8,v9),'false','') ) = 4*3;
```

## 