## Redis

### 用分布式锁的时候主节点挂了，从节点还没有同步到数据，锁丢失了，这种情况怎么解决

　　setnx 锁最大的缺点就是它加锁时只作用在一个 Redis 节点上，即使 Redis 通过 Sentinel(哨岗、哨兵) 保证高可用，如果这个 master 节点由于某些原因发生了主从切换，那么就会出现锁丢失的情况，下面是个例子：

1. 在 Redis 的 master 节点上拿到了锁；
2. 但是这个加锁的 key 还没有同步到 slave 节点；
3. master 故障，发生故障转移，slave 节点升级为 master节点；
4. 上边 master 节点上的锁丢失。

　　**有的时候甚至不单单是锁丢失这么简单，新选出来的 master 节点可以重新获取同样的锁，出现一把锁被拿两次的场景。锁被拿两次，也就不能满足安全性了...**

　　redlock算法

### redis集群之间的关系，三个节点存储数据是相同的，还是不同的。

　　存储的数据是不同的

### Redis Cluster 是如何进行扩容的？

### redis的主从复制，超过缓冲区大小怎么办？

　　若发生缓存溢出，则要进行全量复制。

### 释放锁如果不用lua脚本会出现什么问题

　　为了解决锁不能正常释放的问题，所以set锁的时候，需要设置过期时间。因为多进程释放锁加锁时，是无法做到原子操作，比如进程 A 执行完业务逻辑，<u>在准备释放锁时，恰好这时候进程 A 的锁自动过期时间到了，而另一个进程 B 获得锁成功，然后 B 还没来得及执行，进程 A 就执行了 delete(key) ，释放了进程 B 的锁</u>，因此需要配合 Lua 脚本释放锁

### redis集群部署介绍，get key从发起请求到获取值的过程

### redis的内部一致性是怎么实现的，RDB快照的过程，为什么fork进程能够读到快照数据？

### 全量和增量复制的区别

- **全量复制**<u>用于初次复制或者其他无法进行部分复制的情况，将主节点的所有数据都发送给从节点</u>，是一个非常重型的操作，当数据量较大时，会对主从节点和网络造成很大的开销

- **增量复制**<u>用于处理在主从复制中因**网络闪断**等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点的**复制积压缓冲区**内存将这部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。补发的这部分数据一般远远小于全量数据。</u>，因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销，需要注意的是，如果网络中断时间过长，造成主节点没有能够完整的保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制

  > 主节点接到psync命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+COUTINUE响应，表示可以进行部分复制。因为缓冲区大小固定，若发生

### redis集群介绍一下

　　**redis的集群是将一共16384个槽分给集群中节点，每个节点通过gossip协议得知其它节点的信息，并在自身的clusterState中记录了所有的节点的信息和槽数组的分配情况**

　　**Gossip协议**基本思想就是：一个节点想要分享一些信息给网络中的其他的一些节点。于是，它**周期性**的**随机**选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。一般而言，信息会周期性的传递给N个目标节点，而不只是一个。20个节点且设置fanout=4，公式结果是2.16，这只是个近似值。真实传递时，可能需要3次甚至4次循环才能让所有节点收到消息。这是因为每个节点在传播消息的时候，是随机选择N个节点的，这样的话，就有可能某个节点会被选中2次甚至更多次。

　　gossip 好处在于，**元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后**

### 客户端是如何访问集群的？

　　客户端会先访问集群中的一个节点，如果槽命中直接访问，如果不命中，则会返回MOVED指令，并告知槽实际存在的节点，然后再去访问。(这里其实还有个迁移中的情况，如果访问的槽正在迁移，则返回ask命令，[客户端]()会被引导去目标节点查找)

### 一致性 hash？那和普通hash有什么区别？

　　**一致性hash把hash的空间虚拟成一个圆环**，key做hash落在圆环上，按顺时针查找，遇到的第一个缓存节点就命中。另外还可以通过虚拟节点避免缓存分布不均，以及某个节点挂了之后，下面的节点只需要承担一部分的流量而不会因为需要承担所有流量而挂了，然后发生雪崩

### Redis分布式锁先SETNX后,未来得及设置过期时间宕机了怎么办

1. set key value nx ex seconds(原子操作)
2. LUA脚本保证原子操作

　　某个线程在申请分布式锁的时候，为了应对极端情况，比如机器宕机，那么这个锁就一直不能被释放。一个比较好的解决方案是，申请锁的时候，预估一个程序的执行时间，然后给锁设置一个超时时间，这样，即使机器宕机，锁也能自动释放。

　　但是这也带来了一个问题，就是在有时候负载很高，任务执行的很慢，锁超时自动释放了任务还未执行完毕，这时候其他线程获得了锁，导致程序执行的并发问题。对这种情况的解决方案是：在获得锁之后，就开启一个守护线程，定时去查询Redis分布式锁的到期时间，如果发现将要过期了，就进行续期。

### Redis内存不足时怎么样

1. 执行淘汰策略.默认是返回错误;还有随即淘汰和最近最少使用淘汰策略(注意设置maxmemory,否则64位机器会用尽机器内存)
2. 使用集群模式,将数据分片存储(中间件解决分片/业务keyhash实现)
3. 减少大key产生,查询大key优化

### Redis如何查看大KEY

1. redis-cli --bigkeys 查看大Key;基于scan命令,不用担心阻塞问题.对String类型统计字节长度,对集合类型统计元素个数.
2. debug object key 查看对应key的序列化后长度
3. 手动执行bgsave命令,生成rdb文件,通过[redis]() rdb tools工具分析rdb文件
4. memory usage key 查看对应key的内存使用(4.0+版本)

### 缓存雪崩

　　缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。结果就是DB 撑不住，挂掉。

- **使用集群缓存，保证缓存服务的高可用**。这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。
- **ehcache本地缓存 + Hystrix限流&降级，避免MySQL被打死**。使用 ehcache 本地缓存的目的也是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。使用 Hystrix进行限流 & 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。

**服务限流算法**

限流怎么做的？令牌桶的算法实现？限流还有哪些方式？

限流的算法有：计数器算法、漏桶算法、令牌桶算法

　　令牌桶算法是比较常见的限流算法之一，大概描述如下：

1. 所有的请求在处理之前都需要拿到一个可用的令牌才会被处理
2. 根据限流大小，设置按照一定的速率往桶里添加令牌
3. 桶设置最大的放置令牌限制，当桶满时、新添加的令牌就被丢弃或者拒绝；
4. 请求达到后首先要获取令牌桶中的令牌，拿着令牌才可以进行其他的业务逻辑，处理完业务逻辑之后，将令牌直接删除；
5. 令牌桶有最低限额，当桶中的令牌达到最低限额的时候，请求处理完之后将不会删除令牌，以此保证足够的限流；

　　实现简单令牌桶算法，没有考虑随时间滑动的情况； 加强版：令牌桶，加上随时间滑动的要求，即：限制用户在任一连续的一小时内，不能超过5W的请求。这边提到了说将一小时分成多格，比如60格这样的，面试官点头貌似同意了，然后就实现代码了，包括协程异步更新时间窗口；

**服务降级**

　　这里有两种场景:

- 当下游的服务因为某种原因响应过慢，下游服务**主动停掉一些不太重要的业务，释放出服务器资源，增加响应速度**
- 当下游的服务因为某种原因不可用，上游**主动调用本地的一些降级逻辑，避免卡顿，迅速返回给用户**

　　其实应该要这么理解:

- 服务降级有很多种降级方式！如开关降级、限流降级、熔断降级
- 服务熔断属于降级方式的一种

> 服务熔断：当下游的服务因为某种原因突然**变得不可用**或**响应过慢**，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。

```java
try{
    //调用下游的helloWorld服务
    xxRpc.helloWorld();
}catch(Exception e){
    //因为熔断，所以调不通
    doSomething();
}
```

　　注意看，下游的helloWorld服务因为熔断而调不通。此时上游服务就会进入catch里头的代码块，那么catch里头执行的逻辑，你就可以理解为降级逻辑!

　　开关降级也是我们生产上常用的另一种降级方式！做法很简单，做个开关，然后将开关放配置中心！在配置中心更改开关，决定哪些服务进行降级。至于配置变动后，应用怎么监控到配置发生了变动，这就不是本文该讨论的范围。那么，在应用程序中部下开关的这个过程，业内也有一个名词，称为**埋点**！

　　那接下来最关键的一个问题，哪些业务需要埋点？一般有以下方法

1. 简化执行流程。自己梳理出核心业务流程和非核心业务流程。然后在非核心业务流程上加上开关，一旦发现系统扛不住，关掉开关，结束这些次要流程。
2. 关闭次要功能。一个微服务下肯定有很多功能，那自己区分出主要功能和次要功能。然后次要功能加上开关，需要降级的时候，把次要功能关了吧！
3. 降低一致性。假设，你在业务上发现执行流程没法简化了，愁啊！也没啥次要功能可以关了，桑心啊！那只能降低一致性了，即将核心业务流程的同步改异步，将强一致性改最终一致性！

### 缓存穿透

　　正常情况下，我们去查询数据都是存在的。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。

* 那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。这样，就不用在到数据库中去了。(**对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存**)
* 在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -> 查 DB。(**针对于一些恶意攻击，攻击带过来的大量key 是不存在的**)

### 缓存击穿

　　在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为**缓存击穿**。

　　在第一个查询数据的请求上使用一个 互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。

### Redis挂了，流量把数据库也打挂了，怎么办？

　　这是啥？**Redis 挂了，不就是缓存都没了吗？缓存都没了，不就是缓存雪崩了吗**？缓存雪崩了，不就导致数据库挂了吗？一提到“缓存雪崩”这四个字，缓存穿透、缓存击穿这几兄弟，是不是就立马条件反射的出现在你的脑海里面了，还顺带着对应的几套解决方案。(穿，只是穿过了缓存。透，是直接干到底。)

　　**Redis 挂了，为什么挂了**？怎么就挂了？是不是有单点问题？这不就是问你 Redis 服务的高可用吗？说到 Redis 的高可用，脑子里面必须马上蹦出来主从、哨兵和集群吧？

　　**这时该怎么进行恢复**？站在运维人员的角度，当然优先考虑是先把 Redis 和数据库服务重新启动起来啦。但是启动之前得先做个小操作，把流量摘掉，可以先把流量拦截在入口的地方，比如简单粗暴的通过 Nginx 的配置把请求都转到一个精心设计的错误页面，就是说这么一个意思。这样做的目的是为了防止流量过大，直接把新启动的服务，启动一个打挂一个的情况出现。<u>当 Redis 服务重新启动后，通过程序先放点已知的热点 key 进去后，系统再对外提供服务，防止缓存击穿的场景。</u>

　　**该怎么进行预防**？服务中是不是需要考虑限流或者熔断机制，最大程度的保护程序的运行？或者我们是否应该建立多级缓存的机制，防止 Redis 挂掉之后，大批流量直接打到 MySQL 服务导致数据库的崩盘？**多级缓存、限流措施、服务降级、熔断机制**

**Redis Sentinel 重选主的流程，客户端找不到新主怎么办？**

　　当客户端试图连接失效的Master时，集群也会向客户端返回新Master的地址。Master和Slave服务器切换后，Master的redis.conf、Slave的redis.conf和sentinel.conf的配置文件的内容都会发生相应的改变，即，<u>Master主服务器的redis.conf配置文件中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换。</u>

### 过期策略

　　使用过Redis的同学应该知道，我们在设置一个key之后，可以指定这个key的过期时间。那么这个key到了过期时间就会立即被删除吗？Redis是如何删除这些过期key的呢？

　　先说结论：Redis是使用**定期删除**+**惰性删除**两者配合的过期策略。

**定期删除**

　　<u>定期删除指的是Redis默认每隔**100ms**就随机抽取一些**设置了过期时间**的key，检测这些key是否过期，如果过期了就将其删掉。</u>因为key太多，如果全盘扫描所有的key会非常耗性能，所以是随机抽取一些key来删除。这样就有可能删除不完，需要惰性删除配合。

**惰性删除**

　　<u>惰性删除不再是Redis去主动删除，而是在客户端在请求某个key的时候，Redis会先去检测一下这个key是否已经过期，如果没有过期则返回给客户端，如果已经过期了，那么Redis会删除这个key，不会返回给客户端。</u>

　　所以惰性删除可以解决一些过期了，但没被定期删除随机抽取到的key。但有些过期的key既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以Redis提供了内存淘汰机制来解决这个问题。

> 为什么不使用定时删除？所谓定时删除，指的是用一个定时器来负责监视key，当这个key过期就自动删除，虽然内存及时释放，但是十分消耗CPU资源，因此一般不推荐采用这一策略。

### 内存淘汰策略

1. noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。**默认策略**
2. allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。
3. allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。
4. volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。
5. volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。
6. volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。

### LRU和LFU

　　LRU和LFU都是内存管理的页面置换算法。主要思想都是：如果数据最近被访问过，那么将来被访问的几率也更高。

　　LRU，即：**最近最少使用淘汰**算法（Least Recently Used）。LRU是<u>淘汰最长时间**没有被使用**的页面</u>，

　　**存在的问题**：偶发性的、周期性的批量查询操作（包含冷数据）会淘汰掉大量的热点数据，导致 LRU 命中率急剧下降，缓存污染情况比较严重。

　　LFU，即：**最不经常使用淘汰**算法（Least Frequently Used）。LFU是<u>淘汰一段时间内使用**次数最少**的页面</u>。

**存在的问题**：

1. **最近加入的数据总是易于被剔除**（缓存末端抖动），因为他**起始的频率很低**。它无法对一个拥有最初高访问率之后长时间没有被访问的条目缓存负责。
2. 为了避免早期的热点数据一直占据缓存，即LFU算法也需有一些访问时间模式的特性。
   但是，如果频率的时间度量是 1 小时（数据根据最近一小时内的访问次数排序），则平均每小时访问 1000 次的数据可能会比前一个小时内访问次数为 1001 的数据更优先剔除掉。

> 一般情况下，LFU 效率要优于 LRU，且**能够避免周期性或者偶发性的操作导致缓存命中率下降的问题**，但 LFU 需要记录数据的历史访问记录，一旦数据访问模式改变，LFU 需要更长时间来适用新的访问模式，即 **LFU 存在历史数据影响将来数据的 `缓存污染` 问题**。
>
> LFU 使用计数器来记录条目被访问的频率，通过使用 LFU 缓存算法，最低访问次数的条目首先被移除，此方法并不经常使用，因为它无法对一个拥有最初高访问率之后长时间没有被访问的条目缓存负责。

### 持久化如何处理过期？

**RDB**　从内存持久化数据到RDB文件：持久化key之前，会检查是否过期，过期的key不进入RDB文件。从RDB文件恢复数据到内存：数据载入内存之前，会对key先进行过期检查，如果过期，不导入内存（主库情况）。

1. 如果 Redis 以主服务器的模式运行，那么会对 RDB 中的键进行时间检查，过期的键不会被恢复到 Redis 中。
2. 如果 Redis 以从服务器的模式运行，那么 RDB 中所有的键都会被载入，忽略时间检查。在从服务器与主服务器进行数据同步的时候，从服务器的数据会先被清空，所以载入过期键不会有问题。

**AOF**　如果一个键过期了，那么不会立刻对 AOF 文件造成影响。因为 Redis 使用的是**惰性删除和定期删除**，只有这个键被删除了，才会往 AOF 文件中追加一条 DEL 命令。**在重写 AOF 的过程中，程序会检查数据库中的键，已经过期的键不会被保存到 AOF 文件中。**

1. 对于主服务器，一个过期的键被删除了后，会向从服务器发送 DEL 命令，通知从服务器删除对应的键
2. 从服务器接收到读取一个键的命令时，即使这个键已经过期，也不会删除，而是照常处理这个命令。
3. 从服务器接收到主服务器的 DEL 命令后，才会删除对应的过期键。

redis扩容时  新老旧节点 数据迁移具体是怎么做的？

cannal binlog mq具体过程？怎么防止重复消费？怎么防止消息丢失？

 ### 一致性hash

　　一致性哈希在某节点宕机时怎么保证一致性的？

### 布隆过滤器

　　讲述布隆过滤器的原理之前，我们先思考一下，通常你判断某个元素是否存在用的是什么？应该蛮多人回答 HashMap 吧，确实可以将值映射到 HashMap 的 Key，然后可以在 O(1) 的时间复杂度内返回结果，效率奇高。但是 HashMap 的实现也有缺点，**例如存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很可观了。**

　　还比如说你的数据集存储在远程服务器上，本地服务接受输入，而数据集非常大不可能一次性读进内存构建 HashMap 的时候，也会存在问题。

　　**布隆过滤器（Bloom Filter）的核心实现是一个超大的位数组和几个哈希函数。假设位数组的长度为m，哈希函数的个数为k**

<img src="D:/%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9C%E4%BA%91/pictures/4360245-015a6e823496b8b3.png" alt="img" style="zoom:50%;" />

　　以上图为例，具体的操作流程：假设集合里面有3个元素{x， y， z}，哈希函数的个数为3。首先将位数组进行初始化，将里面每个位都设置位0。对于集合里面的每一个元素，将元素依次通过3个哈希函数进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。查询W元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。反之，如果3个点都为1，则该元素可能存在集合中。注意：此处不能判断该元素是否一定存在集合中，可能存在一定的误判率。可以从图中可以看到：假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1，这是误判率存在的原因。

　　它有**一个致命的缺点，就是不支持删除**。为什么？

　　假设要删除 [why]，那么就要把 1,4,8 这三个位置置为 0。但是你想啊，[jay] 也指向了位置 8 呀。如果删除 [why] ，位置 8 变成了 0，那么是不是相当于把 [jay] 也移除了？

　　布隆过滤器还有一个问题：查询性能不高。

　　因为真实场景中过滤器中的数组长度是非常长的，经过多个不同 Hash 函数后，得到的数组下标在内存中的跨度可能会非常的大。跨度大，就是不连续。不连续，就会导致 CPU 缓存行命中率低。

### 布谷鸟过滤器

　　它有两个 hash 表，记为 T1，T2。两个 hash 函数，记为 h1，h2。

* 当一个不存在的元素插入的时候，会先根据 h1 计算出其在 T1 表的位置，如果该位置为空则可以放进去。
* 如果该位置不为空，则根据 h2 计算出其在 T2 表的位置，如果该位置为空则可以放进去。
* 如果该位置不为空，就把当前位置上的元素踢出去，然后把当前元素放进去就行了。
* 也可以随机踢出两个位置中的一个，总之会有一个元素被踢出去。

- 支持动态的新增和删除元素。
- 提供了比传统布隆过滤器更高的查找性能，即使在接近满的情况下（比如空间利用率达到 95% 的时候）。
- 比诸如商过滤器（quotient filter，另一种过滤器）之类的替代方案更容易实现。
- 如果要求错误率小于3%，那么在许多实际应用中，它比布隆过滤器占用的空间更小。

### Redis 和 Memcached的区别

1. 数据操作不同。与Memcached仅支持简单的key-value结构的数据记录不同，Redis支持的数据类型要丰富得多。Memcached基本只支持简单的key-value存储，不支持枚举，不支持持久化和复制等功能。Redis支持服务器端的数据操作相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，支持list、set、sorted set、hash等众多数据结构，还同时提供了持久化和复制等功能。
2. 内存管理机制不同。在Redis中，并不是所有的数据都一直存储在内存中的。当物理内存用完时，Redis可以将一些很久没用到的value交换到磁盘，重启的时候可以再次加载进行使用。 。而memcache不支持数据持久存储 
3. 集群管理不同。redis支持master-slave复制模式，memcache可以使用一致性hash做分布式
4. 数据一致性不同。<u>redis使用的是单线程模型，保证了数据按顺序提交。memcache需要使用cas保证数据一致性。</u>CAS（Check and Set）是一个确保并发一致性的机制，属于“乐观锁”范畴；原理很简单：拿版本号，操作，对比版本号，如果一致就操作，不一致就放弃任何操作 

　　这是和Memcached相比一个最大的区别。Redis只会缓存所有的key的信息，如果Redis发现内存的使用量超过了某一个阀值，将触发swap的操作，Redis根据“swappability = age*log(size_in_memory)”计算出哪些key对应的value需要swap到磁盘。然后再将这些key对应的value持久化到磁盘中，同时在内存中清除。这种特性使得Redis可以保持超过其机器本身内存大小的数据。

　　从内存利用率来讲，使用简单的key-value存储的话，Memcached的内存利用率更高。而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。

　　小结：Redis和Memcached哪个更好？

　　Redis更多场景是作为Memcached的替代者来使用，当需要除key-value之外的更多数据类型支持或存储的数据不能被剔除时，使用Redis更合适。如果只做缓存的话，Memcached已经足够应付绝大部分的需求，Redis 的出现只是提供了一个更加好的选择。总的来说，根据使用者自身的需求去选择才是最合适的。

### redis常用的数据结构有哪几种，在你的项目中用过哪几种，以及在业务中使用的场景

　　主要使用的是value为String类型的。

1. `String`：字符串类型

   在用户登录之后，将用户对象转为Json字符串

   保存秒杀商品信息的时候，将商品的uuid保存

   保存秒杀订单，将秒杀订单转为Json字符串

   判断是否已经秒杀过等等

2. `List`：列表类型。商品的关注列表；店铺的粉丝列表；商品评论（将评论信息转成json存储到list中）

3. `Set`：无序集合类型。共同好友；利用唯一性，统计访问网站的所有独立ip；好友推荐时，根据tag求交集，大于某个阈值就可以推荐

4. `ZSet`：有序集合类型。销售的排行榜；带权重的消息队列

5. `Hash`：哈希表类型。存储、读取、修改用户属性

### 为什么要用redis做缓存？

　　主要还是相对于mysql等关系型数据库，redis的性能更高以及redis支持高并发。

　　为什么redis性能高支持高并发？主要有四点

1. redis是存储在内存中的，是纯内存的操作
2. redis中存储的是键值对，内部采用了高效的数据结构
3. redis的是单线程模型的，减少了线程切换所带来的的开销
4. redis使用的是非阻塞IO，IO多路复用。吞吐能力比较大

### 怎么实现redis缓存的一致性？

　　在我自己做的秒杀项目中，系统不是严格要求缓存和数据库必须严格一致性的，主要用redis抗住峰值流量，只是简单的给缓存设置过期时间以保证最终一致性，比如商品的详情，设置的时间为1s。

　　如果需要保证缓存和数据库的一致性的话：读的时候，先读缓存，缓存没有的话就去读数据库，然后取出数据后放入缓存中。更新的时候，先更新数据库，然后再删除缓存。

　　另外还有**延时双删策略(缓存双淘汰法)+设置缓存过期时间**，可以**<u>将前面所造成的缓存脏数据，再次删除</u>**：

1. 先删除(淘汰)缓存
2. 再写数据库（1和2的步骤可以互换）
3. 休眠一段时间，再次删除(淘汰)缓存

　　还有一个更复杂的基于订阅binlog的**异步更新缓存**策略。binlog增量订阅消费+消息队列+增量数据更新到redis。

- 读Redis：热数据基本都在Redis
- 写MySQL:增删改都是操作MySQL
- 更新Redis数据：MySQ的数据操作binlog，来更新到Redis

　　这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。

### redis的hash怎么实现的，rehash过程讲一下和JavaHashMap的rehash有什么区别？

　　Redis中，键值对（Key-Value Pair）存储方式是由字典（Dict）保存的，而字典底层是通过哈希表来实现的。通过哈希表中的节点保存字典中的键值对。类似Java中的HashMap，将Key通过哈希函数映射到哈希表节点位置。和HashMap不同的是，redis里面保存的是两张哈希表以便进行rehash。

``` c
typedef struct dict {
    // 和类型相关的处理函数
    dictType *type;                        
    // 上述类型函数对应的可选参数
    void *privdata;                        
    // 两张哈希表，ht[0]为原生哈希表，ht[1]为 rehash 哈希表
    dictht ht[2];                          
    // 当等于-1时表示没有在 rehash，否则表示 rehash 的下标
    long rehashidx;                        
    int iterators;// 迭代器数量(暂且不谈)
} dict;
```

rehash的过程：

- 两张哈希表，ht[0]为原生哈希表，ht[1]为 rehash 哈希表。如果是扩容操作，为 ht[1] 分配空间，ht[1] 的大小为第一个大于等于 $ht[0].used*2$ 的 $2^n$ 比当前 ht[0].used 值的二倍大的第一个 2 的整数幂；如果是缩容操作，ht[1] 的大小为第一个大于等于 $ht[0].used$ 的 $2^n$。
- 将 ht[0] 中的键值 Rehash 到 ht[1] 中。
- 当 ht[0] 全部迁移到 ht[1] 中后，释放 ht[0]，将 ht[1] 置为 ht[0]，并为 ht[1] 创建一张新表，为下次 Rehash 做准备。

渐进式rehash的过程：

- 为ht[1]分配空间，字典中维护一个 rehashidx，并将它置为 0，表示 Rehash 开始。
- 在 Rehash 期间，还可以对字典操作。程序会将 ht[0] 在 rehashidx 索引上的键值对 rehash 到 ht[1] 中，当 Rehash 完成后，将 rehashidx+1(位置变化)。当全部 rehash 完成后，将 rehashidx 置为 -1，表示 rehash 完成。

### redis cluster怎么做到高可用的？

1. Redis Cluster可以很方便的进行横向扩容

   当新的节点加入进来的时候，<u>通过**reshard**（重新分片）来将已经分配给某个节点的任意数量的slot迁移给另一个节点，在Redis内部是由redis**-**trib负责执行的</u>。

   假设我们需要向集群中加入一个D节点，而此时 集群内已经有A、B、C三个节点了。此时redis**-**trib会向A、B、C三个节点发送迁移出槽位的请求，同时向D节点发送准备导入槽位的请求，做好准备之后A、B、C这三个源节点就开始执行迁移，将对应的slot所对应的键值对迁移至目标节点D。最后redis**-**trib会向集群中所有主节点发送槽位的变更信息。

2. 如果Redis Cluster中的某个master节点挂了，会进行故障转移

   简单来说，针对A节点，某一个节点认为A宕机了，那么此时是**主观宕机**。而如果集群内超过半数的节点认为A挂了， 那么此时A就会被标记为**客观宕机**。

   一旦节点A被标记为了客观宕机，集群就会开始执行**故障转移**。其余<u>正常运行的master节点会进行投票选举，从A节点的slave节点中选举出一个，将其切换成新的master对外提供服务。当某个slave获得了超过半数的master节点投票，就成功当选。</u>当选成功之后，新的master会执行`slaveof no one`来让自己停止复制A节点，使自己成为master。然后将A节点所负责处理的slot，全部转移给自己，然后就会向集群发**PONG**消息来广播自己的最新状态。

   <img src="D:/%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9C%E4%BA%91/pictures/0081Kckwgy1glqmfywf8jj30920f3mxp.jpg" alt="cluster-failover" style="zoom:50%;" />

   按照**一致性哈希**的思想，如果某个节点挂了，那么就会沿着那个圆环，按照顺时针的顺序找到遇到的第一个Redis实例。而对于Redis Cluster，某个key它其实并不关心它最终要去到哪个节点，他只关心他最终落到哪个slot上，无论你节点怎么去迁移，最终还是只需要找到对应的slot，然后再找到slot关联的节点，最终就能够找到最终的Redis实例

遇到过redis的hotkey吗？怎么处理的？

### redis集群和哨兵机制有什么区别？

1. 哨兵模式是基于主备模式演进而来的。一个Master可以有多个Slaves，sentinel发现master挂了后，就会从slave中重新选举一个master。 
2. 集群：集群是基于哨兵模式，为了解<u>决单机Redis容量有限的问题，将数据按一定的规则分配到多台机器，内存/QPS不受限于单机</u>，可受益于分布式集群高扩展性。

### redis的持久化机制了解吗？在项目中是怎么做持久化的？

Redis提供了两种不同的持久化方法可以将数据存储在磁盘中，一种叫快照RDB，另一种叫追加文件AOF。

1. 在指定的时间间隔内将内存中的数据集快照写入磁盘(`Snapshot`)，它恢复时是将快照文件直接读到内存里。

   Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那`RDB`方式要比`AOF`方式更加的高效。`RDB`的缺点是最后一次持久化后的数据可能丢失。

2. AOF 会把 Redis 服务器**执行的写命令**记录到一个日志文件中，当服务器重启时再次执行 AOF 文件中的命令来恢复数据。

   Redis**每次执行**，会将执行的写命令追加到 AOF 的缓冲区 aof_buf，随后根据相应的策略才真正将缓冲区的数据写入到磁盘里。并且定期对 AOF 进行重写，从而实现对写命令的压缩。

### redis单线程的吗？单线程为什么还这么快？

1. Redis的线程模型

- 纯内存操作。数据存放在内存中，内存的响应时间是纳秒级别的
- 使用IO多路复用技术。利用 epoll/select/kqueue 等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求），最后回写响应数据到客户端。
- 单线程的优势。非CPU密集型任务，线程没有了线程上下文切换和访问共享资源加锁的性能损耗，而且单线程模型对程序的开发和调试非常友好。

2. 高效的数据结构

* 用一种称为 SDS（Simple Dynamic String）的结构体来保存字符串。
* 字典类型的。Rehash和渐进式 Rehash。
* Zset底层的数据结构是跳跃表 skiplist
* 编码转化。对于某一种类型的数据，可能有多种编码来实现

### 讲一讲redis的内存模型？

Redis的内存占用主要可以划分为以下几个部分：

1. 数据。这部分内存在used_memory中。Redis所有数据都是Key-Value型，每次创建Key-Value都是创建2个对象，即Key对象和Value对象。Key对象都是字符串。Value对象则包括5种类型（String，List，Hash，Set，Zset）

2. 进程本身运行需要的内存。Redis主进程本身运行肯定需要占用内存，如代码、常量池等等。这部分内存在used_memory中。

3. 缓冲内存。包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等

   客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。这部分内存由jemalloc分配，因此会统计在used_memory中。

4. 内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。

### Redis Cluster的架构，怎么寻找对应的Key的？

<img src="https://cdn.jsdelivr.net/gh/candyboyou/imgs/img899685-20161105172636752-598157782.jpg" alt="img" style="zoom:50%;" />

1. 一般集群建议搭建三主三从架构，三主提供服务，三从提供备份功能。每一个节点都存有这个集群所有主节点以及从节点的信息
2. <u>所有的redis节点彼此互联(PING-PONG机制)，</u>内部使用二进制协议优化传输速度和带宽
3. 客户端与redis节点直连，不需要中间proxy层。<u>客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可</u>
4. 节点的fail是通过集群中超过半数的master节点检测失效时才生效。如果有一半以上的节点去ping一个节点的时候没有回应，集群就认为这个节点宕机了，然后去连接它的备用节点。如果某个节点和所有从节点全部挂掉，我们集群就进入fail状态。还有就是如果有一半以上的主节点宕机，那么我们集群同样进入fail状态。

redis cluster并没有使用一致性哈希来计算key对应的节点，而是通过记录一张映射表 hash slots的方式。由于分层两层结构，从key到slotId这一步还是使用了哈希算法的。为了提高客户端快速找到key所在的slot，这里采用了哈希的方式，计算公式是: `slotId = crc16(key) % 16384`。

如何保证消息的顺序执行？Kafka了解吗？

你为啥不用kafka来做，当时怎么考虑的？

tcp怎么保证有序传输的，讲下tcp的快速重传和拥塞机制，知不知道time_wait状态，这个状态出现在什么地方，有什么用？

有没有了解过协程？说下协程和线程的区别？用过哪些linux命令？如查看内存使用、网络情况？

### RDB的实现细节

1. <u>客户端发起 BGSAVE 命令，Redis 主进程判断当前是否存在正在执行备份的子进程，如果存在则直接返回</u>
2. <u>父进程 fork 一个子进程</u> （fork 的过程中会造成阻塞的情况），这个过程可以使用 info stats 命令查看 latest_fork_usec 选项，查看最近一次 fork 操作消耗的时间，单位是微秒
3. 父进程 fork 完成之后，则会返回 Background saving started 的信息提示，此时 fork 阻塞解除
4. <u>fork 创建的子进程开始根据父进程的内存数据生成临时的快照文件，然后替换原文件</u>
5. 子进程备份完毕后向父进程发送完成信息，父进程更新统计信息

#### 为什么bgsave不阻塞请求，那这时候如果来请求了[redis]()如何处理的

1. 为什么 `fork` 之后的子进程能够获取父进程内存中的数据？

   **通过 `fork` 生成的父子进程会共享包括内存空间在内的资源；**

2. `fork` 函数是否会带来额外的性能开销，这些开销我们怎么样才可以避免？

   `fork` 函数并不会带来明显的性能开销，对内存进行大量的拷贝，它能通过**写时拷贝**将拷贝内存这一工作推迟到真正需要的时候

   > 在fork之后exec之前两个进程**用的是相同的物理空间**（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的**物理空间是同一个**。当父子进程中**有更改相应段的行为发生时**，再**为子进程相应的段分配物理空间**。
   >
   > 总体来看，Redis还是读操作比较多。如果子进程存在期间，发生了大量的写操作，那可能就会出现很多的分页错误(页异常中断page-fault)，这样就得耗费不少性能在复制上。
   >
   > 而在rehash阶段上，写操作是无法避免的。所以Redis在fork出子进程之后，将<u>负载因子阈值提高，尽量减少写操作</u>，避免不必要的内存写入操作，最大限度地节约内存。

#### 生成的快照是精确到指定时刻的内存数据，还是在某个时间段内的内存数据？

Copy On Write 机制，备份的是开始那个时刻内存中的数据。

#### RDB的优缺点

优点

1. 生成RDB快照文件的过程是异步的，所以在持久化过程中对服务器性能影响小。
2. RDB文件存储的是内存数据库的快照，采用紧凑的二进制文件存储。通过RDB文件进行**数据库恢复的时候速度快**。

缺点

1. 由于RDB文件是异步进行备份的，所以存在**数据安全性**弱的弊端：当系统发生故障导致内存数据库数据丢失的时候，从RDB文件中只能恢复创建RDB快照那一刻的数据，在最近一次创建RDB快照那一刻到服务器宕机之间的数据将永久性的丢失了。数据恢复的完整程度依赖于RDB快照创建的频率。
2. 由于RDB快照是将整个内存数据库备份下来，所以当内存数据库很大的时候创建RDB文件需要耗费更久的时间。 

### AOF的实现细节

1. 命令追加（append）：将 Redis 执行的写命令追加到 AOF 的缓冲区 aof_buf

2. 文件写入（write）和文件同步（fsync）：AOF 根据对应的策略将 aof_buf 的数据**同步**到硬盘

   write：为了提高文件的写入效率，<u>当用户调用 write 函数将数据写入文件时，操作系统会先把数据写入到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里</u>。

   fsync：Redis 提供了 appendfsync 配置项来控制 AOF 缓存区的文件同步策略，appendfsync 可配置以下三种策略：

   - **appendfsync always**：每执行一次命令保存一次

   　　命令写入 aof_buf 缓冲区后立即调用系统 fsync 函数同步到 AOF 文件

   - **appendfsync no**：不保存

   　　命令写入 aof_buf 缓冲区后调用系统 write 操作，不对 AOF 文件做 fsync 同步；**同步由操作系统负责，通常同步周期为 30 秒**。

   - **appendfsync everysec**：每秒钟保存一次

3. 文件重写（rewrite）：定期对 AOF 进行重写，从而实现对写命令的压缩。

   1. 触发重写，执行bgrewriteaof命令
   2. 父进程fork子进程进行重写，fork子进程的同时父进程阻塞，fork完毕父进程继续接受指令（子进程只是父进程的快照（相当于复制了某时刻的父进程））
   3. 子进程在创建新的aof文件的同时，父进程继续接收write指令，存储到继续存到aof_buf缓存中和aof_rewirte_buf缓存中，所以父进程继续往旧的aof文件中备份，同时也要往新的AOf文件中备份。
   4. 新的aof备份完成
   5. 同时父进程，备份的新文件创建完成
   6. 将aof_rewrite_buf缓存中的备份到新的aof文件中
   7. 新的文件替换旧的aof文件

#### AOF的优缺点

优势

- 每修改同步：`appendfsync always` 同步持久化，每次发生数据变更会被立即记录到磁盘，性能较差但数据完整性比较好
- 每秒同步：`appendfsync everysec` 异步操作，每秒记录，如果一秒内宕机，有数据丢失
- 不同步：`appendfsync no` 从不同步

劣势

- 相同数据集的数据而言`aof`文件要远大于`rdb`文件，恢复速度慢于`rdb`
- `aof`运行效率要慢于`rdb`，每秒同步策略效率较好，不同步效率和`rdb`相同

所以如果 Redis 服务器开启了 AOF 持久化功能，那么服务器会优先使用 AOF 文件来还原数据库状态；只有在 AOF 的持久化功能处于关闭状态时，服务器才会使用使用 RDB 文件还原数据库状态。

### 缓存和DB之间怎么保证数据一致性

缓存预留模式
读操作：先读缓存，缓存没有的话读DB，然后取出数据放入缓存，最后响应数据
写操作：先更新DB，再删除缓存
为什么是删除而不是更新呢？
原因很简单，复杂场景下缓存不单单是DB中直接取出来的值，此外更新缓存的代价是很高的，频繁更新的缓存到底会不会被频繁访问到？可能更新到缓存里面的数据都是冷数据，频繁失效，所以一般用到再去加载缓存，lazy加载的思想

先更新DB，再删除缓存的问题，如果更新DB成功，删除缓存失败会导致数据不一致
所以一般是先删除缓存，再更新DB

还是有问题，A先删除了缓存，但还没更新DB，这时B过来请求数据，发现缓存没有，去请求DB拿到旧数据，然后再写到缓存，等A更新完了DB之后就会出现缓存和DB数据不一致的情况了

解决方案：
更新数据时，根据数据的唯一标识路由到队列中，读取数据时，如果发现数据不再缓存中，那么把读取数据+更新缓存的操作，根据唯一标识路由之后，也发送到相应队列中。一个队列对应一个工作线程，线程串行拿到队列里的操作一一执行

带来的新问题：
可能数据更新频繁，导致队列中积压了大量的更新操作，读请求长时间阻塞，所以要压测

一致性Hash的特点，虚拟节点的作用

RpcContext是在什么维度传递的？

Dubbo的远程调用怎么实现的？

Spring的单例是怎么实现的？

为什么要单独实现一个服务治理框架？

Redis了解哪些（我把底层的SDS，渐进式hash，压缩表，raft算法，gossip协议疯狂输出） 