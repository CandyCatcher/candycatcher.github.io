# 线程和进程

## 什么是线程？什么是进程？线程和进程有什么区别？

1. 进程是操作系统进行资源分配的基本单位，是资源分配和调度的独立单位，也是正在运行的程序。进程之间资源不是共享的，有自己的独立空间；线程是进程划分为的更小的运行单位，是操作系统进行调度的基本单位，必须依赖于进程而存在。
2. 进程单独占有一定的内存空间，进程之间存在内存隔离，数据是分开的，各个进程之间互不干扰；而线程共享所在进程的地址空间和其它资源:堆、方法区，当然进程也有自己的私有资源:虚拟机栈、本地方法栈、程序计数器。
3. 进程的创建和销毁不仅需要保存寄存器和栈信息，还需要资源的分配回收和页调度，开销较大；而线程只需要保存寄存器和栈信息，开销较小。
4. 因为一个进程单独占有一定的内存空间，一个进程出现问题不会影响其它进程，可靠性更高；但是一个线程的崩溃可能会导致整个程序的稳定性，可靠性更低。

## 操作系统是如何分配时间片给线程的？

目前操作系统中主流的线程调度方式是：基于CPU时间片方式进行线程调度。线程只有得到CPU时间片才能执行指令，处于执行状态，没有得到时间片的线程处于就绪状态，等待系统分配下一个CPU时间片。

线程的调度模型目前主要分为两种：分时调度模型和抢占式调度模型。

1. 分时调度模型：系统平均分配CPU的时间片，所有线程轮流占用CPU。分时调度模型在时间片调度的分配上，所有线程“人人平等”。
2. 抢占式调度模型：系统按照线程优先级分配CPU时间片。优先级高的线程，优先分配CPU时间片，如果所有就绪线程的优先级相同，那么会随机选择一个，优先级高的线程获取的CPU时间片相对多一些。

(1) 抢占式调度策略

Java运行时系统的线程调度算法是抢占式的 (preemptive)。Java运行时系统支持一种简单的固定优先级的调度算法。如果一个优先级比其他任何处于可运行状态的线程都高的线程进入就绪状态，那么运行时系统就会选择该线程运行。新的优先级较高的线程抢占(preempt)了其他线程。但是Java运行时系统并不抢占同优先级的线程。换句话说，Java运行时系统不是分时的(time-slice)。然而，基于JavaThread类的实现系统可能是支持分时的，因此编写代码时不要依赖分时。当系统中的处于就绪状态的线程都具有相同优先级时，线程调度程序采用一种简单的、非抢占式的轮转的调度顺序。

(2) 时间片轮转调度策略

有些系统的线程调度采用时间片轮转(round-robin)调度策略。这种调度策略是从所有处于就绪状态的线程中选择优先级最高的线程分配一定的CPU时间运行。该时间过后再选择其他线程运行。只有当线程运行结束、放弃(yield)CPU或由于某种原因进入阻塞状态，低优先级的线程才有机会执行。如果有两个优先级相同的线程都在等待CPU，则调度程序以轮转的方式选择运行的线程。

## 程序计数器为什么是私有的?

程序计数器主要用于记录当前线程执行的位置，在线程切换后能恢复到正确的执行位置，所以必须是私有的。

## 虚拟机栈和本地方法栈为什么是私有的?

虚拟机栈: 每个方法在执行的同时会创建一个栈帧用于存储局部变量表、操作数栈、 常量池引用等信息。从方法调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈和出栈的过程。

本地方法栈: 和虚拟机栈所发挥的作用非常相似，区别是: 虚拟机栈为虚拟机执行 Java 方法 (也就是字节码)服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 虚拟机中和虚拟机栈合二为一。

所以，为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地方法栈是线程私有的。

## 为什么要使用多线程呢?/多线程的方式可以实现并发，为什么要使用多线程？

从计算机底层来说: 线程可以比作是轻量级的进程，是程序执行的最小单位线程间的切换。和调度的成本远远小于进程。另外，多核时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。

从当代互联网发展趋势来说: 现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。

单核时代: 在单核时代多线程主要是为了提高CPU和IO设备的综合利用率。

多核时代: 多核时代多线程主要是为了提高 CPU利用率。可以让多个CPU核心被利用到。

## 在多线程中，什么是上下文切换(context-switching)？

上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。

一个CPU核心在任意时刻只能被一个线程使用，为了让多线程都能得到有效执行，CPU采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态把CPU让给其他线程使用，这个过程就属于一次上下文切换。然后当前线程在执行完CPU时间片切换到另一个线程之前会先保存自己的状态，以 便下次再切换回这个线程时，可以再加载这个线程的状态。

# Thread的使用

## 如何在Java中实现线程？

1. 继承Thread类实现多线程

继承Thread类，然后重写run方法（由于Java单继承的特性，这种方式用的比较少）

2. 实现Runnable()接口定制执行目标（target）类，实现其run()方法

推荐此方式。两个特点：

* 覆写Runnable接口实现多线程可以避免单继承局限
* 当执行目标类实现Runnable接口，此时执行目标（target）类和Thread是代理模式（子类负责真实业务的操作，thread负责资源调度与线程创建辅助真实业务

3. 实现Callable接口创建多线程（JDK1.5）
4. 通过线程池创建多线程。请参见后面线程池的面试题。

## 继承Thread类或者实现Runnable接口来创建线程，有何区别？

提示：这个问题很容易回答。Java不支持类的多重继承，但允许你调用多个接口。所以如果你要继承其他类，当然是调用Runnable接口好了。

参考答案，有两点：

1. 覆写Runnable接口实现多线程可以避免单继承局限
2. 实现Runnable()可以更好的体现共享的概念

## Thread 类中的start() 和 run() 方法有什么区别？

当直接调用`run()`方法的时候，它的行为就会和普通的方法一样，直接运行`run()`方法。只会是在原来的线程中调用，没有新的线程启动。只有调用`start()`方法才会启动新线程。`start()`方法被用来启动新创建的线程，使该被创建的线程状态变为可运行状态。

## Java中Runnable和Callable有什么不同？

Runnable和Callable都代表那些要在不同的线程中执行的任务目标target。Runnable从JDK1.0开始就有了，Callable是在JDK1.5增加的。它们的主要区别是Callable的` call() `方法可以返回值和抛出异常，而Runnable的`run()`方法没有这些功能。

**如何执行一个实现了 Callable 接口的任务呢？**

要执行一个 Callable 接口的任务必须要配合线程池（ExecutorService）来使用。从下图中可以看到，ExecutorService 中的 submit 方法可以接收 Callable 类型的任务，并且返回 Future 类型的对象。

**future对象**

在 JDK1.5 以前，我们异步的执行任务，将要处理的复杂操作交给其他线程处理，提高了程序的运行效率。我们并不关心其它线程的执行情况，也不需要其它线程返回结果。正是由于这种不关心的模式，决定了我们不能在线程中抛出异常。异常一般是由方法的调用者来处理的，试想下，如果我们在新的线程中抛出了异常，那么这个异常由谁来处理呢，又要在什么时候处理呢，毕竟没有任何线程关心着这个执行的任务。

随着业务越来越复杂，我们不仅需要其他线程来处理任务，有时候还需要获得其它线程处理任务后的返回结果。当然，你可以使用其它方式获得任务的返回结果，比如用一个全局变量来实现线程之间的通信，当需要使用这个全局变量时，就等待这个线程结束然后使用这个全局变量。比如 join()，wait()等，但仍然无法抛出异常，即无法抛出检查异常，每次都需要在线程内部进行捕获。

为了方便的解决上面的问题，在 JDK1.5后引入了 Callable 接口，并且通过 Future 接口可以获取任务的返回值。

## 什么是FutureTask？

如果在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些作业交给Future对象在后台完成，当主线程将来需要时，就可以通过Future对象获得后台作业的计算结果或者执行状态。

FutureTask 实现了 RunnableFuture 接口，而RunnableFuture 接口同时继承了 Runnable 接口和 Future 接口。所以FutureTask具有 Runnable 的特性，创建类继承 FutureTask类并重写 run() 后，可以创建线程来执行这个任务，并且可以获取任务的返回值。另外，FutureTask 可以把Runnable 类型的任务转换成 Callable 类型的任务来获取返回值。

## 如何创建守护线程？

使用Thread类的setDaemon(true)方法可以将线程设置为守护线程，需要注意的是，需要在调用start()方法前调用这个方法，否则会抛出IllegalThreadStateException异常。

如果在main方法里面创建一个守护线程，就算这个线程里面是个循环，当主线程退出的时候，这个守护线程也会自动结束。

## 用户线程和守护线程有什么区别？

当我们在Java程序中创建一个线程，它就被称为用户线程。一个守护线程是在后台执行并且不会阻止JVM终止的线程。当没有用户线程在运行的时候，JVM关闭程序并且退出。一个守护线程创建的子线程依然是守护线程。

1. 守护线程是用来为用户线程服务的，当一个程序中的所有用户线程都结束之后，无论守护线程是否在工作都会跟随用户线程一起结束；
2. 守护线程的子线程也是守护线程；
3. 守护线程的优先级和用户线程优先级一致；
4. 守护线程setDaemon(true) 如果设置在 start() 之后，程序执行会报错，守护线程也不会生效。

> 守护线程存在被JVM强行终止的风险，所以在守护线程中尽量不去访问系统资源，如文件句柄、数据库连接等。守护线程被强行终止时，可能会引发系统资源操作不负责任的中断，从而导致资源不可逆的损坏。

## Java多线程中调用wait() 和 sleep()方法有什么不同？

1. 两者最主要的区别在于: **sleep()** 方法没有释放锁，而 **wait()** 方法释放了锁 。 两者都可以暂停线程的执行。
2. `wait() `通常被用于线程间交互通信，` sleep() `通常被用于暂停执行。
3. `wait() `方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify() `或者 `notifyAll()` 方法。 `sleep()` 方法执行完成后，线程会自动苏醒。或者可以使用 `wait(long timeout)` 超时后线程会自动苏醒。

## 线程的常用方法有哪些

1. Thread.sleep(long millis)，一定是当前线程调用此方法，**当前线程进入TIMED_WAITING状态，但不释放对象锁**，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。

2. Thread.yield()，一定是当前线程调用此方法，**当前线程放弃获取的CPU时间片，但不释放锁资源，由运行状态变为就绪状态**，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停多长时间。

   1. yield仅能使一个线程从运行状态转到就绪状态，而不是阻塞状态。
   2. yield不能保证使得当前正在运行的线程迅速转换到就绪状态。
   3. 即使完成了迅速切换，系统通过线程调度机制从所有就绪线程中挑选下一个执行线程时，

   就绪的线程有可能被选中，也有可能不被选中，其调度的过程受到其他因素（如优先级）的影响。

3. thread.join()/thread.join(long millis)

   join是thread的方法，<u>在当前线程中调用另一个线程的join时，当前线程会挂起，等到另一个线程执行完毕之后才能继续</u>。 如果在当前线程中调用当前线程的join方法会怎么样?会将当前线程挂起，同时一直不会结束。 join方法是通过调用wait方法实现的。 

   **wait()的作用是让“当前线程”等待，而这里的“当前线程”是指当前运行的线程。虽然是调用子线程的 wait()方法，但是它是通过“主线程”去调用的;所以，休眠的是主线程，而不是“子线程”!**

   既然调用的是wait方法，那么肯定是释放锁，释放的锁是调用join方法线程所持有的锁。比如说在main方法里面调用`thread1.join()`

   **<u>没有在同步代码块里，调用join方法也不会抛出异常，释放的锁是当前这个对象锁。因为实际执行的代码是`this.wait();`，也就是释放this这个锁，在这里就是指的子线程。调用thread2.wait()的效果和thread2.join()效果一样的</u>**

4. obj.wait()，当前线程调用对象的`wait()`方法，**当前线程释放对象锁，进入等待队列**。依靠`notify()/notifyAll()`唤醒或者`wait(long timeout) timeout`时间到自动唤醒。

   <u>如果没有在同步代码里面进行wait方法，会抛出异常：java.lang.IllegalMonitorStateException。但是如果调用的是线程wait方法，就不会出错</u>

5. `obj.notify()`唤醒在此对象监视器上等待的单个线程，选择是任意性的。`notifyAll()`唤醒在此对象监视器上等待的所有线程。

6. LockSupport.park()/LockSupport.parkNanos(long nanos),LockSupport.parkUntil(long deadlines), 当前线程进入WAITING/TIMED_WAITING状态。对比wait方法,不需要获得锁就可以让线程进入WAITING/TIMED_WAITING状态，需要通过LockSupport.unpark(Thread thread)唤醒。

## Java线程的状态

![image-20240711151657396](https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimage-20240711151657396.png)

# 线程安全

## Java中的volatile 变量是什么？

在Java并发程序缺少同步类的情况下，多线程对成员变量的操作对其它线程是透明的。volatile变量可以保证下一个读取操作会在前一个写操作之后发生。线程都会直接从内存中读取该变量并且不缓存它。这就确保了线程读取到的变量是同内存中是一致的。

## 什么是线程安全？Vector是一个线程安全类吗？

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。一个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似的ArrayList不是线程安全的。

## Java中什么是竞态条件？

在大多数实际的多线程应用中，两个或两个以上的线程需要共享对同一数据的存取。如果多个线程存取相同的对象，并且每一个线程都调用了一个修改该对象状态的方法，根据线程访问数据的次序，可能会产生讹误的对象。这样的情况通常称为竞争条件。

## Java中如何停止一个线程？

Java提供了很丰富的API但没有为停止线程提供API。JDK 1.0本来有一些像stop(), suspend() 和resume()的控制方法，但是由于潜在的死锁威胁。因此在后续的JDK版本中他们被弃用了，之后JavaAPI的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。

- 1、任务中一般都会有循环结构，只要用一个标记控制住循环，就可以结束任务。
- 2、如果线程处于了`冻结状态`，无法读取标记，此时可以使用`interrupt()`方法将线程`从冻结状态强制恢复到运行状态中`来，让线程具备CPU的执行资格。

## Java中interrupted 和 isInterrupted方法的区别？

Thread.interrupt()方法: 作用是中断线程。将会设置该线程的中断状态位，即设置为true，但是该方法不会中断一个正在运行的线程。需要用户自己去监视线程的状态为并做处理。支持线程中断的方法（也就是线程中断后会抛出interruptedException的方法）就是在监视线程的中断状态，一旦线程的中断状态被置为“中断状态”，就会抛出中断异常。

这一方法实际完成的是，给受阻塞的线程发出一个中断信号，这样受阻线程检查到中断标识，就得以退出阻塞的状态。 如果线程被Object.wait, Thread.join和Thread.sleep三种方法之一阻塞，此时调用该线程的interrupt()方法，那么该线程将抛出一个 InterruptedException中断异常（该线程必须事先预备好处理此异常），从而提早地终结被阻塞状态。

然后interrupted()是静态方法：内部实现是调用的当前线程的isInterrupted()，并且会重置当前线程的中断状态。而`this.isInterrupted()`测试线程是否已经中断，但是不能清除状态标识。

> 在程序中，我们是不能随便中断一个线程的，我们无法知道这个线程正运行在什么状态，它可能持有某把锁，强行中断线程可能导致锁不能被释放的问题；或者线程可能在操作数据库，强行中断线程可能导致数据不一致的问题。

## 一个线程运行时发生异常会怎样？

如果异常没有被捕获该线程将会停止执行。Thread.UncaughtExceptionHandler是用于处理未捕获异常造成线程突然中断情况的一个内嵌接口。当一个未捕获异常将造成线程中断的时候，JVM会使用Thread.getUncaughtExceptionHandler()来查询线程的UncaughtExceptionHandler并将线程和异常作为参数传递给handler的uncaughtException()方法进行处理。

## 如何避免死锁？

死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的发生必须满足以下四个条件：

* 互斥条件：一个资源每次只能被一个进程使用。
* 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
* 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
* 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。

避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。

## 怎么检测一个线程是否拥有锁？

在java.lang.Thread中有一个方法叫holdsLock()，它返回true如果当且仅当当前线程拥有某个具体对象的锁。

## 你对线程优先级的理解是什么？

每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。

## 什么是线程调度器(Thread Scheduler)和时间分片(TimeSlicing)？

线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。

* 

# Synchronized

## 说一说自己对于 synchronized 关键字的了解

**synchronized** 关键字解决的是多个线程之间访问资源的同步性， **synchronized** 关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。 

另外，在jdk早期版本中， synchronized 属于重量级锁，效率低下。因为监视器锁(monitor)是依赖于底层的操作系统的 Mutex Lock 来实现的， java的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统实现线程之间的切换，也就是需要从用户态转换到内核态，这个状态之间的转换需要相对比⻓的时间，时间成本相对高。

庆幸的是在jdk1.6之后官方对从jvm层面对 synchronized大优化，所以现在的 synchronized 锁效率也优化得很不错了。对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。所以各种开源框架都大量使用了 synchronized 关键字。

## 说说自己是怎么使用 synchronized 关键字

synchronized 关键字最主要的三种使用方式:

1. **修饰实例方法: 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁** 
2. **修饰静态方法: 也就是给当前类加锁，会作用于类的所有对象实例** ，进入同步代码前要获得当前 class 的锁。因为静态成员不属于任何一个实例对象，是类成员( static 表明这是该类的一个 静态资源，不管 new 了多少个对象，只有一份)。所以，如果一个线程 调用一个实例对象的 非静态 synchronized 方法，而线程需要调用这个实例对象所属类的静态 synchronized 方法， 是允许的，不会发生互斥现象，因为访问静态 **synchronized** 方法占用的锁是当前类的锁，而访 问非静态 **synchronized** 方法占用的锁是当前实例对象锁。
3. **修饰代码块 :指定加锁对象，对给定对象类加锁**。 synchronized(this|object) 表示进入同步代码 库前要获得给定对象的锁。 synchronized(􏱈.class) 表示进入同步代码前要获得 当前 class 的锁

synchronized 关键字加到 static 静态方法和 synchronized(class) 代码块上都是是给  类上锁。

synchronized 关键字加到实例方法上是给对象实例上锁。
 尽量不要使用 synchronized(String a) 因为  中，字符串常量池具有缓存功能!

## Synchronized的执行过程/原理

1. 线程抢锁时，JVM首先检测内置锁对象Mark Word中biased_lock（偏向锁标识）是否设置成1，lock（锁标志位）是否为01，如果都满足，确认内置锁对象为可偏向状态。

2. 在内置锁对象确认为可偏向状态之后，JVM检查Mark Word中线程ID是否为抢锁线程ID，如果是，就表示抢锁线程处于偏向锁状态，抢锁线程快速获得锁，开始执行临界区代码。

   > 如果内置锁处于偏向状态，当有一个线程来竞争锁时，先用偏向锁，表示内置锁偏爱这个线程，这个线程要执行该锁关联的同步代码时，不需要再做任何检查和切换。偏向锁在竞争不激烈的情况下效率非常高。

3. 如果Mark Word中线程ID并未指向抢锁线程，就通过CAS操作竞争锁。如果竞争成功，就将Mark Word中线程ID设置为抢锁线程，偏向标志位设置为1，锁标志位设置为01，然后执行临界区代码，此时内置锁对象处于偏向锁状态。

4. 如果CAS操作竞争失败，或者锁处于偏向其它线程时，到达全局安全点偏向锁就会撤销并膨胀为轻量级锁。企图抢占的线程会通过自旋的形式尝试获取锁，不会阻塞抢锁线程，以便提高性能。

   > 哪个线程先占有锁对象，锁对象的Mark Word就指向哪个线程的栈帧中的锁记录。

5. JVM使用CAS将锁对象的Mark Word替换为抢锁线程的锁记录指针，如果成功，抢锁线程就获得锁。如果替换失败，就表示其他线程竞争锁，JVM尝试使用CAS自旋替换抢锁线程的锁记录指针，如果自旋成功（抢锁成功），那么锁对象依然处于轻量级锁状态。

6. 如果JVM的CAS替换锁记录指针自旋失败，轻量级锁膨胀为重量级锁，后面等待锁的线程也要进入阻塞状态。

   > 这个锁对象Mark Word再次发生变化，会指向一个监视器对象，该监视器对象用集合的形式来登记和管理排队的线程。

### 偏向锁撤销和膨胀

**偏向锁的撤销**

1. JVM需要等待一个全局安全点（global safe point），当JVM到达全局安全点后，所有的用户线程都是暂停的，当然，此时持有偏向锁的用户线程也被暂停了。
2. 遍历线程的栈帧，检查是否存在锁记录。如果存在锁记录，就需要清空锁记录，使其变成无锁状态，并修复锁记录指向的Mark Word，清除其线程ID。
3. 将当前锁升级（或碰撞）成轻量级锁。少数场景直接升级为重量级锁。
4. 唤醒当前线程。

所以，如果某些临界区存在两个及两个以上的线程竞争，那么偏向锁反而会降低性能。在这种情况下，可以在启动JVM时就把偏向锁的默认功能关闭。

**偏向锁的膨胀**

如果偏向锁被占据，一旦有第二个线程争抢这个对象，因为偏向锁不会主动释放，所以第二个线程可以看到内置锁偏向状态，这时表明在这个对象锁上已经存在竞争了。JVM检查原来持有该对象锁的占有线程是否依然存活，如果挂了，就可以将对象变为无锁状态，然后进行重新偏向，偏向为抢锁线程。

如果JVM检查到原来的线程依然存活，就表明原来的线程还在使用偏执锁，发生锁竞争，撤销原来的偏向锁，将偏向锁膨胀为轻量级锁。

偏向锁的撤销操作需要依赖JVM的全局安全点，从而会带来STW停顿。如果偏向锁撤销操作发生频繁，会招来频繁的STW，从而导致严重的性能问题。所以，对于高并发应用来说，一般建议关闭偏向锁。具体的方式：可以在启动命令中加上以下JVM参数：

-XX:-UseBiasedLocking

关闭偏向锁之后，Java内置锁默认会进入轻量级锁状态。

### 轻量级锁的原理

1. 在抢锁线程进入临界区之前，如果内置锁（临界区的同步对象）没有被锁定，JVM首先将在抢锁线程的栈帧中建立一个锁记录（Lock Record），用于存储对象目前MarkWord的拷贝。
2. 抢锁线程通过CAS自旋操作，尝试将内置锁对象头的Mark Word的ptr_to_lock_record（锁记录指针）更新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，这个线程就拥有了这个对象锁。然后JVM将Mard Word中的lock标记位改为00（轻量级锁标志），即表示该对象处于轻量级锁状态。
3. 最后将含有锁对象信息（如哈希表等）的旧Mard Word值保存在抢锁线程Lock Record的Displaced Mark Word（可以理解为放错地方的Mark Word）字段中，这一步起到备份的作用，以便锁释放之后，将旧的Mark Word值恢复到锁对象头部。抢锁线程将栈帧中的锁记录的owner指针指向锁对象。

**自旋锁:**由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来 回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态， 自旋锁可以通过设置-XX:+UseSpining来开启，自旋的默认次数是10次，可以使用-XX:PreBlockSpin设置。

**自适应锁:自适应锁就是自适应的自旋锁**，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状
态来决定。

**锁消除:**锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。 锁粗化:锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。

**偏向锁:**当线程访问同步块获取锁时，会在对象头和栈帧中的锁记录里存储偏向锁的线程ID，之后这个线程再次进入同步块时 都不需要CAS来加锁和解锁了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程 就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置-XX: +UseBiasedLocking开启偏向锁。

**轻量级锁:**JVM的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，JVM将会使用CAS方式来尝试获取锁，如 果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，当前线程就尝试自旋来获得锁。

## Java对象模型

在JVM中，Hotspot并没有将Java对象映射成C++对象，而是实现了Java的对象模型（OOP-Klass）。

* OOP 英文全程是Ordinary Object Pointe，即普通对象指针，看起来像个指针实际上是藏在指针里的对象，表示对象的实例信息。
* Klass 元数据和方法信息，用来描述 Java。是Java类的在C++中的表示形式，用来描述Java类的信息。

当加载一个Class时，会创建一个InstanceKlass对象，实例化的对象则对应InstanceOopDesc，instanceOopDesc继承自oopDesc，用于表示普通的Java对象，每次new一个Java对象就会创建一个新的instanceOopDesc实例，其中InstanceKlass存放在元空间，InstanceOopDesc存放在堆中。

Java对象（Object实例）结构包括三部分：对象头、对象体和对齐字节：

1. 对象头包括三个字段，第一个字段叫作Mark Word（标记字），用于存储自身运行时的数据例如GC标志位、哈希码、锁状态等信息；第二个字段叫作Class Pointer（类对象指针），用于存放此对象的元数据（InstanceKlass）的地址。虚拟机通过此指针可以确定这个对象是哪个类的实例；第三个字段叫作Array Length（数组长度）。如果对象是一个Java数组，那么此字段必须有，用于记录数组长度的数据；如果对象不是一个Java数组，那么此字段不存在，所以这是一个可选字段。
2. 对象体包含了对象的实例变量（成员变量），用于成员属性值，包括父类的成员属性值。
3. 对齐字节也叫作填充对齐，其作用是用来保证Java对象在所占内存字节数为8的倍数（8N bytes）。

## Java的内置锁

Java内置锁的涉及很多重要信息，这些都存放在对象结构中，并且存放于对象头的Mark Word字段中。Java内置锁的状态总共有4种，级别由低到高依次为：无锁、偏向锁、轻量级锁和重量级锁。4种状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级，也就是说只能进行锁升级。

 Mark Word 的构成

<img src="https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimage-20240712095634890.png" alt="image-20240712095634890" style="zoom: 33%;" />

* age：4位的Java对象分代年龄。在GC中，如果对象在Survivor区复制一次，年龄增加1。当对象达到设定的阈值时，将会晋升到老年代。默认情况下，并行GC的年龄阈值为15，并发GC的年龄阈值为6。**由于age只有4位，因此最大值为15，这就是-XX:MaxTenuringThreshold选项最大值为15的原因。**
* identity_hashcode：31位的对象标识HashCode（哈希码）采用延迟加载技术，当调用Object.hashCode()方法或者System.identityHashCode()方法计算对象的HashCode后，其结果将被写到该对象头中。**当对象被锁定时，该值会移动到Monitor（监视器）中。**
* thread：54位的线程ID值为持有偏向锁的线程ID。
* epoch：偏向时间戳。
* ptr_to_lock_record：占62位，在轻量级锁的状态下指向栈帧中锁记录的指针。
* ptr_to_heavyweight_monitor：占62位，在重量级锁的状态下，指向对象监视器的指针。

## Java中synchronized 和 ReentrantLock 有什么不同？

相比于synchronized，ReentrantLock需要显式的获取锁和释放锁，相对现在基本都是用JDK7和JDK8的 版本，ReentrantLock的效率和synchronized区别基本可以持平了。他们的主要区别有以下几点:

1. 等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。
2. 公平锁:synchronized和ReentrantLock默认都是非公平锁，但是ReentrantLock可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。
3. 绑定多个条件:ReentrantLock可以同时绑定多个Condition条件对象。
4. ReentrantLock基于AQS(AbstractQueuedSynchronizer 抽象队列同步器)实现

## 什么时候会使用ReentrantLock而不是Synchronized? 

* 场景1:如果发现该操作已经在执行中则不再执行(有状态执行)

  * 用在定时任务时，如果任务执行时间可能超过下次计划执行时间，确保该有状态任务只有一个 正在执行，忽略重复触发。 

  * 用在界面交互时点击执行较长时间请求操作时，防止多次点击导致后台重复执行(忽略重复触发)。

* 场景2: 如果发现该操作已经在执行，等待一个一个执行(公平锁) 
* 场景3:如果发现该操作已经在执行，则尝试等待一段时间，等待超时则不执行(设置等待的时 间)
* 场景4:可中断正在进行的操作立刻释放锁:lock.lockInterruptibly()



33） 有三个线程T1，T2，T3，怎么确保它们按顺序执行（确保

main()方法所在的线程是Java程序最后结束的线程）？

在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的join()方法在一个线程中启动另一个

线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个(T3调用

T2，T2调用T1)，这样T1就会先完成而T3最后完成。

## 如果同步块内的线程抛出异常会发生什么？

无论你的同步块是正常还是异常退出的，里面的线程都会释放锁，所以对比锁接口我们更喜欢同步块，因为它不用花费精力去释放锁，该功能可以在finally block里释放锁实现。

## Thread.sleep()和LockSupport.park()的区别

LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。

1. 从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源;
2. Thread.sleep()没法从外部唤醒，只能自己醒过来;LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒;
3. Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出;LockSupport.park()方法不需要捕获中断异常;
4. Thread.sleep()本身就是一个native方法;LockSupport.park()底层是调用的Unsafe的native方法;

## Object.wait()和LockSupport.park()的区别

1. Object.wait()方法需要在synchronized块中执行;LockSupport.park()可以在任意地方执行;
2. Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出;LockSupport.park()不需要捕获中断异常
3. Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容;LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容;
4. 如果在wait()之前执行了notify()会怎样?抛出IllegalMonitorStateException异常;如果在park()之前执行了unpark()会怎样?线程不会被阻塞，直接跳过park()，继续执行后续内容

## 显式锁的分类

显式锁有很多种，从不同的角度来看，显式锁大概有以下几种分类：可重入锁与不可重入锁、悲观锁和乐观锁、公平锁和非公平锁、共享锁和独占锁、可中断锁和不可中断锁。

1. 可重入锁与不可重入锁。可重入锁也被称为递归锁，指的是一个线程可以多次抢占同一个锁。例如，线程A在进入外层函数抢占了一个Lock显式锁之后，当线程A继续进入内层函数时，如果遇到有抢占同一个Lock显式锁的代码，线程A依然可以抢到该Lock显式锁。

2. 悲观锁和乐观锁。

   悲观锁就是悲观思想，每次去入临界区操作数据的时候都认为别的线程会修改，所以线程每次在读写数据时都会上锁，锁住同步资源，这样其他线程需要读写这个数据时就会阻塞，一直等到拿到锁。总体来说，悲观锁适用于写多读少的场景，遇到高并发写的可能性高。Java的Synchronized重量级锁是一种悲观锁。

   乐观锁是一种乐观思想，每次去拿数据的时候都认为别的线程不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样就更新），如果失败就要重复读-比较-写的操作。总体来说，乐观锁适用于读多写少的场景，遇到高并发写的可能性低。Java中的乐观锁基本都是通过CAS自旋操作实现的。

3. 公平锁和非公平锁。

   公平锁是指不同的线程抢占锁的机会是公平的、平等的，从抢占时间上来说，先对锁进行抢占的线程一定被先满足，抢锁成功的次序体现为FIFO（先进先出）顺序。简单来说，公平锁就是保障了各个线程获取锁都是按照顺序来的，先到的线程先获取锁。

4. 可中断锁和不可中断锁。

   如果某一线程A正占有锁在执行临界区代码，另一线程B正在阻塞式抢占锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己的阻塞等待，这种就是可中断锁。

5. 独占锁和共享锁。

   独占锁指的是每次只有一个线程能持有的锁。独占锁是一种悲观保守的加锁策略，它不必要地限制了读/读竞争，如果某个只读线程获取锁，那么其他的读线程都只能等待，这种情况下就限制了读操作的并发性，因为读操作并不会影响数据的一致性。

   共享锁允许多个线程同时获取锁，容许线程并发进入临界区。与独占锁不同，共享锁是一种

   乐观锁，它放宽了加锁策略，并不限制读/读竞争，允许多个执行读操作的线程同时访问共享资源。JUC的ReentrantReadWriteLock（读写锁）类是一个共享锁实现类。使用该读写锁时，读操作可以有很多线程一起读，但是写操作只能有一个线程去写，而且在写入的时候，别的线程也不能进行读的操作。

# CAS

## 什么是 CAS

CAS(Compare And Swap 比较并且替换)是乐观锁的一种实现方式，是一种轻量级锁，比较并交换，主要 是通过处理器的指令来保证操作的原子性，它包含三个操作数:

1. 变量内存地址，V表示 
2. 旧的预期值，A表示
3. 准备设置的新值，B表示

当执行CAS指令时，只有当V等于A时，才会用B去更新V的值，否则就不会执行更新操作

## CAS有什么缺点吗?

CAS的缺点主要有3点:

1. **ABA问题:**ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A， 但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的 问题大部分场景下都不影响并发的最终效果。

   > 小牛取款，由于机器不太好使，多点了几次取款操作。后台threadA和threadB工作。此时threadA操作成功(100->50)，threadB阻塞。正好牛妈打款50元给小牛(50->100)，threadC执行成功，之后threadB运行了，又改为(100->50)。少了50块钱。

2. **循环时间长开销大:**自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。

3. **只能保证一个共享变量的原子操作:**只对一个共享变量操作可以保证原子性，但是多个则不行，多个可 以通过AtomicReference来处理或者使用锁synchronized实现。 多变量原子问题:类似AtomicInteger、AtomicLong、AtomicBoolean这些Atomic都是对基本数据类型进行 CAS操作，如果我们需要对多个变量保证原子性呢? 那么就需要使用AtomicReference，多个变量可以封装为一个自定义对象，使用AtomicReference的话就可 以比较对象的引用是不是同一个，保证多个变量的原子性

4. **在部分CPU平台上存在“总线风暴”问题：**CAS操作和volatile一样也需要CPU进行通过MESI协议各个内核的“Cache一致性”，会通过

   CPU的BUS（总线）发送大量MESI协议相关的消息，产生“Cache一致性流量”。因为总线被设计为固定的“通信能力”，如果Cache一致性流量过大，总线将成为瓶颈，这就是所谓的“总线风暴”。

## ABA 问题解决方案

1. 使用AtomicStampedReference 解决ABA 问题。AtomicStampReference的compareAndSet()方法首先检查当前的对象引用值是否等于预期引用，并且当前印戳标志是否等于预期标志，如果全部相等，就以原子方式将引用值和印戳标志的值更新为给定的更新值。
2. 使用AtomicMarkableReference 解决ABA 问题。AtomicMarkableReference是AtomicStampedReference的简化版，不关心修改过几次，仅仅关心是否修改过。因此，其标记属性mark是boolean类型，而不是数字类型，标记属性mark仅记录值是否修改过。

## 提升高幵发场景下 CAS 操作的性能

1. 分散操作热点，使用LongAdder替代基础原子类AtomicLong，LongAdder将单个CAS热点（value值）分散到一个cells数组中。

   **AtomicLong**是多个线程针对单个热点值value进行原子操作。而**LongAdder**是每个线程拥有自己的槽，各个线程一般只对自己槽中的那个值进行CAS操作。

   > 比如有三个ThreadA、ThreadB、ThreadC，每个线程对value增加10。

   对于**AtomicLong**，最终结果的计算始终是下面这个形式：
   𝑣𝑎𝑙𝑢𝑒=10+10+10=30*v**a**l**u**e*=10+10+10=30

   但是对于**LongAdder**来说，内部有一个`base`变量，一个`Cell[]`数组。
   `base`变量：非竞态条件下，直接累加到该变量上
   `Cell[]`数组：竞态条件下，累加个各个线程自己的槽`Cell[i]`中

2. 使用队列削峰，将发生CAS争用的线程加入一个队列中排队，降低CAS争用的激烈程度。JUC中非常重要的基础类AQS（抽象队列同步器）就是这么做的。

# AQS

## AQS原理

AQS 核心思想是，**AQS**内部维护一个**state**状态位，如果被请求的共享资源空闲，尝试加锁的时 候通过**CAS(CompareAndSwap)**修改值，如果成功设置为**1**，并且把当前线程**ID**赋值，则代表加锁 成功。如果被请求的共享资源被占用，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程 释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把state重新置为**0**，同时当前线程 **ID**置为空。这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列 中。

CLH队列是一个虚拟的双向队列(虚拟的双向队列即不存在 队列实例，仅存在结点之间的关联关系)。 是将每条请求共享资源的线程封装成一个 锁队列的一个结点()来实现锁的分配。

## AQS 了解么?

 Q:某个线程获取锁失败的后续流程是什么呢?

A:如果线程获取锁失败后，将这个线程封装成一个节点通过CAS自旋操作加入到等待队列中，找 到一个安全点进入等待状态，堵塞调用栈，有机会时(轮到自己，会被unpark())会去尝试获取资 源。获取到资源后才返回。

Q:既然说到了排队等候机制，那么就一定会有某种队列形成，这样的队列是什么数据结构呢?

A:是CLH变体的FIFO双端队列，头结点不存储数据。

Q:处于排队等候机制中的线程，什么时候可以有机会获取锁呢?

A:一个线程获取锁失败了，被放入等待队列，acquireQueued会把放入队列中的线程不断去获取 锁，直到获取成功或者不再需要获取(中断)

Q:如果处于排队等候机制中的线程一直无法获取锁，需要一直等待么?还是有别的策略来解决 这一问题?

A:线程所在节点的状态会变成取消状态，取消状态的节点会从队列中释放，如果等待过程中没 有成功获取资源(如timeout，或者可中断的情况下被中断了)，那么取消结点在队列中的等待。

Q:Lock函数通过Acquire方法进行加锁，但是具体是如何加锁的呢?

A:AQS的Acquire会调用tryAcquire方法，tryAcquire由各个自定义同步器实现，通过tryAcquire完成 加锁过程。ReentrantLock是通过修改State字段表示的同步状态来实现加锁的。

# 线程池

## 线程池主要解决的问题

1. 提升性能：线程池能独立负责线程的创建、维护和分配。在执行大量异步任务时，可以不需要自己创建线程，而是将任务交给线程池。线程池能尽可能使用空闲的线程去执行异步任务，最大限度地对已经创建的线程进行复用，能够降低线程创建和销毁造成的消耗。
2. 线程管理：每个Java线程池会保持一些基本的线程统计信息，例如完成的任务数量、空闲时间等，使用线程池可以进行统一的分配，调优和监控。

## **ThreadPoolExecutor** 构造函数重要参数

1. **corePoolSize**-线程池核心线程数量，核心线程不会被回收，即使没有任务执行，也会保持空闲状态。如果核心线程池中的线程少于此数目，则在执行任务时创建。

2. **maximumPoolSize**-线程池允许最大的线程数，当线程数量达到核心线程数，且任务排队队列塞满任务了之后，继续创建线程。

3. **workQueue**-阻塞队列，当前线程数超过核心线程数时，新的任务会处在等待状态，并存在阻塞中，阻塞队列是一个先进先出的阻塞式队列实现

4. **keepAliveTime**-空闲线程存活时间，当线程池中的线程数量大于核心线程池数量的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了空闲线程存活时间才会被回收销毁。
   **unit**-keepAliveTime 参数的时间单位。

5. **threadFactory**  创建新线程的时候会用到。定位。

6. **handler** 饱和策略。如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时， ThreadPoolTaskExecutor 定义一些策略。

   * AbortPolicy:为线程池默认的拒绝策略，该策略直接抛异常处理。

   * DiscardPolicy:直接抛弃不处理。 

   * DiscardOldestPolicy:丢弃队列中最老的任务。 

   * CallerRunsPolicy:将任务分配给当前执行execute方法线程来处理。

   * 自定义策略:如果以上拒绝策略都不符合需求，那么可自定义一个拒绝策略，实现RejectedExecutionHandler

     接口的rejectedExecution方法即可。

## 线程池原理

1. 如果当前工作线程数量小于核心线程池数量，执行器总是优先创建一个任务线程，而不是从线程队列中获取一个空闲线程。
2. 如果线程池中总的任务数量大于核心线程池数量，新接收的任务将被加入到阻塞队列中，一直到阻塞队列已满。在核心线程池数量已经用完、阻塞队列没有满的场景下，线程池不会为新任务创建一个新线程。
3. 在核心线程池数量已经用完、 阻塞队列也已经满了的场景下，如果线程池接收到新的任务，将会为新任务创建一个线程（非核心线程），并且立即开始执行新任务。
4. 如果达到maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理

## Java线程池中submit() 和 execute()方法有什么区别？

两个方法都可以向线程池提交任务，execute()方法的返回类型是void，它定义在Executor接口中, 而submit()方法可以返回持有计算结果的Future对象，它定义在ExecutorService接口中，它扩展了Executor接口，其它线程池类像ThreadPoolExecutor和ScheduledThreadPoolExecutor都有这些方法。更多详细信息请点击这里。

## 一个线程池中的线程异常了，那么线程池会怎么处理这个线程? 

当一个线程池里面的线程异常后:

* 当执行方式是execute时,可以看到堆栈异常的输出。
* 当执行方式是submit时,堆栈异常没有输出。但是调用`Future.get()`方法时，可以捕获到异常。
* 有线程异常并不会影响线程池里面其他线程的正常执行。 线程池会把这个线程移除掉，并创建一个新的线程放到线程池中。

## 任务阻塞队列有哪些

1. ArrayBlockingQueue：**是一个数组实现的有界阻塞队列（有界队列）**，队列中的元素按FIFO排序**。ArrayBlockingQueue在创建时必须设置大小**，接收的任务超出corePoolSize数量时，任务被缓存到该阻塞队列中，任务缓存的数量只能为创建时设置的大小，若该阻塞队列满，则会为新的任务创建线程，直到线程池中的线程总数大于maximumPoolSize。
2. LinkedBlockingQueue：**是一个基于链表实现的阻塞队列**，按FIFO排序任务，可以设置容量（有界队列），不设置容量则默认使用Integer.Max_VALUE作为容量（无界队列）。该队列的吞吐量高于ArrayBlockingQueue。如果不设置LinkedBlockingQueue的容量（无界队列），当接收的任务数量超出corePoolSize数量时，则新任务可以被无限制地缓存到该阻塞队列中，直到资源耗尽。**有两个快捷创建线程池的工厂方法Executors.newSingleThreadExecutor和Executors.newFixedThreadPool使用了这个队列，并且都没有设置容量（无界队列）**。
3. PriorityBlockingQueue：**是具有优先级的无界队列。**
4. DelayQueue：这是一个**无界阻塞延迟队列**，底层基于PriorityBlockingQueue实现，**队列中每个元素都有过期时间，当从队列获取元素（元素出队）时，只有已经过期的元素才会出队，而队列头部的元素是最先过期的元素**。**快捷工厂方法`Executors.newScheduledThreadPool`所创建的线程池使用此队列。**
5. SynchronousQueue（同步队列）：是**一个不存储元素的阻塞队列**，**每个插入操作必须等到另一个线程的调用移除操作，否则插入操作一直处于阻塞状态(只是多个线程之间数据交换的媒介)**，其吞吐量通常高于LinkedBlockingQueue**。快捷工厂方法Executors.newCachedThreadPool所创建的线程池使用此队列**。与前面的队列相比，这个队列比较特殊，它不会保存提交的任务，而是直接新建一个线程来执行新来的任务。

## 如果你提交任务时，线程池队列已满。会时发会生什么？

这个问题问得很狡猾，许多程序员会认为该任务会阻塞直到线程池队列有空位。事实上如果一个任务不能被调度执行那么ThreadPoolExecutor’s submit()方法将会抛出一个RejectedExecutionException异常。

## 关闭线程池的方法

大家可以结合shutdown()、 shutdownNow()和awaitTermination()三个方法去优雅关闭一个线程池，

大致分为以下几步：

1. 执行`shutdown()`方法，拒绝新任务的提交，并等待所有任务有序地执行完毕。
2. 执行`awaitTermination（long timeout,TimeUnit unit）`方法，指定超时时间，判断是否已经关闭所有任务，线程池关闭完成。
3. 如果`awaitTermination()`方法返回false，或者被中断，就调用`shutDownNow()`方法立即关闭线程池所有任务。
4. 补充执行`awaitTermination（long timeout,TimeUnit unit）`方法，判断线程池是否关闭完成。如果超时，就可以进入循环关闭，循环一定的次数（如1000次），不断关闭线程池，直到其关闭或者循环结束。

`shutdown()`方法首先加锁，其次检查调用者是否具有执行线程池关闭的Java Security权限。接着`shutdown()`方法会将线程池状态变为SHUTDOWN，在这之后线程池不再接受提交的新任务。此时如果还继续往线程池提交任务，将会使用线程池拒绝策略响应.

`shutdownNow()`方法将会把线程池状态设置为STOP，然后中断interrupt所有线程（包括工作线程以及空闲线程），最后清空工作队列，取出工作队列中所有未完成的任务返回给调用者。这样通过工作线程的interrupt()实例方法设置了中断状态，需要用户程序主动配合线程进行中断操作。

## 介绍使用Executors工厂方法快捷创建线程池将会面临的潜在问题

1. FixedThreadPool和SingleThreadPool

   这两个工厂方法所创建的线程池，工作队列（任务排队的队列）长度都为Integer.MAX_VALUE，可能会堆积大量的任务，从而导致OOM（即耗尽内存资源）。

2. CachedThreadPool和ScheduledThreadPool

   这两个工厂方法所创建的线程池允许创建的线程数量为Integer.MAX_VALUE，可能会导致创建大量的线程，从而导致OOM问题。

## 确定线程池的线程数

* **为IO 密集型任务确定线程数：**由于IO密集型任务的CPU使用率较低，导致线程空余时间很多，因此通常需要开CPU核心数两倍的线程。Netty的IO处理任务就是典型的IO密集型任务。所以，Netty的Reactor（反应器）实现类（定制版的线程池）的IO处理线程数默认正好为CPU核数的两倍。

* **为CPU 密集型任务确定线程数：**CPU密集型任务虽然也可以并行完成，但是并行的任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以要最高效地利用CPU，**CPU密集型任务并行执行的数量应当等于CPU的核心数。**比如说4个核心的CPU，通过4个线程并行执行4个CPU密集型任务，此时的效率是最高的。

* **为混合型任务确定线程数：**混合型任务既要执行逻辑计算，又要进行大量非CPU耗时操作<u>（如RPC调用、数据库访问、网络通信等）</u>，所以混合型任务CPU利用率不是太高，非CPU耗时往往是CPU耗时的数倍。

  在为混合型任务创建线程池时，如何确定线程数呢？业界有一个比较成熟的估算公式，具体如下：

  **最佳线程数目 =（线程等待时间与线程CPU时间之比 + 1）* CPU核数**

  由于Redis基本都是内存操作，在这种情况下单线程可以高效地利用CPU，多线程反而不是太适用。**多线程适用场景一般是：存在相当比例非CPU耗时操作，如IO、网络操作，需要尽量提高并行化比率以提升CPU的利用率。**

# ThreadLocal

## ThreadLocal 了解么?

ThreadLocal可以理解为线程本地变量，他会在每个线程都创建一个副本，那么在线程之间访问内部副本变量就行了，做到了线程之间互相隔离，避免了线程安全的问题。

每个线程内维护一个 ThreadLocalMap，这个Map的 key是ThreadLocal实例本身，value是真正需要存储的值。get方法[Thread.currentThread]获得到该线程的ThreadLocalMap之后，调用getEntry()在该线程的ThreadLocalMap中根据 ThreadLocal的对象值获得该ThreadLocal相应的value。ThreadLocalMap是使用ThreadLocal的弱引用作为Key的，弱引用的对象在 GC 时会被回收

ThreadLocal的流程：

set(T value)方法的执行流程，大致如下：

1. 获得当前线程，然后获得当前线程的ThreadLocalMap成员，暂存于map变量。
2. 如果map不为空，就将Value设置到map中，当前的ThreadLocal作为key。
3. 如果map为空，为该线程创建map，然后设置第一个“Key-Value对”， Key为当前的ThreadLocal实例，Value为set方法的参数value值。

T get()方法的执行流程，大致如下：

1. 先尝试获得当前线程，然后获得当前线程的ThreadLocalMap成员，暂存于map变量。
2. 如果获得的map不为空，那么以当前ThreadLocal实例为Key尝试获得map中的Entry （条目）。
3. 如果Entry条目不为空，就返回Entry中的Value。
4. 如果Entry为空，就通过调用initialValue初始化钩子函数获取“ThreadLocal”初始值，并设置在map中。如果map不存在，还会给当前线程创建新ThreadLocalMap成员，并绑定第一个“Key-Value对”。

ThreadLocalMap的流程，主要说一下set：

1. 根据key的HashCode，找到key在数组上的槽点i。
2. 从槽点i开始向后循环搜索，找空余槽点（空余位置）或者找现有槽点。如果没有现有槽点，则必定有空余槽点，因为没有空间时会扩容。正常到这一步就return了。
3. 没有找到现有的槽点，增加新的Entry。接着清理Key为null的无效Entry。最后判断现有条目数量是否大于扩容因子值，然后进行扩容。

## 为什么ThreadLocal中Entry是弱引用，而且Entry的key也是弱引用？

弱引用的目的是为了防止内存泄露，如果是强引用那么ThreadLocal对象除非线程结束否则始终无法被回收，弱引用则会在下一次GC的时候被回收。 

但是这样还是会存在内存泄露的问题，假如key和ThreadLocal对象被回收之后，entry中就存在key为null，但是value 有值的entry对象，但是永远没办法被访问到，同样除非线程结束运行。但是只要ThreadLocal使用恰当，在使用完之后调用remove方法删除Entry对象，实际上是不会出现这个问题的。

**总结一下，使用ThreadLocal会发生内存泄漏的前提条件如下：**

1. 线程长时间运行而没有被销毁。线程池中的Thread实例很容易满足此条件。
2. ThreadLocal引用被设置为null，且后续在同一Thread实例的执行期间，没有发生对其他ThreadLocal实例的`get()`、`set()`或`remove()`操作。但是只要存在一个针对任何ThreadLocal实例的`get()`、`set()`。`funcA()`的栈帧或remove()操作，就会触发Thread实例拥有的ThreadLocalMap的Key为null的Entry清理工作，释放掉ThreadLocal弱引用为null的Entry。

## 编程规范为什么推荐使用static final 修饰ThreadLocal 对象

为了避免重复创建TSO（thread specific object，即与线程相关的变量）。因此，一般我们将ThreadLocal使用static修饰即可。另外因为是一个全局使用的，可能在静态方法中使用，这样必须是static的。然后声明一个静态引用变量，会在类第一次被使用时装载，只会分配一次存储空间，此类的所有实例都会共享这个存储空间，所以使用static修饰ThreadLocal就会节约内存空间(因为就这一个实例呀)

为了确保ThreadLocal实例的唯一性，除了使用static修饰之外，还会使用final进行加强修饰，以防止其在使用过程中发生动态变更。(其实就是final的作用)

使用static、final修饰ThreadLocal实例也会带来副作用，使得Thread实例内部的ThreadLocalMap中Entry的Key在Thread实例的生命期内将始终保持为非null。所以，在使用完static、final修饰ThreadLocal实例，使用完后必须使用remove()进行手动释放。

> ThreadLocalMap中Entry继承自WeakReference，正常来说GC后Entry的key即ThreadLocal应该被回收。但因为static是强引用的原因，当GC时，key不会被回收，同时Entry也不会被放入ReferenceQueue队列中（事实上，ThreadLocalMap也没有类似WeakHashMap的回收Entry的机制），Entry对象中的value也不会被回收，所以我们必须手动清除Entry以避免内存泄露

## 为什么自增运算不是线程安全的呢？

一个自增运算符是一个复合操作，至少包括三个JVM指令：“内存取值”“寄存器增加1”“存值到内存”。这三个指令在JVM内部是独立进行的，中间完全可能会出现多个线程并发进行。比如在amount=100时，假设有三个线程同一时间读取amount值，读到的都是100，增加1后结果为101，三个线程都将结果存入到amount的内存，amount的结果是101，而不是103。

实际上是4步：

1. 获取当前sum变量的值，并且放入栈顶。
2. 将常量1放入栈顶。
3. 将当前栈顶中两个值（sum的值和1）相加，并把结果放入栈顶。
4. 把栈顶的结果再赋值给sum变量。



如何在Java中创建Immutable对象？

Immutable对象可以在没有同步的情况下共享，降低了对该对象进行并发访问时的同步化开销。要创建

不可变类，要实现下面几个步骤：通过构造方法初始化所有成员、对变量不要提供setter方法、将所有

的成员声明为私有的，这样就不允许直接访问这些成员、在getter方法中，不要直接返回对象本身，而

是克隆对象，并返回对象的拷贝。

44） Java中的ReadWriteLock是什么？

一般而言，读写锁是用来提升并发程序性能的锁分离技术的成果。Java中的ReadWriteLock是Java 5

中新增的一个接口，一个ReadWriteLock维护一对关联的锁，一个用于只读操作一个用于写。在没有写

线程的情况下一个读锁可能会同时被多个读线程持有。写锁是独占的，你可以使用JDK中的

ReentrantReadWriteLock来实现这个规则，它最多支持65535个写锁和65535个读锁。

46）volatile 变量和 atomic 变量有什么不同？

这是个有趣的问题。首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。Volatile变量可

以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用volatile修饰

count变量那么 count++ 操作就不是原子性的。而AtomicInteger类提供的atomic方法可以让这种操作

具有原子性如getAndIncrement()方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变

量也可以进行相似操作。

48） 单例模式的双检锁是什么？

这个问题在Java面试中经常被问到，但是面试官对回答此问题的满意度仅为50%。一半的人写不出双检

锁还有一半的人说不出它的隐患和Java1.5是如何对它修正的。它其实是一个用来创建线程安全的单例的

老方法，当单例实例第一次被创建时它试图用单个锁进行性能优化，但是由于太过于复杂在JDK1.4中它

是失败的。

49） 如何在Java中创建线程安全的Singleton？

这是上面那个问题的后续，如果你不喜欢双检锁而面试官问了创建Singleton类的替代方法，你可以利

用JVM的类加载和静态变量初始化特征来创建Singleton实例，或者是利用枚举类型来创建Singleton。

\50) 写出3条你遵循的多线程最佳实践

以下三条最佳实践大多数Java程序员都应该遵循：

给你的线程起个有意义的名字。

这样可以方便找bug或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比

Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要

框架甚至JDK都遵循这个最佳实践。

避免锁定和缩小同步的范围

锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相

对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。

多用同步类少用wait 和 notify

首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而

用wait和notify很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的JDK中

它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。

多用并发集合少用同步集合

这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程

时使用并发集合效果更好。如果下一次你需要用到map，你应该首先想到用ConcurrentHashMap。

\52) Java中的fork join框架是什么？

fork join框架是JDK7中出现的一款高效的工具，Java开发人员可以通过它充分利用现代服务器上的多

处理器。它是专门为了那些可以递归划分成许多子模块设计的，目的是将所有可用的处理能力用来提升

程序的性能。fork join框架一个巨大的优势是它使用了工作窃取算法，可以完成更多任务的工作线程可

以从其它线程中窃取任务来执行。

\55) 什么是Java线程转储(Thread Dump)，如何得到它？

线程转储是一个JVM活动线程的列表，它对于分析系统瓶颈和死锁非常有用。有很多方法可以获取线程

转储——使用Profiler，Kill -3命令，jstack工具等等。我们更喜欢jstack工具，因为它容易使用并且是

JDK自带的。由于它是一个基于终端的工具，所以我们可以编写一些脚本去定时的产生线程转储以待分

析。

56) 什么是Java Timer类？如何创建一个有特定时间间隔的任务？

java.util.Timer是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer类可以用安排

一次性任务或者周期任务。

java.util.TimerTask是一个实现了Runnable接口的抽象类，我们需要去继承这个类来创建我们自己的定

时任务并使用Timer去安排它的执行。

58） Java Concurrency API中的Lock接口(Lock interface)是什

么？对比同步它有什么优势？

Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同

的性质，并且可以支持多个相关类的条件对象。

它的优势有：

可以使锁更公平

可以使线程在等待锁的时候响应中断

可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间

可以在不同的范围，以不同的顺序获取和释放锁

64） 什么是并发容器的实现？

Java集合类都是快速失败的，这就意味着当集合被改变且一个线程在使用迭代器遍历集合的时候，迭代

器的next()方法将抛出ConcurrentModificationException异常。

并发容器：并发容器是针对多个线程并发访问设计的，在jdk5.0引入了concurrent包，其中提供了很多

并发容器，如ConcurrentHashMap，CopyOnWriteArrayList等。并发容器使用了与同步容器完全不同

的加锁策略来提供更高的并发性和伸缩性，例如在ConcurrentHashMap中采用了一种粒度更细的加锁

机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问map，并且执行读操作的

线程和写操作的线程也可以并发的访问map，同时允许一定数量的写操作线程并发地修改map，所以它

可以在并发环境下实现更高的吞吐量。



69、如何确保线程安全？

在Java中可以有很多方法来保证线程安全——

同步，

使用原子类(atomic concurrent classes)，

使用显示锁，

page:12/48 of 尼恩Java硬核架构班：狠卷3高架构，卷透底层技术，走向技术自由！使用volatile关键字，

使用不变类





## AQS 组件总结

Java中的Semaphore是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接池。

**Semaphore** (信号量)-允许多个线程同时访问: synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源， Semaphore 信号量可以指定多个线程同时访问某个资源。

**CountDownLatch** (倒计时器): CountDownLatch 是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结 束，再开始执行。

**CyclicBarrier** (循环栅栏): CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和CountDownLatch 类似。 CyclicBarrier 的字面意思是可循环使用( Cyclic )的屏障
 ( Barrier )。它要做的事情是，让一组线程到达一个屏障(也可以叫同步点)时被阻塞， 直到最后一个线程到达屏障时，屏障才会开⻔，所有被屏障拦截的线程才会继续干活。 CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties) ，其参数表示屏障拦截的线程 数量，每个线程调用 await() 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

# 可见行和有序性

## Java内存模型是什么？

Java内存模型的规定如下：

1. 所有变量存储在主存中。
2. 每个线程都有自己的工作内存，且对变量的操作都是在工作内存中进行的。
3. 不同线程之间无法直接访问彼此工作内存中的变量，要想访问只能通过主存来传递。

因此，JMM模型也需要解决代码重排序和缓存可见性问题。JMM提供了一套自己的方案去禁用缓存以及禁止重排序来解决这些可见性和有序性问题。JMM提供的方案包括大家都很熟悉的volatile、synchronized、 final等。 JMM定义了一些内存操作的抽象指令集，然后将这些抽象指令包含到Java的volatile、synchronized等关键字的语义中，并要求JVM在实现这些关键字时必须具备其包含的JMM抽象指令的能力。

## JMM 与JMM 物理内存的区别

1. 对于硬件内存来说只有寄存器、缓存内存、主存的概念，并没有工作内存（线程私有数据区域）和主存（堆内存）之分，也就是说Java内存模型对内存的划分对硬件内存并没有任何影响，因为JMM只是一种抽象的概念，是一组规则，并不实际存在，
2. 无论是JMM工作内存的数据还是主存的数据，对于计算机硬件来说都会存储在计算机主存中，当然也有可能存储到CPU高速缓存或者寄存器中，因此总体上来说，Java内存模型和计算机硬件内存架构是相互交叉的关系，是一种抽象概念划分与真实物理硬件的交叉。

## JMM 如何解决有序性问题？

JMM提供了自己的内存屏障指令，要求JVM编译器实现这些指令，禁止特定类型的编译器和处理器重排序

首先，使用StoreLoad的缓存写入方不仅需要将存储缓存（Store Buffer）刷入缓存行（Cache Line），	还要刷入到内存

**为什么这一堆 Barrier 里 StoreLoad 最重？**

 所谓的重实际就是跟内存交互次数，交互越多延迟越大，也就是越重。

StoreStore， LoadLoad 两个都不提了，因为它俩要么只限制读，要么只限制写，也即只有一次内存交互。

只有 LoadStore 和 StoreLoad 看上去有可能对读写都有限制。但 LoadStore 里实际限制的更多的是读，<u>即 Load 数据进来，而load可能是缓存行的无效数据了，这样是没有起到让高速缓存数据一致性。</u>它并不对最后的 Store 存出去数据的可见性有要求，只是说 Store 不能重排到 Load 之前。

而反观 StoreLoad，

首先，使用StoreLoad的缓存写入方不仅需要将存储缓存（Store Buffer）刷入缓存行（Cache Line），还要刷入到内存。如果不将存储缓存刷入主存，其他高速缓存可能读取到本地存储缓存/缓存行中的旧数据。

其次，在将存储缓存中的数据刷入主存之外，缓存写入方还要确保失效方的Invalidate Queue请求生效，从而保障失效方的缓存行变成Invalid状态。如果失效方的Invalidate Queue请求没有处理，则失效方也有可能读到缓存行中的旧数据，这就实际上又把Load操作重排到Store操作的前面。

> 这里理解出错了，load不是从主存加载到缓存中，而是从工作内存加载到缓存中。
>
> store是从工作内存加载到主存中。

## JMM 的8 个操作

![image-20240712163204925](https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimage-20240712163204925.png)
## volatile 

在Java代码中，volatile关键字的主要有两层语义：

* 不同线程对volatile变量的值具有内存可见性，即一个线程修改了某个volatile变量的值，该值对其他线程立即可见。
* 禁止进行指令重排序。

**基于保守策略的volatile操作的内存屏障插入策略：**

<img src="https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimage-20240712174000069.png" alt="image-20240712174000069" style="zoom:50%;" />

StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意CPU可见了。StoreLoad屏障可以保证在volatile写完成之后，缓存中的已经刷新成最新数据，后面所有CPU的读操作都可见了。

<img src="https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgimage-20240712174111208.png" alt="image-20240712174111208" style="zoom:50%;" />

LoadLoad屏障可以保证在volatile读之后，高速缓存中的数据是重新从主存加载的，并且是最新数据。LoadStore屏障可以保证，后面的写（load）操作也不会排到前面。	

但是以X86 CPU为例，该平台的JVM实现仅仅在volatile写操作后面插入一个StoreLoad屏障，其他的JMM屏障都会被省略。

## volatile 变量的复合操作不具备原子性的原理？

当执行x++,其实是执行了三步操作

1.从主内存读取值x=0;

2.执行x=0+1;

3.再把x=1刷回主内存；

当a,b同时操作x共享变量时，都执行到第一步，同时读取了x的值为0，此时a变量率先执行完到第2步第3步，x的值为1刷回到主内存了，但b线程已经执行到第2步了，即使x此时的值为1，b线程执行第2步的操作时是x=0+1.而不是x=x+1,所以最后结果还是1，这就是为什么复合操作不能保证原子性的原因。

使用volatile修饰的变量其(read、load)和(store、write)必须是连续出现的，但是在他们呢操作的过程中间可能被其它线程打断。



## 说说 synchronized 关键字和 volatile 关键字的区别 

synchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在!

**volatile** 关键字是线程同步的轻量级实现，所以 **volatile** 性能肯定比 **synchronized** 关键字 要好。但是 **volatile** 关键字只能用于变量而 **synchronized** 关键字可以修饰方法以及代码 块。

**volatile** 关键字能保证数据的可⻅性，但不能保证数据的原子性。 **synchronized** 关键字两 者都能保证。

**volatile** 关键字主要用于解决变量在多个线程之间的可⻅性，而 **synchronized** 关键字解决 的是多个线程之间访问资源的同步性。



## 如果线程数目过多会怎么样

我们的进程的计算能力是有限的,分配更多的线程只会强迫cpu在多个线程上下文之间频繁来回切换.一个cpu core在同一时间只能运行一条线程,所以如果cpu要切换到另外一个线程去执行,需要将当前的state保存起来,然后加载其他的线程进来执行.如果线程上下文切换发生在一个cpu core内,那么还好一些,但是如果在多个cpu core之间发生线程上下文切换,那么还需要走一个cpu core内部的通信.这种线程上下文切换会消耗掉很多的cpu资源,对于现在的cpu来说,每次线程上下文切换,都会导致30微秒的时间开销,所以宁愿将这些时间花费在任务的处理上.