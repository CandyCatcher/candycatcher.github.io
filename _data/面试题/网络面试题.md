### TCP里面遇到滑动窗口为0会发生什么

　　接收端通告的窗口大小变成0，发送端会发一个1字节的段（就是下一字节的数据，没新的数据段发送的时候发一个ack）（TCP零窗口探测），强制接收端重新宣告**下一个期望的字节**和**窗口大小**。如果接收方回复窗口大小仍然为零，则发送方的探测定时器加倍。没有收到ACK时，**发送探测包的最大次数之后连接超时**

### 怎么让udp像tcp一样可靠

* **确认机制**——UDP要想可靠，就要接收方收到UDP数据报文段之后回复确认；
* **超时重传**——让每个包有递增的序号，接收方发现中间丢了包就要发重传请求；发送方收不到确认包就要重新发送；
* **滑动窗口**——当网络太差时候频繁丢包，防止越丢包越重传的恶性循环，要有个发送窗口的限制，发送窗口的大小根据网络传输情况调整，调整算法要有一定自适应性。

　　等于说要在传输层的上一层（或者直接在应用层）实现TCP协议的可靠数据传输机制，比如使用UDP数据包+序列号，UDP数据包+时间戳等方法。

### 简述URL并分别说明各部分含义

基本URL包含协议名、服务器名称（或IP地址）、路径和文件名。

1. protocol（协议）：指定使用的传输协议。http：通过 HTTP 访问该资源。 格式 HTTP:// ；资源是本地计算机上的文件。格式file:// ；ftp：通过 FTP访问资源。格式 FTP://
2. hostname（主机名）：是指存放资源的服务器的域名系统 (DNS) 主机名或 IP 地址。
3. port（端口号）：整数，可选，省略时使用方案的默认端口，各种传输协议都有默认的端口号，如http的默认端口为80。
4. path（路径）：由零或多个“/”符号隔开的字符串，一般用来表示主机上的一个目录或文件地址。
5. ?xx=xxx这是问号传参，在HTTP事务中，问号传参是客户端把信息传递给服务器的一种方式（也有可能是跳转到某一个页面，把参数值传递给页面用来标识的）。
   \#xxx这是哈希值，哈希值一般都是跟用户端服务器交互没啥关系，主要用于页面中的锚点定位和HASH路由切换。

### **http报文格式**

HTTP请求报文

1. 请求方法——常见的GET/POST 还有GET， POST， PUT， DELETE

2. 请求的URL

3. HTTP协议及版本

4. 报文头

   User-Agent：产生请求的浏览器类型。

   Accept：客户端可识别的内容类型列表。

   Host：请求的主机名，允许多个域名同处一个IP地址，即虚拟主机。

5. 请求数据

HTTP响应报文

1. 报文协议以及版本
2. 状态码
3. 响应头 Server : web服务器软件名称；Content-Type : 请求的与实体对应的MIME信息；Date : 请求发送的日期和时间
4. 响应体。数据、HTML代码或者JS代码等

**HTTP如何实现缓存，怎样告诉浏览器这个可以被缓存以及缓存时间** 

　　服务端缓存又分为 代理服务器缓存 和 反向代理服务器缓存（也叫网关缓存，比如Nginx反向代理、Squid等），其实广泛使用的 CDN 也是一种服务端缓存，目的都是让用户的请求走”捷径“，并且都是缓存图片、文件等静态资源。

　　在客户端的话缓存一般指的是浏览器缓存，目的就是加速各种静态资源的访问。

浏览器缓存控制机制有两种：**HTML Meta标签** vs. **HTTP头信息**

1. 使用HTML Meta 标签，在HTML页面的<head>节点中加入<meta>标签，在meta标签中可以设定网页的到期时间

   ``` html
   <!--用于设定网页的到期时间，一旦过期则必须到服务器上重新调用。需要注意的是必须使用GMT时间格式-->
   <meta http-equiv="Expires" contect="Mon,12 May 2001 00:20:00 GMT">
   
   <!--用于设定禁止浏览器从本地机的缓存中调阅页面内容，设定后一旦离开网页就无法从Cache中再调出-->
   <meta http-equiv="Pragma" contect="no-cache">
   ```

2. 使用HTTP头信息控制缓存，浏览器第一次向web服务器请求，请求响应后，协商缓存，比如

   * Expires策略，Expires是Web服务器响应消息头字段，在响应http请求时告诉浏览器在过期时间前浏览器可以直接从浏览器缓存取数据，而无需再次请求。

   * **Cache-control策略**，Cache-Control与Expires的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存取数据。只不过Cache-Control的选择更多，设置更细致，如果同时设置的话，其优先级高于Expires。

     **max-age指示客户机可以接收生存期不大于指定时间（以秒为单位）的响应。**

     **min-fresh指示客户机可以接收响应时间小于当前时间加上指定时间的响应。**

     **max-stale指示客户机可以接收超出超时期间的响应消息。如果指定max-stale消息的值，那么客户机可以接收超出超时期指定值之内的响应消息。**

     Public指示响应可被任何缓存区缓存。

     Private指示对于单个用户的整个或部分响应消息，不能被共享缓存处理。这允许服务器仅仅描述当用户的部分响应消息，此响应消息对于其他用户的请求无效。

     no-cache指示请求或响应消息不能缓存，该选项并不是说可以设置”不缓存“，容易望文生义~

     no-store用于防止重要的信息被无意的发布。在请求消息中发送将使得请求和响应消息都不使用缓存，完全不存下來。

     * Last-Modified/If-Modified-Since：

       Last-Modified：标示这个响应资源的最后修改时间。web服务器在响应请求时，告诉浏览器资源的最后修改时间。
       2 If-Modified-Since：当资源过期时（使用Cache-Control标识的max-age），发现资源具有Last-Modified声明，则再次向web服务器请求时带上头 If-Modified-Since，表示请求时间。web服务器收到请求后发现有头If-Modified-Since 则与被请求资源的最后修改时间进行比对。若最后修改时间较新，说明资源又被改动过，则响应整片资源内容（写在响应消息包体内），HTTP 200；若最后修改时间较旧，说明资源无新修改，则响应HTTP 304 (无需包体，节省浏览)，告知浏览器继续使用所保存的cache

     * Etag/If-None-Match：

       Etag：web服务器响应请求时，告诉浏览器当前资源在服务器的唯一标识（生成规则由服务器决定）。Apache中，ETag的值，默认是对文件的索引节（INode），大小（Size）和最后修改时间（MTime）进行Hash后得到的

       If-None-Match：当资源过期时（使用Cache-Control标识的max-age），发现资源具有Etage声明，则再次向web服务器请求时带上头If-None-Match （Etag的值）。web服务器收到请求后发现有头If-None-Match 则与被请求资源的相应校验串进行比对，决定返回200或304

### http tcp ip的联系 

　　<u>**HTTP属于应用层，应用层为操作系统或网络应用程序提供访问网络服务的接口**</u>。该层的数据放在TCP数据包的数据部分，该层定义了一个很重要的协议——Http协议，一般的Web开发都是基于应用层的开发。之所以叫应用层是因为这些是我们直接接触到的具体应用，比如用于<u>网页浏览的HTTP，用于传输文件的FTP，或者远程登录的Telnet和SSH</u>。应用层需要交换数据的时候，比如你需要访问一个网页，浏览器会先生成HTTP的数据包，然后交给传输层去建立连接。

　　<u>**TCP是传输层，它通过流量控制，超时重传等机制来保证主机间连接的可靠性**</u>。TCP使用不同的端口来标记不同的应用发起的连接。为了避免在网络层产生分片，TCP会通过协商MSS，Path MTU Discovery的方式来对数据包进行分段交给网络层。

　　**<u>IP是网络层，负责处理不同的网络之间发送的数据包</u>**，在网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。IP的任务就是**<u>选择合适的网间路由和交换结点，确保数据的及时传送</u>**。它不需要考虑具体应用或者端口的信息。它的主要工作是分片（fragmentation）和重组（reassembly）数据包（TCP需要通过重传来保证可靠性，所以不依赖网络层的分片，主要是UDP使用）以及根据IP地址做路由（route）。当然，寄送过程中可能会被中间某跳丢了，或者复制了，或者有的慢有的快，IP层不解决，留给TCP解决。

### get和post的区别 

　　GET和POST本质上就是**TCP链接**，并无差别。但是由于HTTP的规定和浏览器/服务器的限制，导致他们在应用过程中体现出一些不同。 

1. **传输方式不同：**GET参数通过URL传递，参数直接暴露在URL上，POST放在Request body中

2. **传输数据大小不同：**相对于GET方式，浏览器或操作系统对POST可传较大量的数据

3. **传输过程不同：<u>对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200（返回数据）；而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok（返回数据）。</u>**

4. **传输含义不同：**<u>get表达的是一种幂等的，只读的，纯粹的操作，即它除了返回结果不应该会产生其它副作用（如写数据库），因此绝大部分get请求（通常超过90%）都直接被CDN缓存了，这能大大减少web服务器的负担。</u>

   <u>而post所表达的语义是非幂等的，有副作用的操作，所以必须交由web服务器处理。把所有get请求换成post，意味着主干网络上的所有CDN都废掉了，web服务器要处理的请求数量将成百上千倍地增加。</u>

5. GET请求会被浏览器主动cache，而POST不会，除非手动设置

6. GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留

### https与http的区别

- **HTTPS是HTTP协议的安全版本，HTTP协议的数据传输是明文的，是不安全的，HTTPS使用了SSL/TLS协议进行了加密处理**。
- **http和https使用连接方式不同，默认端口也不一样，http是80，https是443**。
- 使用 HTTPS 协议需要申请 CA 证书，一般免费证书较少，因而需要一定费用。证书颁发机构如：Symantec、Comodo、DigiCert 和 GlobalSign 等。
- HTTP **页面响应速度**比 HTTPS 快，这个很好理解，由于加了一层安全层，建立连接的过程更复杂，也要交换更多的数据，难免影响速度。
- 由于 HTTPS 是建构在 **SSL / TLS** 之上的 HTTP 协议，所以，要比 HTTP 更**耗费服务器资源**。

> SSL运行在TCP/IP层之上、应用层之下，为应用程序提供加密数据通道，它采用了RC4、MD5以及RSA等加密算法。
>
> TLS是SSL的标准化后的产物。安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。较低的层为 TLS 记录协议，位于某个可靠的传输协议（例如 TCP）上面。

### 详细讲述一下ssl 

1. 客户端给出支持SSL协议版本号、一个客户端**随机数**(第一个随机数)、客户端支持的加密方法等信息；
2. 服务器收到信息后，确认双方使用的加密方法，并返回数字证书，一个服务器生成的**随机数**(第二个随机数)等信息；
3. 客户端确认数字证书的有效性，然后生成一个新的**随机数**(第三个随机数)，然后使用数字证书中的公钥，加密这个随机数，发给服务器（**只有用私钥才能解密**）。
4. 服务器使用自己的私钥，获取客户端发来的随机数；
5. 客户端和服务器通过约定的加密方法(通常是[AES算法](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%E9%AB%98%E7%BA%A7%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86))，使用前面三个随机数，作为后续传输数据使用的**对称密钥**

### 对称加密和非对称加密

1. 加密和解密过程不同。<u>对称加密过程和解密过程使用的同一个密钥</u>，加密过程相当于用原文+密钥可以传输出密文，同时解密过程用密文-密钥可以推导出原文。但<u>非对称加密采用了两个密钥，一般使用公钥进行加密，使用私钥进行解密。</u>

2. 加密**解密**速度不同。<u>对称加密解密的速度比较快</u>，适合数据比较长时的使用。<u>非对称加密和解密花费的时间长、速度相对较慢，只适合对少量数据的使用</u>。

3. <u>对称加密的过程中无法确保密钥被安全传递</u>，密文在传输过程中是可能被第三方截获的，如果密码本也被第三方截获，则传输的密码信息将被第三方破获，<u>安全性相对较低</u>。

   非对称加密算法中私钥是基于不同的算法生成不同的随机数，私钥通过一定的加密算法推导出公钥，但私钥到公钥的推导过程是单向的，也就是说公钥无法反推导出私钥。所以安全性较高。

### 具体的加密算法

　　对称加密、非对称加密、数字签名、数字证书等

### 常见的非对称加密算法：RSA 

　　RSA加密是一种非对称加密。可以在不直接传递密钥的情况下，完成解密。这能够确保信息的安全性，避免了直接传递密钥所造成的被破解的风险。是由一对密钥来进行加解密的过程，分别称为公钥和私钥。两者之间有数学相关，该加密算法的原理就是对一极大整数做因数分解的困难性来保证安全性。通常个人保存私钥，公钥是公开的（可能同时多人持有）。

　　RSA签名的过程如下：

1. A生成一对密钥（公钥和私钥），私钥不公开，A自己保留。公钥为公开的，任何人可以获取。
2. A传递自己的公钥给B，B用A的公钥对消息进行加密。
3. A接收到B加密的消息，利用A自己的私钥对消息进行解密。

　　在这个过程中，只有2次传递过程，第一次是A传递公钥给B，第二次是B传递加密消息给A，即使都被敌方截获，也没有危险性，因为只有A的私钥才能对消息进行解密，防止了消息内容的泄露。

### 常见的对称加密算法：DES、AES，DES 和 AES 区别  

　　DES是较旧的算法，而AES是高级算法，它比DES更快，更安全。

HTTPS 证书是啥？加密内容？ 

#### 可以伪造证书吗？中间人攻击能预防吗？ 

　　客户端在使用HTTPS方式与Web服务器通信时有以下几个步骤，如图所示。（先用非对称加密获取秘钥，用对称加密进行通信）

- **第一步：**首先，当客户端开启一个新的浏览器第一次去访问服务器的时候，会先让客户端安装一个**数字证书**，这个数字证书里包含的主要信息就是CA机构的公钥。
- **第二步：**服务器发送来了CA机构颁发给自己的数字证书，客户端通过第一步中已经得到的公钥解密CA用私钥加密的Hash-a(**这个过程就是非对称加密**)，然后再用传递过来的HASH算法生成一个Hash-b，如果Hash-a === Hash-b就说明认证通过，确实是服务器发过来的。

### 怎么实现跨域访问？

　　CORS是一个W3C标准，全称是"跨域资源共享"（Cross-origin resource sharing）。

　　实现原理：对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个`Origin`字段。如果`Origin`指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应

**Tcp握手为什么两次不行，三次握手时候第三次ack信号没有到达服务端会发生什么情况。四次握手呢？** 

　　由于Server没有收到ACK确认，因此会重发之前的SYN+ACK（**默认重发五次，之后自动关闭连接**），Client收到后会重新传ACK给Server；如果Client向服务器发送数据，服务器会以**RST**包响应。

### 队头阻塞 tcp http的角度，分别讲一下 

TCP的：

　　**队头阻塞（head-of-line blocking）发生在一个TCP分节丢失，导致其后续分节不按序到达接收端的时候，那么这个分节将被接收端一直保持直到丢失的分节被发送端重传并到达接收端为止。**该后续分节的延迟递送确保接收应用进程能够按照发送端的发送顺序接收数据。这种为了达到完全有序而引入的延迟机制非常有用，但也有不利之处。

ＨTTP的：

　　http队头阻塞和TCP队头阻塞完全不是一回事。http1.x采用长连接(Connection:keep-alive)，可以在一个TCP请求上，发送多个http请求。**管道化**，请求可以并行发出，但是响应必须串行返回。后一个响应必须在前一个响应之后。原因是，没有序号标明顺序，只能串行接收。

**管道化请求的致命弱点**:

1. <u>会造成队头阻塞，前一个响应未及时返回，后面的响应被阻塞</u>
2. 请求必须是幂等请求，不能修改资源。因为，意外中断时候，客户端需要把未收到响应的请求重发，非幂等请求，会造成资源破坏。

　　由于这个原因，目前大部分浏览器和Web服务器，都关闭了管道化，采用非管道化模式。无论是非管道化还是管道化，都会造成队头阻塞(请求阻塞)。

### UDP 伪首部多大，有啥，有啥用？ 

　　UDP和TCP的伪首部只用于计算校验和。32位源IP地址、32位目的IP地址、8位协议、16位UDP长度。

　　目的是让UDP两次**检查数据是否已经正确到达目的地。**第一次，通过伪首部的**IP地址检验**，UDP可以确认该数据报是不是发送给本机IP地址的；第二，通过伪首部的**协议字段检验**，UDP可以确认IP有没有把不应该传给UDP而应该传给别的高层的数据报传给了UDP。从这一点上，伪首部的作用其实很大。

　　发送方将UDP伪首部、首部、数据每16位一组进行二进制反码求和，再将求和结果求反码，填入校验和字段。接收方收到UDP报文后，生成伪首部，将伪首部、首部、数据每16位一组进行二进制反码求和，若求和结果全为1则无差错传输，否则丢弃。

**如果接收端TCP接收到来自对端的重复数据， 可以根据序列号判断数据是否重复，从而丢弃重复数据**

### 滑动窗口的接收缓存和什么有关系？

　　TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：

* 如果连接的<u>内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低</u>；
* 如果连接的<u>内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立</u>；

　　下文代码基于3.2.12内核，主要源文件为：`net/ipv4/tcp_input.c`。

### 10G内存能不能用8G做接收缓存，最大能设多大 

　　对于linux，所有的TCP/IP参数都位于/proc/sys/net目录下（请注意，对/proc/sys/net目录下内容的修改都是临时的，任何修改在系统重启后都会丢失），例如下面这些重要的参数：

| 参数（路径+文件）               | 描述                                | 默认值 | 优化值 |
| ------------------------------- | ----------------------------------- | ------ | ------ |
| /proc/sys/net/core/rmem_default | 默认的TCP数据接收窗口大小（字节）。 | 212992 | 256960 |
| /proc/sys/net/core/rmem_max     | 最大的TCP数据接收窗口（字节）。     | 212992 | 513920 |
| /proc/sys/net/core/wmem_default | 默认的TCP数据发送窗口大小（字节）。 | 229376 | 256960 |
| /proc/sys/net/core/wmem_max     | 最大的TCP数据发送窗口（字节）。     | 131071 | 513920 |

### 滑动窗口分哪几个区域？

已经发送并收到确认，已经发送未收到确认，允许发送但尚未发送，不允许发送

### 拥塞控制 

　　**慢开始和拥塞避免**：拥塞窗口从1开始按照指数增长，达到慢开始门限值每次加1，出现拥塞以后门限值设置为当前拥塞窗口大小/2，拥塞窗口从1开始重复这个过程

　　**快重传和快恢复**：发送方收到连续三个重复确认就重传接收方没有收到的报文段，而不用等待重传计时器到期，然后把门限值减半，执行拥塞避免

**发送窗口和拥塞窗口**

　　发送窗口 `swnd` 和接收窗口 `rwnd` 是约等于的关系，那么由于入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。

### 拥塞控制对移动端、打[游戏]()，[游戏]()动作同步有什么影响 

　　[游戏]()里面很多都是用UDP，你了解吗。为什么直播要用UDP--》直播和视频网站一般用TCP，因为对画面质量有要求，且允许缓冲等待；而微信视频聊天一般用udp，因为不希望画面卡顿，可以接受画面不太清晰 

　　王者荣耀用UDP会有什么问题（我答的丢包） 但是它实际不会出现这个问题，为什么（我答应用层加了处理逻辑） 

csrf 预防，http/dns 劫持 

### **分片和分段区别** 

1. **TCP分段的原因是TCP最大分段大小MSS的限制，IP分片的原因是最大传输单元MTU的大小限制。**
2. **由于一直有MSS<=MTU，因此也就不需要在网络层进行IP分片了。因此TCP报文段很少会发生IP分片的情况。**若数据过大，只会在传输层进行数据分段，到了IP层就不用分片。我们常提到的 IP分片是由于UDP传输协议造成的，因为UDP传输协议并未限定传输数据报的大小。
3. **IP分片由网络层完成，也在网络层进行重组；TCP分段是在传输层完成，并在传输层进行重组**
4. 总之，**UDP不会分段，就由IP来分片。**TCP会分段，当然就不用IP来分片了

　　**MTU（最大传输单元）**。MTU是链路层中的网络对数据帧的一个限制，以以太网为例，MTU为1500个字节。一个IP数据报在以太网中传输，如果它的长度大于该MTU值，就要进行分片传输，使得每片数据报的长度小于MTU。分片传输的IP数据报不一定按序到达，但IP首部中的信息能让这些数据报片按序组装  。IP数据报的分片与重组是在网络层进完成的。

　　**MSS（最大分段大小）**。MSS是TCP里的一个概念（首部的选项字段中）。MSS是TCP数据包每次能够传输的最大数据分段，TCP报文段的长度大于MSS时，要进行分段传输。TCP协议在建立连接的时候通常要协商双方的MSS值，每一方都有用于通告它期望接收的MSS选项（**MSS选项只出现在SYN报文段中，即TCP三次握手的前两次**）。Internet上标准的MTU为576，那么如果不设置，则MSS的默认值就为536个字节。很多时候，MSS的值最好取512的倍数。TCP报文段的分段与重组是在运输层完成的。

**为什么要避免UDP数据报分片呢？在网络编程中，我们要避免出现IP分片，那么为什么要避免呢？**

　　简单来说，就是一个消息，只能被封装为一个udp报文，这就是一个整体消息，这个消息被拆解为多个udp报文了，**因为udp报文间是没有任何联系的**，这个消息实质上就失去意义了。从这个层面上讲的udp报文不能分片。

　　但如果这个消息被tcp报文携带，那么这个消息可以分为多个tcp报文，tcp报文间是有联系的，每个tcp报文都有seq号，而且每个tcp报文都属于某一个连接，属于同一连接上的多个tcp报文间经过seq号可以排序组装，最终形成那个消息。

　　**对于UDP包，我们需要在应用层去限制每个包的大小，一般不要超过1472字节，**即以太网MTU（1500—UDP首部（8）—IP首部（20）。

### 用过哪些linux命令？如查看内存使用、网络情况？

**free 命令**

　　是Linux系统中最简单和最常用的内存查看命令， 示例如下:

``` 
$ free -m
              total        used        free      shared  buff/cache   available
Mem:           7822         321         324         377        7175        6795
Swap:          4096           0        4095

$ free -h
              total        used        free      shared  buff/cache   available
Mem:           7.6G        322M        324M        377M        7.0G        6.6G
Swap:          4.0G        724K        4.0G
```

**使用 top 命令**

　　top 命令一般用于查看进程的CPU和内存使用情况；当然也会报告内存总量，以及内存使用情况，所以可用来监控物理内存的使用情况。
在输出信息的顶部展示了汇总信息。

示例输出：

``` 
top - 15:20:30 up  6:57,  5 users,  load average: 0.64, 0.44, 0.33
Tasks: 265 total,   1 running, 263 sleeping,   0 stopped,   1 zombie
%Cpu(s):  7.8 us,  2.4 sy,  0.0 ni, 88.9 id,  0.9 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem:   8167848 total,  6642360 used,  1525488 free,  1026876 buffers
KiB Swap:  1998844 total,        0 used,  1998844 free,  2138148 cached

PID USER      PR  NI  VIRT  RES  SHR S  %CPU %MEM    TIME+  COMMAND                                                                                 
2986 enlighte  20   0  584m  42m  26m S  14.3  0.5   0:44.27 yakuake                                                                                 
1305 root      20   0  448m  68m  39m S   5.0  0.9   3:33.98 Xorg                                                                                    
7701 enlighte  20   0  424m  17m  10m S   4.0  0.2   0:00.12 kio_thumbnail

```

**nload**

　　`nload` 命令可以查看各个网络设备的当前网络速率，也会展示流经设备的总流量。

**ss/netstat**

　　`ss` 和 `netstat` 是查看活动链接/监听端口的常用命令。`ss` 是 `netstat` 的替代，性能更好，建议使用。

　　`ss` 是 `iproute2util` 包的一部分，因此在大多数系统上默认安装，也可通过`yum install -y iproute`安装。`netstat` 来自 `net-tools` 包，新版系统上需要自行安装：`yum install -y net-tools`。

　　下图是用`ss`查看tcp连接的输出：

[![ss查看tcp连接](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img1460000022275531.png)](https://tlanyan.me/linux-traffic-commands/ss查看连接/)

**iftop**

　　`iftop` 是一款实时流量监控工具，可以查看每个连接的实时速率。

　　`iftop` 来自[EPEL](https://fedoraproject.org/wiki/EPEL)软件库，安装命令是：`yum install -y epel-release && yum install -y iftop`。`iftop -nN -i eth0`实时查看eth0网卡的各个连接和网速：

[![iftop查看实时网速](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img1460000022275530.png)](https://tlanyan.me/linux-traffic-commands/iftop查看实时网速/)

### TCP的粘包？粘包怎么解决？UDP会粘包吗？

　　发送端为了将多个数据包更有效的发到接收端，使用了优化方法（Nagle算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。但是这样的话接收端就难以将多个包分辨了。

　　UDP不存在粘包问题，是由于UDP发送的时候，没有经过Negal算法优化，不会将多个小包合并一次发送出去。 另外，在UDP协议的接收端，采用了链式结构来记录每一个到达的UDP包，这样接收端应用程序一次recv只能从socket接收缓冲区中读出一个数据包。

1. 发送端给每个数据包添加包首部，**首部中应该至少包含数据包的长度**，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
2. 发送端将每个数据包封装为**固定长度（不够的可以通过补0填充）**，这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
3. 可以在数据包之间**设置边界**，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。

### TCP面向什么传输，UDP面向什么传输？

　　TCP是面向连接的协议。UDP是一个简单的面向数据报的传输层协议。

### 显示URL到浏览器整个过程  

　　浏览器打开一个网站的过程中会经历哪些网络处理，DNS的具体过程是啥。面试官问每次都要域名解析吗？使用本地缓存。

### TCP报文

* 16位的源端口号、16位的目标端口号
* 32位序号
* 32位确认序号
* 4位首部长度、6位保留位、6位状态位、16位滑动窗口的大小
* 16位校验和、16位紧急指针

1. **紧急URG**,当设置为有效时（URG=1）,表示该标志位有效，告诉操作系统有紧急数据要传送，而不要按原来的排列顺序来传送。
2. 确认ACK，仅当ACK为1时，确认字段有效，为0时，确认字段无效
3. **推送PSH**，两个进程在进行交互式通信时，一个进程键入一个命令希望另一个进程立即收到该进程的响应，将PSH置为1，TCP使用
   推送操作，<u>发送方发送一个报文段，接收方收到TCP推送的报文段时，立即向前交付接受应用程序，不等整个缓冲区满了才向上交付</u>。
4. 复位RST,RST为1时，表明TCP连接中出现了严重差错，必须释放链接，需要去重新建立链接。也可以拒绝非法报文和拒绝打开链接。
5. 同步SYN，连接建立时同步序号。
6. 终止FIN，释放连接

### TCP的四次挥手，为什么有2MSL的等待时间，出现大量TIME_WAIT的情况以及解决方法

　　在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它**必须确认Server接收到了该ACK**。<u>Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。**如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL**</u>。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。<u>**如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。**</u>

　　在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。

- 服务内核参数调整：
  可以先看看 `ip_local_port_range` 能否还能再设置大一些，以便可以使用**开启更多的端口**（如何修改可以参考[这里](https://ma.ttias.be/linux-increase-ip_local_port_range-tcp-port-range/)）。
- **增加服务器**：
  既然一台机器已经无法承载更多的连接了，加服务器是最快捷和合理的方案。
- **尽量不要让服务器端成为主动关闭连接的一方**：
  设置服务器端的 KeepAlive ，尽可能不让服务器端主动关闭连接，而是让客户端连接，这样就不会出现 TIME_WAIT 过多的问题。

> 短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接。
>
> 在 Linux 系统中，MSL 被定义成 30 秒， 2MSL 就是 60 秒

### Session、Cookie、Token

　　**由于http的无状态性，为了使某个域名下的所有网页能够共享某些数据，session和cookie出现了。**客户端访问服务器的流程如下　

- 首先，客户端会发送一个http请求到服务器端。
- 服务器端接受客户端请求后，建立一个session，并发送一个http响应到客户端，这个响应头，其中就包含Set-Cookie头部。该头部包含了sessionId。Set-Cookie格式如下，具体请看[Cookie详解](https://link.segmentfault.com/?url=http%3A%2F%2Fbubkoo.com%2F2014%2F04%2F21%2Fhttp-cookies-explained%2F)
  `Set-Cookie: value[; expires=date][; domain=domain][; path=path][; secure]`
- 在客户端发起的第二次请求，假如服务器给了set-Cookie，浏览器会自动在请求头中添加cookie
- 服务器接收请求，分解cookie，验证信息，核对成功后返回response给客户端

　　session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie

　　cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。另外，**cookie**只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中。

　　**token** 的认证流程与cookie很相似

- 用户登录，成功后服务器返回Token给客户端。
- 客户端收到数据后保存在客户端
- 客户端再次访问服务器，将token放入headers中
- 服务器端采用filter过滤器校验。校验成功则返回请求数据，校验失败则返回错误码

 　　**token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。**需要开发者手动添加。token在客户端一般存放于localStorage，cookie，或sessionStorage中。在服务器一般存于数据库中。

### Cookies在HTTP请求的哪个位置，以及Cookies的格式

　　每个HTTP请求和响应都会带有相应的**头部信息**。Cookie：当前页面设置的任何Cookie。

　　格式就是键值对。

```dart
Set-Cookie: "name=value;domain=.domain.com;path=/;expires=Sat, 11 Jun 2016 11:29:42 GMT;HttpOnly;secure"
```

### Session是存储在服务器上，如何存储的？存储方式的区别

　　Session的服务端服务实现由很多种，常见有磁盘文件保存（PHP默认方式，会阻塞）、MySQL（Discuz! 的自己的实现方式）、Memcached（性能较高的一种实现）、Redis。

### tcp和udp区别

### tcp为什么可靠

　　序列号，确认重发，超时重传，三握四挥，流量控制，拥塞控制

1. 序列号：给发送的每一个包进行编号
2. 校验和：TCP报文段首部和数据的校验和，如果收到的校验和有差错，TCP将丢弃这个报文段和不确认收到此报文段
3. 流量控制：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。TCP的流量控制协议是可变大小的滑动窗口协议
4. 拥塞控制：当网络拥塞时，调整数据的发送的大小
5. 超时重传：当TCP发出一个段后，将启动一个定时器，等待目的端口确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段

### 半连接攻击以及如何解决半连接攻击

　　半连接攻击是一种攻击协议栈的攻击方式，坦白说就是攻击主机的一种攻击方式。**通过将主机的资源消耗殆尽，从而导致应用层的程序无资源可用，导致无法运行。**在正常情况下，客户端连接服务端需要通过三次握手，首先客户端构造一个SYN连接数据包发送至服务端，自身进入SYN_SEND状态，<u>当服务端收到客户端的SYN包之后，为其分配内存核心内存，并将其放置在半连接队列中</u>。半连接就是通过不断地构造客户端的SYN连接数据包发向服务端，等到服务端的半连接队列满的时候，后续的正常用户的连接请求将会被丢弃，从而无法连接到服务端。此为半连接攻击方式。根据服务端的半连接队列的大小，不同主机的抵抗这种SYN攻击的能力也是不一样。

　　可以通过拓展半连接队列的大小，来进行补救，但缺点是，不能无限制的增加，这样会耗费过多的服务端资源，导致服务端性能地下。这种方式几乎不可取。现主要通syn cookie或者syn中继机制来防范半连接攻，部位半连接分配核心内存的方式来防范。

调整半连接队列阀值（正对不同操作系统带参数），**缩短timeout，syn cookie,设置可疑队列**，syn中继

### 全连接攻击以及解决全连接攻击

　　全连接攻击是通过消费服务端进程数和连接数，<u>只连接而不进行发送数据的一种攻击方式。当客户端连接到服务端，仅仅只是连接，此时服务端会为每一个连接创建一个进程来处理客户端发送的数据。</u>但是客户端只是连接而不发送数据，此时服务端会一直阻塞在recv或者read的状态，如此一来，多个连接，服务端的每个连接都是出于阻塞状态从而导致服务端的崩溃。

　　可以通过不为全连接分配进程处理的方式来防范全连接攻击，具体的情况是当收到数据之后，在为其分配一个处理线程。具体的处理方式在accept返回之前是不分配处理线程的。直到接收相关的数据之后才为之提供一个处理过程。

### Connection=[keep](https://www.nowcoder.com/jump/super-jump/word?word=keep)-alive干嘛的

　　HTTP每次请求都会执行TCP连接握手操作，比较消耗资源而且性能也不是很好，所以通过客户端告知服务端建立长连接方式，进行长连接复用。客户端的下次请求即可使用该长连接进行发送。**HTTP1.0协议要求客户端增加`Connection=keep-alive`表明长连接请求，服务端也需要返回加`Connection=keep-alive`表示支持，然后双方建立长连接**，客户端可复用该条连接请求。http1.1默认使用加`Connection=keep-alive`的长连接模式，默认的连接时长可以在服务器端设置不会让它长时间连接防止无效资源占用。长连接可以保证客户端可进行连接复用，但不能使服务器端主动向客户端发送请求(复用的是底层TCP的Socket连接，但需要和TCP的[keep]()-alive区分开)

### session 和 cookie 是什么，有什么区别

　　Session是在服务端保存用来**跟踪用户的状态**，这个数据可以保存在集群、数据库、文件中；**Session的生命周期是指一个终端用户与交互系统进行通信的时间间隔，通常指从注册进入系统到注销退出系统之间所经过的时间以及如果需要的话，可能还有一定的操作空间。**　

　　Cookie是客户端保存用户信息的一种机制，用来记录**用户的一些信息**，也是实现Session的一种方式。<u>如果不设置过期时间，则表示这个cookie生命周期为浏览器会话期间，只要关闭浏览器窗口，cookie就消失了。</u>Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。

### token

- session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie
- cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。
- token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。
- jwt只是一个跨域认证的方案

> **token可以抵抗csrf(跨站请求伪造)，cookie+session不行**
>
> 如果黑客在其他页面设置了一个链接，这个链接指向一个网站的转账系统。并且当前用户是这个网站的会员，并且处于登陆的状态(也就是客户端浏览器存在存储合法的session_id的cookie)，那么当用户点击了这个链接以后，那么客户端浏览器就会将用户的这些信息进行传递到服务端，但是这个链接具体做了什么，用户根本不知道，这也就做到了伪造了用户的身份，做了用户都不知道的事情。(转账)

### DNS 是基于传输层的什么协议的？

　　<u>DNS区域传输的时候使用TCP协议</u>：<u>辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP</u>，因为数据同步传送的数据量比一个请求应答的数据量要多得多。TCP是一种可靠连接，保证了数据的准确性。

　　<u>域名解析时使用UDP协议</u>：<u>客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。</u>不用经过三次握手，这样DNS服务器负载更低，响应更快。理论上说，客户端也可以指定向DNS服务器查询时用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。

### tcp连接后，路由器突然断开了，需要重新连接吗

　　<u>**根据tcp/ip协议的描述，tcp连接建立之后，如果双方没有通信，连接可以一直保存下去，假如中间路由器崩溃或者中间的某条线路断开，只要两端的主机没有被重启，连接就一直被保持着。**</u>

　　保活定时器一般配置的时间是**2小时**，即服务器每个2小时就会向客户端发送探查消息，如果收到客户端的反馈消息，则再等2个小时再发；如果等不到客户端的反馈，则再等75秒钟再发一次保活探查，这样连续发送10次，如果10次都没有收到反馈，就认为客户端已经异常断开了，此时，tcp层的程序就会向上层应用程序发送一条“连接超时”的错误反馈。

### 一个 10M 大小的 buffer 里存满了数据，现在要把这个 buffer 里的数据尽量发出去，可以允许部分丢包，问是用TCP好还是UDP好？为什么？ 

### 一个完整的 HTTP 请求会涉及到哪些协议？

　　HTTP协议就是基于TCP/IP协议模型来传输信息的。

1. 链路层。也称作数据链路层或网络接口层（在第一个图中为网络接口层和硬件层），通常包括操作系统中的**设备驱动程序**和计算机中对应的**网络接口卡**。它们一起处理与电缆（或其他任何传输媒介）的物理接口细节。**ARP（地址解析协议）和RARP（逆地址解析协议）**是某些网络接口（如以太网和令牌环网）使用的特殊协议，用来转换IP层和网络接口层使用的地址。
2. 网络层。处理分组在网络中的活动，例如分组的选路。在TCP/IP协议族中，网络层协议包括IP协议（网际协议），ICMP协议（Internet互联网控制报文协议），以及IGMP协议（Internet组管理协议）。
   1. **IP是一种网络层协议**，提供的是一种不可靠的服务，它只是尽可能快地把分组从源结点送到目的结点，但是并不提供任何可靠性保证。同时被TCP和UDP使用。TCP和UDP的每组数据都通过端系统和每个中间路由器中的IP层在互联网中进行传输。
   2. **ICMP是IP协议的附属协议**。IP层用它来与其他主机或路由器交换错误报文和其他重要信息。
   3. **IGMP是Internet组管理协议**。它用来把一个UDP数据报多播到多个主机。
3. 传输层主要为两台主机上的应用程序提供端到端的通信。在TCP/IP协议族中，有两个互不相同的传输协议：TCP（传输控制协议）和UDP（用户数据报协议）。
4. 应用层。应用层决定了向用户提供应用服务时通信的活动。TCP/IP 协议族内预存了各类通用的应用服务。包括 HTTP，FTP（File Transfer Protocol，文件传输协议），DNS（Domain Name System，域名系统）服务。

socket的原理

syn-cookie算法

http1.1和2.0主要区别 http头部压缩怎么协商 介绍一下cc防护[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)

介绍一下nginx能说多少是多少

### 其他问题

输入Url之后发生了什么 

Dns解析的全过程 

Http1.1 特点，缺点 

http2.0 特点，缺点 	

http3.0 特点，缺点 

QUIC 特点，缺点 

常见的拥塞控制[算法]() （BBR，RENO，BIC-tcp）

TCP连接过程，如何实现拥塞控制？ 

BBR 怎么快，怎么实现，和之前的有什么区别 

tcp 选项有什么 

tcp 首部多大 TCP 首部的数据结构，如果不计选项字段，首部是 20 个字节。

tcp半打开和半关闭的区别 

udp 存在的意义 

tcp怎么计算时间，RTT和RTO ？ 

tcp 异常处理，什么时候有RST，