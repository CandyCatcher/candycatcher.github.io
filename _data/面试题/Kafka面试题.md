# 项目

Kafka在项目中的使用

# 原理

## 什么是Kafka？

你是一个程序员，假设你维护了两个服务 A 和 B。 B 服务每秒只能处理 100 个消息，但 A 服务却每秒发出 200 个请求，B 服务哪里顶得住，分分钟被压垮。那么问题就来了，有没有办法让 B 在不被压垮的同时，还能处理掉 A 的消息？为了保护 B 服务，我们很容易想到可以在 B 服务的内存中加入一个**队列**。说白了，它其实是个链表，链表的每个节点就是一个消息。每个节点有一个序号，我们叫它 **Offset**，记录消息的位置。 B 服务依据自己的处理能力，消费链表里的消息。能处理多少是多少，不断更新已处理 Offset 的值。但这有个问题，来不及处理的消息会堆积在内存里，如果 B 服务更新**重启**，这些消息就都丢了。 这个好解决，将队列挪出来，变成一个**单独的进程**。就算 B 服务重启，也不会影响到了队列里的消息。

那么这样一个简陋的队列进程，其实就是所谓的**消息队列**。 而像 A 服务这样负责发数据到消息队列的角色，就是**生产者**，像 B 服务这样处理消息的角色，就是**消费者**。但这个消息队列属实过于简陋，像什么高性能，高扩展性，高可用，它是一个都不沾。 我们来看下怎么优化它。

### 高性能

B 服务由于性能较差，消息队列里会不断堆积数据，为了提升性能，我们可以扩展更多的消费者, 这样消费速度就上去了，相对的我们就可以增加更多生产者，提升消息队列的吞吐量。但是，随着生产者和消费者都变多，我们会发现它们会同时争抢同一个消息队列，抢不到的一方就得等待，降低了效率。怎么解决？首先是对消息进行分类，每一类是一个 **topic**，然后根据 topic 新增队列的数量，生产者将数据按 topic 投递到不同的队列中，消费者则根据需要订阅不同的 topic，这样就讲锁分散了。但是单个 topic 的消息还是可能过多，我们可以将单个队列拆成好几段，每段就是一个 **partition 分区**，每个消费者负责一个 partition。 这两个措施就大大降低了争抢，提升了消息队列的性能。

**segment**：一个partition当中存在多个segment文件段，每个segment分为两部分，.log文件和 .index 文件，其中 .index 文件是索引文件，主要用于快速查询， .log 文件当中数据的偏移量位置；

### 高扩展性

随着 partition 变多，如果 partition 都在同一台机器上的话，就会导致单机 cpu 和内存过高，影响整体系统性能。于是我们可以申请更多的机器，将 partition 分散部署在多台机器上，这每一台机器，就代表一个 **broker**。我们可以通过增加 broker 分散**partition 分区**来缓解机器 cpu 过高带来的性能问题。

### 高可用

最后还有一个问题，如果其中一个 partition 所在的 broker 挂了，那 broker 里所有 partition 的消息就都没了。这高可用还从何谈起？ 我们可以给 partition 多加几个副本，也就是 **replicas**，将它们分为 **Leader** 和 **Follower**。Leader 负责应付生产者和消费者的读写请求，而 Follower 只管同步 Leader 的消息。将 Leader 和 Follower 分散到不同的 broker 上，这样 Leader 所在的 broker 挂了，也不会影响到 Follower 所在的 broker, 并且还能从 Follower 中选举出一个新的 Leader partition 顶上。这样就保证了消息队列的高可用。

### 持久化和过期策略

刚刚提到的是几个 broker 挂掉的情况，那搞大点，假设所有 broker 都挂了，那岂不是数据全丢了？ 为了解决这个问题，我们不能光把数据放内存里，还要持久化到磁盘中，这样哪怕全部 broker 都挂了，数据也不会全丢，重启服务后，也能从磁盘里读出数据，继续工作。

但问题又来了，磁盘总是有限的，这一直往里写数据迟早有一天得炸。 所以我们还可以给数据加上保留策略，也就是所谓的 **retention policy**，比如磁盘数据超过一定大小或消息放置超过一定时间就会被清理掉。

### consumer group

这个消息队列好像就挺完美了。但其实还有个问题，按现在的消费方式，每次新增的消费者只能跟着**最新的**消费 Offset 接着消费。 如果我想让新增的消费者从某个 Offset 开始消费呢？ 听起来这个需求很刁钻？我举个例子你就明白了。

哪怕 B 服务有多个实例，但本质上，它只有一个消费业务方，新增实例一般也是接着之前的 offset 继续消费。 假设现在来了个新的业务方，C 服务，它想从头开始消费消息队列里的数据，这时候就不能跟在 B 服务的 offset 后边继续消费了。

所以我们还可以给消息队列加入**消费者组（consumer group）**的概念，B 和 C 服务各自是一个独立的消费者组，不同消费者组维护自己的消费进度，互不打搅。

### ZooKeeper

相信你也发现了，组件太多了，而且每个组件都有自己的数据和状态，所以还需要有个组件去统一维护这些组件的状态信息，于是我们引入 **ZooKeeper** 组件。它会定期和 broker 通信，获取 整个 kafka 集群的状态，以此判断 某些 broker 是不是跪了，某些消费组消费到哪了。

好了，到这里，当初那个简陋的消息队列，就成了一个高性能，高扩展性，高可用，支持持久化的超强消息队列，没错，它就是我们常说的消息队列 **Kafka**。

![Kafka是什么](https://cdn.jsdelivr.net/gh/candyboyou/imgs/imgf6ee8fbcf393433e818f6af59cb05646~tplv-k3u1fbpfcp-jj-mark%3A3024%3A0%3A0%3A0%3Aq75-20240723115455523.awebp)

## kafka优缺点

1. 可靠性：具有副本及容错机制。
2. 可扩展性：kafka无需停机即可扩展节点及节点上线。
3. 持久性：数据存储到磁盘上，持久性保存。 
4. 性能：kafka具有高吞吐量。达到TB级的数据，也有非常稳定的性能。
5. 速度快：顺序写入和零拷贝技术使得kafka延迟控制在毫秒级。

## Kafka基础构架

- Producer：Producer即生产者，消息的产生者，是消息的入口。
- Broker：Broker是kafka实例，每个服务器上有一个或多个kafka的实例，我们姑且认为每个broker对应一台服务器。每个kafka集群内的broker都有一个不重复的编号，如图中的broker-0、broker-1等……
- Topic：消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。在每个broker上都可以创建多个topic。
- Partition：Topic的分区，每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹！
- Replication:每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。
- Message：每一条发送的消息主体。
- Consumer：消费者，即消息的消费方，是消息的出口。
- Consumer Group：我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某一个消费者消费。同一个消费者组的消费者可以消费同一个topic的不同分区的数据，这也是为了提高kafka的吞吐量！

## kafka 作为集群存在，生产 Client 怎么知道该将数据发送到哪个实例？

在客户端初始化生产者对象时，需要配置 bootstrap.servers 参数，用于获取 Kafka 集群的元数据。Producer 可以通过 bootstrap.servers 中任意一个 kafka 实例，就能拉取到所有元信息，和生产有关的比如：某个 Topic 有多少个 Partition，每个 Partition 的 leader 的地址，这些元信息 Producer 会定时轮询更新。

当要生产一条消息时：

1. Producer 会根据策略先决定好这条消息归属于某个 Partition，策略一般有 轮训、随机、基于某个 key( Key-ordering) 这三种。
2. 将该消息直接发往 kafka 目标 Partition 的 leader 所在节点。

## kafka 对请求处理流程/Kafka 究竟是怎么使用 NIO 来实现网络通信的

Kafka网络层的核心类是SocketServer，它包含一个Acceptor用来接收新的连接，Acceptor对应多个Processor线程，每个 Processor线程都有自己的Selector，用来从连接中读取请求并写回响应。Clients 发送请求给 Acceptor 线程。

Kafka网络通信层由SocketServer组件和KafkaRequestHandlerPool组件构成。

首先Acceptor 线程会创建 NIO Selector 对象和 ServerSocketChannel 实例，然后将Channel 和 OP_ACCEPT 事件到 Selector 多路复用器上。然后一直轮询并将请求对象 SocketChannel 放入到新连接队列中（newConnections），通过取模运算找到一个Processor，Processor 线程从newConnections队列中取出客户端SocketChannel，并向 SocketChannel 注册了 OP_READ/OP_WRITE 事件，这样之后客户端发过来的请求就会被该 SocketChannel 对象获取到。接着Processor从一个已经接收完毕的网络请求集合中不断读取请求，并依次转换成Request实例，放入到Request队列。最后KafkaRequestHandler 线程循环地从请求队列中获取 Request 实例，然后交由KafkaApis 的 handle 方法，执行真正的请求处理逻辑，并最终将数据存储到磁盘中。待处理完请求后，KafkaRequestHandler 线程会将 Response 对象放入 Processor 线程的 Response 队列。 Processor 线程通过 Request 中的 ProcessorID 不停地从 Response 队列中来定位并取出 Response 对象，返还给 Request 发送方。

## kafka 收到生产请求后，是怎么处理数据的？

包含首领副本的broker在收到生产请求时，会对请求做一些验证。

1. 发送数据的用户是否有主题写入权限。
2. 请求里包含的acks值是否有效（只允许出现0、1、all）
3. 如果acks=all，是否有足够多的同步副本保证消息已经被安全写入（我们可以对broker进行配置，如果同步副本的数量不足，broker可以拒绝处理新消息）

之后，消息被写入本地磁盘。在Linux系统上，消息会被写到文件系统缓存里，并不保证它们何时会被刷新到磁盘上。kafka不会一直等待数据被写到磁盘上--它依赖复制功能来保证消息的持久性。

在消息被写入分区的首领之后，broker开始检查acks配置参数--如果acks被设为0或1，那么broker立即返回响应；如果acks被设为all，那么请求会被保存在一个叫做炼狱的缓冲区里，直到首领发现所有跟随者副本都复制了消息，响应才会被返回给客户端。

> 生产请求和获取请求都必须发送给分区的首领副本。**如果broker收到一个针对特定分区的请求，而该分区的首领在另一个broker上，那么发送请求的客户端会收到一个非分区首领的错误响应**。当针对特定分区的获取请求被发送到一个不含有该分区首领的broker上，也会出现同样的错误。kafka客户端要自己负责把生产请求和获取请求发送到正确的broker上。
>
> 客户端使用了另一种请求类型，也就是元数据请求。这种请求包含了客户端感兴趣的主体列表。服务器端的响应消息里指明了这些主题所包含的分区、每个分区都有哪些副本，以及哪个副本是首领。元数据请求可以发送给任意一个broker，因为所有broker都缓存了这些信息。
>
> 一般情况下，客户端会把这些信息缓存起来，并直接往目标broker上发送生产请求和获取请求。它们需要时不时地通过发送元数据请求来刷新这些信息（刷新的时间间隔通过metadata.max.age.ms参数来配置），从而知道元数据是否发生了变化--比如，在新broker加入集群时，部分副本会被移动到新的broker上。另外，如果客户端收到非首领错误，它会在尝试重发请求之前先刷新元数据，因为这个错误说明了客户端正在使用过期的元数据信息，之前的请求被发到了错误

## 如何尽可能实现高吞吐、高可扩展···？

1. 日志储存。
2. 数据复制。 kafka 会通过数据复制的方式，将数据同步到副本 partition 上，一方面当 leader 故障时，副本能够顶上提供服务，另一方面当 leader 磁盘故障时，数据有备份避免丢失。
3. 故障转移。当 Controller 发现节点故障后，会启动对应节点上的 partition leader 选举，让副本站出来当选 leader 对外提供服务。

## Kafka如何将数据同步给副本？

1. 异步同步数据。同步写副本数据太慢，那就让 follower 节点通过接口异步找 leader 节点拉数据。
2. 有限副本集合 ISR。只有数据写入副本后，才能提供数据可靠性保障，但等所有副本同步完成后再返回成功则太慢了，特别是会受慢节点拖累。kafka 提出了一个 ISR 副本集合的概念，其本质 leader 是维护一个“优质“的副本集合。<u>当对数据可靠性要求高时</u>，可以设置消息同步到所有 ISR 节点后才算成功 (request.required.acks=all)，否则给 Producer 返回超时或错误。当 leader 节点故障后，新的 leader 节点可以从 ISR 中诞生；<u>当对数据可靠性要求不高时</u>，可以设置 request.required.acks=1，此时写入 leader 成功就算成功提交。当然有些场景可以更激进地设置成 0。all,1,0 这三个值对应的吞吐能力依次大幅提升。 

## Kafka故障怎么检测？/谁负责故障恢复？/怎么恢复？

**故障怎么检测：**一般是指网络分区，比如某个节点连接不上了，要么网络出现问题，要么可能宕机了。这种情况的监测，kafka 是依靠 zookeeper 来实现的：

- 每个节点在启动时会到 zookerper 注册创建一个临时节点
- 当某个节点故障后，也会被 zookeeper 的心跳检测到，此时会将之前注册的临时节点删除
- zookeeper 提供节点/目录变更消息订阅通知
- 订阅了相关变更消息的节点，当故障发生时即可检测到

**谁负责故障恢复：**一般分布式系统中，都会有一个角色来统一负责，这种节点在 kafka 这里被叫做控制器 (Controller)，除了故障检测，还会负责 Topic/分区等注册更新，以及上文提到的集群元信息通知。

**故障怎么恢复：**具体策略就是遍历对应 partition 的副本列表，如果有在 ISR 队列中的则直接发消息通知其成为新 leader，并分别通知其他 Broker。如果 ISR 为空，当 unclean.leader.election.enable=true 则选择副本列表 (AR) 第一个为新 leader，否则要等挂了的节点重启后才能完成选举。Producer 可以通过任意 Broker 获得对应 partition 新的 leader 地址 (轮询或生产消息时)。

当 Controller 挂了怎么办？每个节点在启动时都会去 zookeeper 检测/controler 节点是否注册情况，如果没有则会尝试自己注册，第一个注册成功的则为 Controller。如果没能成为 Controller，则会订阅/controller 的变更消息，当 Controller 挂掉后，zk 会删除节点，此时其他所有节点都会收到消息，并竞争成为新的 Controller。

## Kafka日志是怎么存储的？

Kafka日志最后会被持久化到磁盘中，这里有个常见的权衡：

1. 性能。因为写磁盘是一个极高成本的事情，如果每条消息都直接刷盘，则 kafka 的吞吐能力会受到极大限制。
2. 可靠性。但如果只刷到 PageCache(内存) 中，当机器故障，未刷入磁盘的数据就丢了 (可能已经告诉 Producer 成功了) 。

MySQL 为了在事务中的解决方案是：

1. 在事务提交时，以顺序写的方式写入事务日志，默认直接刷盘，顺序写性能相对较好。如果这个失败了，那直接告诉请求方失败。[5]
2. 如果写顺序日志成功了，但由于宕机导致更新失败，则在启动流程中解决，做回滚或恢复。

MySQL 在权衡中选择了可靠性，这也导致其单机更新能力极限一般在 万/s，瓶颈非常明显。而 kafka 为了更牛逼的吞吐能力，选择直接写入 PageCache 就返回成功，定时或条件触发时批量刷盘。 [6]

也有参数可以控制刷盘机制，否则由 OS 决定刷盘时机：

- log.flush.interval.messages //多少条消息刷盘 1 次
- log.flush.interval.ms //隔多长时间刷盘 1 次
- log.flush.scheduler.interval.ms //周期性的刷盘

对于数据可靠性的补偿，kafka 提供 request.required.acks 的配置，可以设定当消息被复制到多个节点后才返回成功，这样数据可靠性就能明显提升，因为多个节点在某个特殊时机下同时故障导致数据丢失的概率会大大降低。

### 消息存放

消息在逻辑上属于某个 Topic，每个 Topic 有多个 Partition。在物理形态上，Topic 和 Partition 都是以文件夹的形态存在，消息数据就存放于这些文件夹里面。

逻辑上消息存放在对应 Partition 目录中的某个文件里，为了防止单个文件过大，在物理形态上，会分成多个数据分段 (Segment)，每个分段存放的数据量大致固定，以追加的方式存于文件末尾，当文件体积到一定阈值，则创建新的分段 (消息只会写入最新分段中)，Partition 的消息就分布在这些分段文件上。

### 消息索引？/当消费者希望读取某个 offset 的消息时，如何快速地定位到数据？

kafka 在存数据时，维护了offset到物理地址的索引，应对快速查询。每个 Segment 都有独立的索引文件。但是由于消息量巨大，不能每个 offset 都维护一个映射，kafka 选择了稀疏索引，即隔一段才存一个映射。根据二分查找可以找到小于等于目标 offset 的消息物理地址，再从分段文件中顺序读取即可。相应的逻辑，kafka 还会维护一个【时间戳=>偏移量】的索引，方便按照时间戳查询数据。

## 如何获取新产生的消息

当生产者创建了新消息时，kafka 会将其存放到对应的 Partition 分段文件中，按照先后顺序有序追加到文件末尾，每个消息都有一个偏移量，由生产的先后顺序决定。

拉模型决定了，kafka 把消息存放好后，就啥事也不干了。因为处理新消息是消费者自己的职责。消费者就是通过 kafka 提供的 FETCH 接口，不断地轮询，一批批地从 kafka 将消息拉下来，然后分发处理，处理完后继续拉下一批。

## 何时需要消息队列？

可以使用mq的场景有很多，最常用的几种，是做业务解耦/最终一致性/广播/错峰流控等。

https://www.cnblogs.com/Xianhuii/p/17081087.html

1. **解耦**。解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”。

   举个例子，假设有一个订单系统和一个库存系统，订单系统需要调用库存系统的接口来检查库存数量。如果库存系统出现问题，订单系统也会受到影响。而通过使用消息队列，订单系统可以将订单信息发送到消息队列中，然后由库存系统从消息队列中获取订单信息并处理。这样，即使库存系统出现问题，也不会影响到订单系统的正常运行。

   **本来石化厂的声学设备和本身的系统是解耦的，因为齐鲁石化有声学设备，在燕山或者广石化就没有该设备。所以本身就不是一个系统。然后声学设备几十个，几乎每秒十几个，但是这边要调用python模型计算并存储数据库，不用消息队列的话系统处理线程资源耗尽，很容易导致系统奔溃，所以还是要通过消息队列。**

2. **最终一致性**。最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。对于跨VM的，虽然也可以用RPC来做，但是可以抽象成一个统一的模型，基于消息队列来做一个“企业总线”。

   > **怎么用消息队列来实现一个最终一致性？**
   >
   > https://www.cnblogs.com/aspirant/p/11455095.html
   >
   > https://juejin.cn/post/6844903951448408071

3. **广播**。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。比如本文开始提到的产品中心发布产品变更的消息，以及景点库很多去重更新的消息，可能“关心”方有很多个，但产品中心和景点库只需要发布变更消息即可，谁关心谁接入。

4. **错峰与流控**。考虑在系统访问高峰期，同一时间内触发大量请求，如果系统处理线程资源耗尽，则会导致系统奔溃。

   此时，如果使用消息队列将异步请求延后处理，则可以将该高访问时间段的业务处理，平摊到后续的请求低峰期，大大提高了系统的稳定性。

## 设计一个消息队列？

因为消息队列简单来说就是两次RPC加一次转存。一个用来接收消息，一个用来确认消息收到。并且做到不管哪个server收到消息和确认消息，结果一致即可。RPC就用公司现成的就行，比如Thrift、Dubbo也好，或者是其他自定义的框架都行。首先broker为了满足错峰/流控/最终可达等一系列需求，需要把消息存储下来，然后选择时机投递。比如说可以存储在内存里，存储在分布式KV里，存储在磁盘里，存储在数据库里等等。怎么存也是看业务需求，如果是强一致性对性能和量没有太大要求的可以直接用DB了，如果是的QPS性能要求很高最好用文件存储，可以参考kafka采用数据文件+索引文件的方式处理。接着是解析发送接收关系。首先可以通过zookeeper来维护广播关系，然后进行消息的广播，不同的组注册不同的订阅。组内的不同机器，如果注册一个相同的ID，则单播；如果注册不同的ID(如IP地址+端口)，则广播。这样就能实现消息队列的基本功能了。

接着看一些特性。

**可靠投递（最终一致性）**

1. producer往broker发送消息之前，需要做一次落地。
2. 请求到server后，server确保数据落地后再告诉客户端发送成功。
3. 支持广播的消息队列需要对每个待发送的endpoint，持久化一个发送状态，直到所有endpoint状态都OK才可删除消息。

**消费确认**

当broker把消息投递给消费者后，消费者可以立即响应我收到了这个消息。但收到了这个消息只是第一步，我能不能处理这个消息却不一定。或许因为消费能力的问题，系统的负荷已经不能处理这个消息；或者是刚才状态机里面提到的消息不是我想要接收的消息，主动要求重发。

<u>消费能力不匹配的时候，直接拒绝</u>，过一段时间重发，减少业务的负担。业务出错这件事情是只有业务方自己知道的，就像上文提到的状态机等等。这时应该允许业务方主动ack error，并可以与broker约定下次投递的时间。

**重复消息和顺序消息**

一般来讲，一个主流消息队列的设计范式里，应该是不丢消息的前提下，尽量减少重复消息，不保证消息的投递顺序。

谈到重复消息，主要是两个话题：

1. 如何鉴别消息重复，并幂等的处理重复消息。

   数据库的唯一键/bloom filter/分布式KV中的key，都是不错的选择。

   因为种种原因重复消息或者错乱的消息还是来到了，说两种通用的解决方案：

   1. 版本号。

      如果每个消息自带一个版本号。上游发送的时候，标记消息1版本号是1，消息2版本号是2。如果再发送下线消息，则版本号标记为3。下游对于每次消息的处理，同时维护一个版本号。如果到来的顺序是21，则先把2存起来，待1到来后，再处理2，这样重复性和顺序性要求就都达到了。

   2. 状态机。业务方只需要自己维护一个状态机，定义各种状态的流转关系。例如，"下线"状态只允许接收"上线"消息，“上线”状态只能接收“下线消息”，如果上线收到上线消息，或者下线收到下线消息，在消息不丢失和上游业务正确的前提下。要么是消息发重了，要么是顺序到达反了。这时消费者只需要把“我不能处理这个消息”告诉投递者，要求投递者过一段时间重发即可。

2. 一个消息队列如何尽量减少重复消息的投递。

   1. broker记录MessageId，直到投递成功后清除，重复的ID到来不做处理，这样只要发送者在清除周期内能够感知到消息投递成功，就基本不会在server端产生重复消息。
   2. 对于server投递到consumer的消息，由于不确定对端是在处理过程中还是消息发送丢失的情况下，有必要记录下投递的IP地址。决定重发之前询问这个IP，消息处理成功了吗？如果询问无果，再重发。

> java实现组内广播
>
> https://www.cnblogs.com/xujian2014/p/5072215.html

## Kafka数据重复怎么办？

### 消息重复的原因

1. 生产者重复消息

   **生产者发送的消息没有收到 Broker 正确的响应**，导致生产者重试。

   生产者发出一条消息，Broker 落盘以后因为网络等种种原因，发送端得到一个发送失败的响应或者网络中断，然后生产者收到一个可恢复的 Exception 重试消息导致消息重复。

2. 消费者重复消息

   **消息消费端在消费过程中挂掉没有及时提交 offset 到 Broker**，另一个消费端启动拿之前记录的 offset 开始消费，由于 offset 的滞后性可能会导致新启动的客户端有少量重复消费。

   具体业务场景有这些：

   1. 消费者宕机、重启等。导致消息已经消费但是没有提交offset。
   2. 消费者使用自动提交offset，但当还没有提交的时候，有新的消费者加入或者移除，发生了rebalance（再平衡）。再次消费的时候，消费者会根据提交的偏移量来，于是重复消费了数据。

   3）消息处理耗时，或者消费者拉取的消息量太多，处理耗时，超过了max.poll.interval.ms的配置时间，导致认为当前消费者已经死掉，触发再均衡。

### 消息重复解决

生产者

1. 幂等性（Idempotence）。要启动kafka的幂等性，无需修改代码，默认为关闭，需要修改配置文件:enable.idempotence=true 同时要求 ack=all 且 retries>1。不允许选举ISR以外的副本作为leader。

2. 事务（Transaction）

   事务型 Producer 代码应该这样写：

   ```java
   producer.initTransactions();
   try {
       producer.beginTransaction();
       producer.send(record1);
       producer.send(record2);
       producer.commitTransaction();
   } catch (KafkaException e) {
       producer.abortTransaction();
   }
   ```

   和普通 Producer 代码相比，事务型 Producer 的显著特点是调用了一些事务 API，如 initTransaction、beginTransaction、commitTransaction 和 abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。

3. 不用自动重试，可以捕获异常记录到数据库或缓存，进行单独处理。

消费者

1. 取消自动自动提交。每次消费完或者程序退出时手动提交。这可能也没法保证一条重复。

2. 做幂等。一般的解决方案是让下游做幂等或者尽量每消费一条消息都记录offset，对于少数严格的场景可能需要把offset或唯一ID,例如订单ID和下游状态更新放在同一个数据库里面做事务来保证精确的一次更新或者在下游数据表里面同时记录消费offset，然后更新下游数据的时候用消费位点做乐观锁拒绝掉旧位点的数据更新。

   利用数据库的唯一约束实现幂等；设置前置条件，满足条件就执行；给每条消息都记录一个全局唯一 ID，消费时，先根据这个全局唯一 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。

## Kafka丢数据咋办？/kafka消息丢失怎么处理？/Kafka怎么确保消息不丢失

### 丢失消息的场景

1. 生产者丢失消息

   1. 目前 Kafka Producer 是异步发送消息的，如果你的 **Producer 客户端使用了 producer.send(msg) 方法来发送消息，方法会立即返回，但此时并不能代表消息已经发送成功了**。

   2. 如果消息再发送的过程中发生了网络抖动，那么消息可能没有传递到 Broker，那么消息可能会丢失。
      如果发送的消息本身不符合，如大小超过了 Broker 的承受能力等。

   3. 为了提升效率，减少IO，producer在发送数据时可以将多个请求进行合并后发送。被合并的请求咋发送一线缓存在本地buffer中。缓存的方式和前文提到的刷盘类似，producer可以将请求打包成“块”或者按照时间间隔，将buffer中的数据发出。通过buffer我们可以将生产者改造为异步的方式，而这可以提升我们的发送效率。

      但是，buffer中的数据就是危险的。在正常情况下，客户端的异步调用可以通过callback来处理消息发送失败或者超时的情况，但是，一旦producer被非法的停止了，那么buffer中的数据将丢失，broker将无法收到该部分数据。又或者，**当Producer客户端内存不够时，如果采取的策略是丢弃消息**（另一种策略是block阻塞），消息也会被丢失。抑或，**消息产生（异步产生）过快，导致挂起线程过多，内存不足，导致程序崩溃，消息丢失。**

2. Broker 服务端丢失消息

   1. Leader Broker 宕机了，触发选举过程，**集群选举了一个落后 Leader 太多的 Broker 作为 Leader**，那么落后的那些消息就会丢失了。
   2. Kafka 为了提升性能，使用页缓存机制，将消息写入页缓存而非直接持久化至磁盘，采用了**异步批量刷盘机制**，也就是说，**按照一定的消息量和时间间隔去刷盘**，刷盘的动作由操作系统来调度的，如果刷盘之前，Broker 宕机了，重启后在页缓存的这部分消息则会丢失。

3. 消费者丢失消息

   1. 消费者拉取了消息，并处理了消息，但处理消息异常了导致失败，并且提交了偏移量，消费者重启后，会从之前已提交的位移的下一个位置重新开始消费，消费失败的那些消息不会再次处理，即相当于消费者丢失了消息。
   2. 消费者拉取了消息，并提交了消费位移，但是在消息处理结束之前突然发生了宕机等故障，消费者重启后，会从之前已提交的位移的下一个位置重新开始消费，之前未处理完成的消息不会再次处理，即相当于消费者丢失了消息。

组里有个同事使用 Kafka 不当，导致线上消息丢失，在修复一些线上的数据，人都麻了。事情是这样，有个 Kafka 消费者实例，部署到线上去，消费到了线上的数据，而新版本做了新的逻辑，新版本的业务逻辑与老版本的业务逻辑不兼容，直接导致消费失败，没有进行重试操作，关键还提交了 offset。直接这部分数据没有被业务处理，导致消息丢失，然后紧急修复线上数据。

### 确保不丢失消息

![img](https://cdn.jsdelivr.net/gh/candyboyou/imgs/img2416314-20230104191059744-80036878.png)

1. 生产者端
   * 通过配置来避免
     1. **使用带有回调通知的 send 方法，保存异常消息表，使用定时任务重试。**
     2. **设置 `retries = 3`，**当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries > 0 的 **Producer 能够自动重试消息发送**，避免消息丢失。设置 `retry.backoff.ms = 300`，合理估算重试的时间间隔，可以避免无效的频繁重试。
     3. **启用消息压缩**可以减小消息体的大小，从而减少网络传输失败的可能性。
   * 消息默认是异步批量发送的
     1. 将批量发送改为每个请求就发送
     2. 按照一定数目，每到一定数量就发送
     3. 将消息写到本地的磁盘中，后序重发
2. Broker 服务端
   * **减少日志刷盘的间隔时间。比如设置每1000条信息刷一次盘；每隔1秒刷一次盘。**
   * **设置 unclean.leader.election.enable = false。**它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。**至少保证ISR中至少有3个follower，**即设置min.insync.replicas = 3。**设置acks为-1。**也就是producer 等待 broker 的 ack，partition 的 leader 和 ISRL里的 follower 全部落盘成功后才返回 ack。但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复。
3. 消费者端
   * 把它设置成 `enable.auto.commit = false`，**采用手动提交位移的方式。**
   * **并且确保消息成功消费完成再提交。**

**如果消息确实丢失了，你可能需要根据具体的应用场景考虑一些业务逻辑上的补救措施，例如在消息处理失败时记录到日志，通过定时任务重新发送等。**

> 0：producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟，broker 一接收到还 没有写入磁盘就已经返回，当 broker 故障时有可能丢失数据；
> 1：producer 等待 broker 的 ack，partition 的 leader 落盘成功后返回 ack，如果在 follower 同步成功之前 leader 故障，那么将会丢失数据
> -1（all）：producer 等待 broker 的 ack，partition 的 leader 和 follower （ISRL里的follower，不是全部的follower）全部落盘成功后才 返回 ack。但是如果在 follower 同步完成后，broker 发送 ack 之前，leader 发生故障，那么会造成数据重复

## isr是什么 

所有与Leader副本保持一定程度同步的副本（包括Leader副本）组成副本列表 ISR（In-Sync Replicas），实际存储的是副本所在Broker的BrokerId。这里的保持同步并不是Follower副本与Leader副本数据完全一致，只需要在一定时间内保持有效连接即可，这个时间由参数replica.lag.time.max.ms设定，默认值为10s。

## kafka为什么高可用

1. 多个Broker进程分散到不同机器上。
2. 备份机制（Replication）。相同的数据拷贝到多台机器。partition 多加几个副本，也就是 **replicas**，将它们分为 **Leader** 和 **Follower**。Leader 负责应付生产者和消费者的读写请求，而 Follower 只管同步 Leader 的消息。将 Leader 和 Follower 分散到不同的 broker 上，这样 Leader 所在的 broker 挂了，也不会影响到 Follower 所在的 broker, 并且还能从 Follower 中选举出一个新的 Leader partition 顶上。这样就保证了消息队列的高可用。
3. 将数据持久化到磁盘中，这样哪怕全部 broker 都挂了，数据也不会全丢，重启服务后，也能从磁盘里读出数据，继续工作。

## kafka为什么快/kafka为什么吞吐量高

1. 使用批量处理的方式来提升系统吞吐能力。构建批消息和解开批消息分别在发送端和消费端的客户端完成，不仅减轻了Broker的压力，还减少了Broker处理请求的次数，提升了总体的处理能力。

   在Kafka内部，消息都是以“批”为单位处理的。当我们调用send()方法发送一条消息后，Kafka并不会立刻把这条消息发送出去，它会先把这条消息存放在内存中，然后选择合适的时机把缓存的所有消息组成一批，一次性的发给Broker；在Broker端，整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本，批消息都不回被解开，一直是作为一条“批消息”进行处理的；在消费时，消息同样是以批为单位进行传递的，Consumer从Broker拉到一批消息后，在客户端把批消息解开，再一条一条交给用户代码处理。

2. 基于磁盘文件高性能顺序读写的特性来设计的存储结构。

   对于磁盘来说，一个重要特性是顺序读写的性能要远远好于随机读写。Kafka利用了磁盘这个特性，它的存储设计非常简单，对于每个分区，它把从Producer收到的消息，顺序地写入对应的log文件中，一个文件写完了，就开启一个新的文件继续顺序写下去。消费的时候，也是从某个全局的位置开始，顺序地把消息读出来。

3. 利用操作系统的PageCache来缓存数据，减少IO并提升读性能。为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。

   * 避免Object消耗：如果是使用 Java 堆，Java对象的内存消耗比较大，通常是所存储数据的两倍甚至更多。
   * 避免GC问题：随着JVM中数据不断增多，垃圾回收将会变得复杂与缓慢，使用系统缓存就不会存在GC问题

   当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。

   详细来说：

   对于Produce请求：Server端的I/O线程统一将请求中的数据写入到操作系统的PageCache后立即返回，当消息条数到达一定阈值后，Kafka应用本身或操作系统内核会触发强制刷盘操作（如左侧流程图所示）。

   对于Consume请求：主要利用了操作系统的ZeroCopy机制，当Kafka Broker接收到读数据请求时，会向操作系统发送sendfile系统调用，操作系统接收后，首先试图从PageCache中获取数据（如中间流程图所示）；如果数据不存在，会触发缺页异常中断将数据从磁盘读入到临时缓冲区中（如右侧流程图所示），随后将数据拷贝到网卡缓冲区中等待后续的TCP传输（数据拷贝利用DMA操作减少拷贝次数和上下文切换）。

   由此我们可以得出重要的结论：如果Kafka producer的生产速率与consumer的消费速率相差不大，那么就能几乎只靠对broker page cache的读写完成整个生产-消费过程，磁盘访问非常少。并且Kafka持久化消息到各个topic的partition文件时，是只追加的顺序写，充分利用了磁盘顺序访问快的特性，效率高。

4. 使用零拷贝技术加速消费流程。

   我们把 Kafka 的生产和消费简化成如下两个过程来看：

   - Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入
   - Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗

   > **Memory Mapped Files**：简称 mmap，也有叫 **MMFile** 的，使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射。从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程。它的工作原理是直接利用操作系统的 Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。
   >
   > 使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销。

5. 分区分段+索引。

   Kafka的message是按topic分类存储的，topic中的数据又是按照一个一个的partition即分区存储到不同broker节点。每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的。这也非常符合分布式系统分区分桶的设计思想。

   通过这种分区分段的设计，Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操作的segment。为了进一步的查询优化，Kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。

6. Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。

## 零拷贝

零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。

- Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入
- Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer进行网络发送，减少 CPU 消耗

## kafka的冷读

定时周期性消费者，消费的消息通常是数分钟前或是数小时前的消息。而这类消息通常存储在磁盘中，消费时会触发磁盘的IO操作。通常称其为冷读，适合报表计算、批量计算等周期性执行的业务场景。

根据消费的实时性可以将消息消费者行为划分两类：实时消费者和离线消费者。

- 实时消费者：对数据实时性要求较高，需要采用实时消费消息的方式。在实时消费的场景下，Kafka会利用系统的page cache缓存，生产消息到broker，然后直接从内存转发给实时消费者，磁盘压力为零。通常称上述操作为热读，常见的业务场景有广告、推荐等。
- 离线消费者：又名定时周期性消费者，消费的消息通常是数分钟前或是数小时前的消息。而这类消息通常存储在磁盘中，消费时会触发磁盘的IO操作。通常称其为冷读，适合报表计算、批量计算等周期性执行的业务场景。

在消息量非常大的情况下，实时和离线消费者同时消费一个集群，会导致两个问题：

- 实时消费者受到离线消费者影响：由于离线消费者消费，导致落盘数据和实时数据会频繁的换入换出内存，直接影响实时业务的实时性，增加实时业务的响应时延；
- 离线数据会导致繁重的磁盘IO操作：当离线任务读取的数据量非常大时，会触发磁盘的高IO，磁盘的IO util 甚至达到100%，影响集群的稳定性。

## kafka消费者拉取消息是怎么做的？/   kafka消费者如何拉取消息



## kafka与消费者建立的长链接是怎么实现的

TCP 连接是在调用 KafkaConsumer.poll 方法时被创建的。

在 poll 方法内部有 3 个时机可以创建 TCP 连接。

1. 发起 FindCoordinator 请求时。当消费者程序首次启动调用 poll 方法时，它需要向 Kafka 集群发送一个名为 FindCoordinator 的请求，希望 Kafka 集群告诉它哪个 Broker 是管理它的协调者。

   消费者应该向哪个 Broker 发送这类请求呢？理论上任何一个 Broker 都能回答这个问题，也就是说消费者可以发送 FindCoordinator 请求给集群中的任意服务器。在这个问题上，社区做了一点点优化：消费者程序会向集群中当前负载最小的那台 Broker 发送请求。负载是如何评估的呢？其实很简单，就是看消费者连接的所有 Broker 中，谁的待发送请求最少。当然了，这种评估显然是消费者端的单向评估，并非是站在全局角度，因此有的时候也不一定是最优解。

2. 连接协调者时。

3. 消费数据时。消费者会为每个要消费的分区创建与该分区领导者副本所在 Broker 连接的 TCP。举个例子，假设消费者要消费 5 个分区的数据，这 5 个分区各自的领导者副本分布在 4 台 Broker 上，那么该消费者在消费时会创建与这 4 台 Broker 的 Socket 连接。

消费者程序会创建 3 类 TCP 连接：

1. 确定协调者和获取集群元数据。
2. 连接协调者，令其执行组成员管理操作。
3. 执行实际的消息获取。

https://www.cnblogs.com/klm-kain/p/16132016.html

## kafka自带的重试还是有序的吗？

可以，只要开启幂等性，在Producer ID（即PID）和Sequence Number的基础上，消息最终将保持AB的顺序。

## 负载均衡算法，扩容了怎么办

https://blog.huohaodong.com/blog/how-kafka-design-loadbalance

1. 生产者层面的负载均衡

   默认就是对 Key 进行哈希处理，这意味着具有相同 Key 的消息将被分配到同一个分区，从而保证了具有相同 Key 的消息将被按照一定顺序处理。此外，当传入的 Key 为 null 时将会 fallback 到轮询策略。

2. Broker 层面的负载均衡

3. 消费者层面的负载均衡

   Kafka 在消费者层面的负载均衡（再平衡）是以消费者组为单位展开的，消费者组中消费者数量的增减都会使得 Kafka 将分区副本按照一定规则重新分配到消费者组中。这里需要注意的是，不同消费者组之前的分区重分配是互不影响，独立进行的。

   Kafka 提供了三个开箱即用的分区分配器：`RangeAssignor`（默认）、`RoundRobinAssignor` 以及 `StickyAssignor`。

   * RangeAssignor。
   * RoundRobinAssignor。将消费者组内所有消费者订阅的所有主题的分区按照字典序排序，之后以轮询的方式分配到每个消费者中，如果某个消费者没有订阅对应的主题，那么则不会将分区分配给它。
   * StickyAssignor。

## kafka异步通信怎么实现的，说说具体的逻辑流程

## kafka优缺点 

## 

## 介绍一下Kafka集群、副本、选举？kafka怎么做的选主 

1. Kafka要先从所有Broker中选出唯一的一个Controller。所有的Broker会尝试在Zookeeper中创建临时节点/controller，谁先创建成功，谁就是Controller。那如果Controller挂掉或者网络出现问题，ZooKeeper上的临时节点就会消失。其他的Broker通过Watch监听到Controller下线的消息后，继续按照先到先得的原则竞选Controller。这个Controller就相当于选举委员会的主席。
2. Controller确定以后，就可以开始做分区选主的事情。只有在ISR（In-Sync Replicas）保持心跳同步的副本才有资格参与竞选。默认是让ISR中第一个Replica变成Leader。比如ISR是1、5、9，优先让1成为Leader。

## kafka怎么保证不同partition分配到同一消费者组不同消费者？/分区分配策略？

https://www.51cto.com/article/708017.html

https://blog.csdn.net/nazeniwaresakini/article/details/108445278

1. **RangeAssignor**。 for循环对订阅的多个topic分别进行处理，对消费者按照字典顺序进行排序，计算平均每个消费者分配的分区数，计算平均分配后多出的分区数。
2. **RoundRobinAssignor**。RoundRobinAssignor策略仍然会将所有Consumer按照预设好的Member ID字典序排序，同时也会将所有Topic中的所有Partition按照字典序排序（注意这点不同），再轮询进行分配。
3. **StickyAssignor**。Partition的分配尽量平均，当Partition重新分配时，能够尽量保留上一次的分配，即尽量少将已经分配了的Partition分配给其他的Consumer。

## kafka的存储策略 

Kafka 中消息是以 topic 进行分类的，生产者通过 topic 向 Kafka broker 发送消息，消费者通过 topic 读取数据；topic 在物理层面又能以 partition 为分组，每个partition为一个目录，partiton命名规则为topic名称+有序序号；partition 还可以细分为 segment，每个partion(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。segment 由2大部分组成，分别为index file和data file。segment index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。

Kafka运行时很少有大量读磁盘的操作，主要是定期批量写磁盘操作，因此操作磁盘很高效。这跟Kafka文件存储中读写message的设计是息息相关的。Kafka中读写message有如下特点:

写message

- 消息从java堆转入page cache(即物理内存)。
- 由异步线程刷盘,消息从page cache刷入磁盘。

读message

- 消息直接从page cache转入socket发送出去。
- 当从page cache没有找到相应数据时，此时会产生磁盘IO,从磁 盘Load消息到page cache,然后直接从socket发出去

2存储策略
2.1 磁盘存储
Kafka使用磁盘存储消息数据，它将消息分成一个个的分区，每个分区对应一个日志文件（log file），并将日志文件存储在磁盘上。每个日志文件由多个日志段（log segment）组成，每个日志段的大小可以配置。当一个日志段写满后，Kafka会创建一个新的日志段，并将新的消息写入其中。旧的日志段会被异步地清理掉，以释放磁盘空间。

2.2 文件系统缓存
Kafka利用操作系统的文件系统缓存来加速数据的读取和写入。当消息被写入磁盘时，操作系统会将其缓存在内存中，并在需要时进行读取，避免了频繁的磁盘IO操作。这种利用文件系统缓存的方式可以显著提高Kafka的读写性能。

2.3 零拷贝技术
Kafka使用了零拷贝技术，即在消息传输过程中避免了数据的复制操作。传统的方式是将数据从一个缓冲区复制到另一个缓冲区，而零拷贝技术通过操作系统的DMA（Direct Memory Access）功能，将数据直接从磁盘读取到内存中，或者从内存中直接写入磁盘，避免了数据的多次复制，提高了数据传输的效率。

## kafka的发送消息接收的完整流程？

## Kafka的数据模型

Kafka 数据模型的主要组成部分：

1. Topic（主题）： 主题是消息的逻辑分类。消息被发布到一个或多个主题中。主题是 Kafka 中数据的最高层级，类似于数据库中的表。主题名称用于标识消息的类型和目的。
2. Partition（分区）： 主题可以被划分成多个分区，每个分区是主题的一个物理子集。分区是 Kafka 中数据的基本单元，用于实现消息在集群中的并行处理。每个分区在不同的 Broker 上进行副本复制，以实现[负载均衡](https://cloud.tencent.com/product/clb?from=20067&from_column=20067)和故障容错。分区的数量可以根据数据量和处理需求进行配置。
3. Offset（偏移量）： 在每个分区中，每个消息都会被赋予一个唯一的偏移量。偏移量表示消息在分区中的位置，它用于唯一标识消息。消费者可以通过指定偏移量来读取特定位置的消息，从而实现消息的顺序消费和跳跃消费。
4. 消息（Message）： 消息是 Kafka 中的基本数据单元。它是一条包含了 key、value 和时间戳等信息的二进制数据。消息被发布到主题的一个分区中，然后由 Broker 存储和处理。
5. Broker（代理）： Broker 是 Kafka 集群中的服务器节点，每个 Broker 负责管理多个分区和副本。它接收来自生产者的消息并为消费者提供消息。

## Kafka的传播关系

## 你们项目中kafka是怎么处理消费失败的	



## kafka消费lag了怎么办？/如何解决Kafka消息积压？

1. consumer导致kafka积压了大量消息

   方法：

   1. 增大partion数量，
   2. 消费者加了并发，服务， 扩大消费线程
   3. 增加消费组服务数量
   4. kafka单机升级成了集群
   5. 避免消费者消费消息时间过长，导致超时
   6. 使Kafka分区之间的数据均匀分布

场景：

1. 如果是Kafka消费能力不足，则可以考虑增加 topic 的 partition 的个数，同时提升消费者组的消费者数量，消费数 = 分区数 （二者缺一不可）
2. 若是下游数据处理不及时，则提高每批次拉取的数量。批次拉取数量过少（拉取数据/处理时间 < 生产速度），使处理的数据小于生产的数据，也会造成数据积压。

2. 消息过期失效

产生消息堆积，消费不及时，kafka数据有过期时间，一些数据就丢失了，主要是消费不及时

经验
1、消费kafka消息时，应该尽量减少每次消费时间，可通过减少调用三方接口、读库等操作，
   从而减少消息堆积的可能性。
2、如果消息来不及消费，可以先存在数据库中，然后逐条消费
  （还可以保存消费记录，方便定位问题）
3、每次接受kafka消息时，先打印出日志，包括消息产生的时间戳。
4、kafka消息保留时间（修改kafka配置文件， 默认一周）

## kafka生产者发了错误的消息怎么办？

## 手动提交offset，但是任务执行失败了怎么办？

很多RPC框架本身就具有服务自动发现，负载均衡等功能，这样消息队列的可用性就可以转交给RPC框架来处理，消息队列只需要保证broker接受消息和确认消息的接口是幂等的，并且consumer的几台机器处理消息是幂等的就行。那么怎么保证幂等呢？最简单的方式莫过于共享存储。broker多机器共享一个DB或者一个分布式文件/kv系统，则处理消息自然是幂等的。

Kafka的本质是日志消息代理 日志的特点就是append-only和不可变 它能带来的显而易见的好处是强大的局部性 内存中可以抽象为buffer 内核态里它又是page cache 磁盘上它会集中在同一磁道 从上至下利于软件和操作系统进行快速写入 这也是为什么大量知名系统 不论是MySQL Server的binlog还是redis的aof 都是使用类似的方式 它是典型的IO密集型应用 所以它并不是线程池 Kafka的大量技术细节都在解决IO性能 包括但不限于零拷贝

因为我的项目用了ElasticSearch，就先让我说一下我是怎么用ElasticSearch的。介绍完之后，看我有用RabbitMQ去更新ElasticSearch，就开始问我RabbitMQ以及业务场景题，比如说现在消息队列里有这么些消息，更新A，更新B，更新C。如何确保在并发的情况下是先更新A再更新B的（假如说B先到了消息队列里面，A因为某些原因慢到了），我一开始想的是直接给消息编号，然后与数据库里的编号比较，如果比它大，说明这个消息的执行优先级是比较后的（不断轮询直到能执行为止）。面试官对这个答案有点不满意，说ElasticSearch里有能实现这个效果的功能（我对ElasticSearch理解还真不多）。事后我查了一下，这个也是RabbitMQ常问的点，就是消息顺序性问题，但是我确实没记住，一般来说就是一个 queue但是对应一个 consumer，然后这个 consumer内部用内存队列做排队，然后分发给底层不同的 worker 来处理。

之后问题就转到RabbitMQ了，问死信队列，延迟队列，由于我很久没看RabbitMQ的知识点，连延迟队列怎么实现的都忘了，然后就疯狂拷打。紧接着又问延迟队列的应用场景（支付订单的倒计时界面），以及还有没有其他可以实现延迟队列的方法，我说redis应该也可以。



Kafka启动命令

zookeeper了解吗？

Kafka架构说说？

可以说下Kafka的分配分区策略吗？

kafka场景

kafka对比roketmq

kafkastream是怎么用的，里面的api之类的。这里感觉这个部门的挺长用kafka以及stream。

如何处理流式大量动态数据。用kafkastream怎么实现。

4.ES怎么保证不丢数据

   kafka相比于其他MQ有啥区别？

   es建立索引逻辑，es面对大的热数据怎么办

   es怎么用的 

   kafka流程；

   es深分页怎么处理mysql 深分页问题

   2、项目里用了Kafka，那聊一下RocketMQ和Kafka的区别；

   4、工作中，你们的ES和Mysql之间是怎么用的；

kafka 架构，WAL，一致性保证（p用pid，c用offset管理，broker用WAL和并发锁，partition、replica高吞吐），broker的并发锁，offset用特殊topic收集存在zookeeper里  

 es mysql用 mysql binlog同步的架构+同步方案，这个属于ETL的过程

   

使用了多路复用，不一定是使用了Reacto模型，Mysql使用了select（为什么不使用epoll，因为Mysql的瓶颈不是网络，是磁盘IO），但是并不是Reactor模型 回到问题，那些也是reactor nginx：nginx是多进程模型，master进程不处理网络IO，每个Wroker进程是一个独立的单Reacotr单线程模型。 netty：通信绝对的王者，默认是多Reactor，主Reacotr只负责建立连接，然后把建立好的连接给到从Reactor，从Reactor负责IO读写。当然可以专门调整为单Reactor。 kafka：kafka也是多Reactor，但是因为Kafka主要与磁盘IO交互，因此真正的读写数据不是从Reactor处理的，而是有一个worker线程池，专门处理磁盘IO，从Reactor负责网络IO，然后把任务交给worker线程池处理。